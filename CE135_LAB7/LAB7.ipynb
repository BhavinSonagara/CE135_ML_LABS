{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kWBMu_eS0QQF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded['BuyComputer.csv']))\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "RqVbHt0U0mum",
        "outputId": "20ac9aa8-7192-41a8-962d-fd029ca3ecb3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c989d7df-6f29-479e-9cef-7e50fc8c3942\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c989d7df-6f29-479e-9cef-7e50fc8c3942\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BuyComputer.csv to BuyComputer (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae530496-eda4-4bdc-8f80-9df4f85e4b12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae530496-eda4-4bdc-8f80-9df4f85e4b12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae530496-eda4-4bdc-8f80-9df4f85e4b12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae530496-eda4-4bdc-8f80-9df4f85e4b12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Aya3h_O70yRL",
        "outputId": "016f5322-0e4e-406b-bb9f-6afe869f9cd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  EstimatedSalary  Purchased\n",
              "0     19            19000          0\n",
              "1     35            20000          0\n",
              "2     26            43000          0\n",
              "3     27            57000          0\n",
              "4     19            76000          0\n",
              "..   ...              ...        ...\n",
              "395   46            41000          1\n",
              "396   51            23000          1\n",
              "397   50            20000          1\n",
              "398   36            33000          0\n",
              "399   49            36000          1\n",
              "\n",
              "[400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-197ecbc5-67e3-4d18-818e-a1bd786ca5d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>41000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>50</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>36</td>\n",
              "      <td>33000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>49</td>\n",
              "      <td>36000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-197ecbc5-67e3-4d18-818e-a1bd786ca5d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-197ecbc5-67e3-4d18-818e-a1bd786ca5d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-197ecbc5-67e3-4d18-818e-a1bd786ca5d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declare label as last column in the source file"
      ],
      "metadata": {
        "id": "N8WUANVP1cy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring X as all columns excluding last\n",
        "X = data.iloc[:,:-1].values\n",
        "\n",
        "#Declare label as last column in the source file\n",
        "Y = data.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "au9edz251fJ_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mHxqdcw2RRJ",
        "outputId": "233e6c5d-dd67-4c79-fb84-337cfe39cc97"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    19,  19000],\n",
              "       [    35,  20000],\n",
              "       [    26,  43000],\n",
              "       [    27,  57000],\n",
              "       [    19,  76000],\n",
              "       [    27,  58000],\n",
              "       [    27,  84000],\n",
              "       [    32, 150000],\n",
              "       [    25,  33000],\n",
              "       [    35,  65000],\n",
              "       [    26,  80000],\n",
              "       [    26,  52000],\n",
              "       [    20,  86000],\n",
              "       [    32,  18000],\n",
              "       [    18,  82000],\n",
              "       [    29,  80000],\n",
              "       [    47,  25000],\n",
              "       [    45,  26000],\n",
              "       [    46,  28000],\n",
              "       [    48,  29000],\n",
              "       [    45,  22000],\n",
              "       [    47,  49000],\n",
              "       [    48,  41000],\n",
              "       [    45,  22000],\n",
              "       [    46,  23000],\n",
              "       [    47,  20000],\n",
              "       [    49,  28000],\n",
              "       [    47,  30000],\n",
              "       [    29,  43000],\n",
              "       [    31,  18000],\n",
              "       [    31,  74000],\n",
              "       [    27, 137000],\n",
              "       [    21,  16000],\n",
              "       [    28,  44000],\n",
              "       [    27,  90000],\n",
              "       [    35,  27000],\n",
              "       [    33,  28000],\n",
              "       [    30,  49000],\n",
              "       [    26,  72000],\n",
              "       [    27,  31000],\n",
              "       [    27,  17000],\n",
              "       [    33,  51000],\n",
              "       [    35, 108000],\n",
              "       [    30,  15000],\n",
              "       [    28,  84000],\n",
              "       [    23,  20000],\n",
              "       [    25,  79000],\n",
              "       [    27,  54000],\n",
              "       [    30, 135000],\n",
              "       [    31,  89000],\n",
              "       [    24,  32000],\n",
              "       [    18,  44000],\n",
              "       [    29,  83000],\n",
              "       [    35,  23000],\n",
              "       [    27,  58000],\n",
              "       [    24,  55000],\n",
              "       [    23,  48000],\n",
              "       [    28,  79000],\n",
              "       [    22,  18000],\n",
              "       [    32, 117000],\n",
              "       [    27,  20000],\n",
              "       [    25,  87000],\n",
              "       [    23,  66000],\n",
              "       [    32, 120000],\n",
              "       [    59,  83000],\n",
              "       [    24,  58000],\n",
              "       [    24,  19000],\n",
              "       [    23,  82000],\n",
              "       [    22,  63000],\n",
              "       [    31,  68000],\n",
              "       [    25,  80000],\n",
              "       [    24,  27000],\n",
              "       [    20,  23000],\n",
              "       [    33, 113000],\n",
              "       [    32,  18000],\n",
              "       [    34, 112000],\n",
              "       [    18,  52000],\n",
              "       [    22,  27000],\n",
              "       [    28,  87000],\n",
              "       [    26,  17000],\n",
              "       [    30,  80000],\n",
              "       [    39,  42000],\n",
              "       [    20,  49000],\n",
              "       [    35,  88000],\n",
              "       [    30,  62000],\n",
              "       [    31, 118000],\n",
              "       [    24,  55000],\n",
              "       [    28,  85000],\n",
              "       [    26,  81000],\n",
              "       [    35,  50000],\n",
              "       [    22,  81000],\n",
              "       [    30, 116000],\n",
              "       [    26,  15000],\n",
              "       [    29,  28000],\n",
              "       [    29,  83000],\n",
              "       [    35,  44000],\n",
              "       [    35,  25000],\n",
              "       [    28, 123000],\n",
              "       [    35,  73000],\n",
              "       [    28,  37000],\n",
              "       [    27,  88000],\n",
              "       [    28,  59000],\n",
              "       [    32,  86000],\n",
              "       [    33, 149000],\n",
              "       [    19,  21000],\n",
              "       [    21,  72000],\n",
              "       [    26,  35000],\n",
              "       [    27,  89000],\n",
              "       [    26,  86000],\n",
              "       [    38,  80000],\n",
              "       [    39,  71000],\n",
              "       [    37,  71000],\n",
              "       [    38,  61000],\n",
              "       [    37,  55000],\n",
              "       [    42,  80000],\n",
              "       [    40,  57000],\n",
              "       [    35,  75000],\n",
              "       [    36,  52000],\n",
              "       [    40,  59000],\n",
              "       [    41,  59000],\n",
              "       [    36,  75000],\n",
              "       [    37,  72000],\n",
              "       [    40,  75000],\n",
              "       [    35,  53000],\n",
              "       [    41,  51000],\n",
              "       [    39,  61000],\n",
              "       [    42,  65000],\n",
              "       [    26,  32000],\n",
              "       [    30,  17000],\n",
              "       [    26,  84000],\n",
              "       [    31,  58000],\n",
              "       [    33,  31000],\n",
              "       [    30,  87000],\n",
              "       [    21,  68000],\n",
              "       [    28,  55000],\n",
              "       [    23,  63000],\n",
              "       [    20,  82000],\n",
              "       [    30, 107000],\n",
              "       [    28,  59000],\n",
              "       [    19,  25000],\n",
              "       [    19,  85000],\n",
              "       [    18,  68000],\n",
              "       [    35,  59000],\n",
              "       [    30,  89000],\n",
              "       [    34,  25000],\n",
              "       [    24,  89000],\n",
              "       [    27,  96000],\n",
              "       [    41,  30000],\n",
              "       [    29,  61000],\n",
              "       [    20,  74000],\n",
              "       [    26,  15000],\n",
              "       [    41,  45000],\n",
              "       [    31,  76000],\n",
              "       [    36,  50000],\n",
              "       [    40,  47000],\n",
              "       [    31,  15000],\n",
              "       [    46,  59000],\n",
              "       [    29,  75000],\n",
              "       [    26,  30000],\n",
              "       [    32, 135000],\n",
              "       [    32, 100000],\n",
              "       [    25,  90000],\n",
              "       [    37,  33000],\n",
              "       [    35,  38000],\n",
              "       [    33,  69000],\n",
              "       [    18,  86000],\n",
              "       [    22,  55000],\n",
              "       [    35,  71000],\n",
              "       [    29, 148000],\n",
              "       [    29,  47000],\n",
              "       [    21,  88000],\n",
              "       [    34, 115000],\n",
              "       [    26, 118000],\n",
              "       [    34,  43000],\n",
              "       [    34,  72000],\n",
              "       [    23,  28000],\n",
              "       [    35,  47000],\n",
              "       [    25,  22000],\n",
              "       [    24,  23000],\n",
              "       [    31,  34000],\n",
              "       [    26,  16000],\n",
              "       [    31,  71000],\n",
              "       [    32, 117000],\n",
              "       [    33,  43000],\n",
              "       [    33,  60000],\n",
              "       [    31,  66000],\n",
              "       [    20,  82000],\n",
              "       [    33,  41000],\n",
              "       [    35,  72000],\n",
              "       [    28,  32000],\n",
              "       [    24,  84000],\n",
              "       [    19,  26000],\n",
              "       [    29,  43000],\n",
              "       [    19,  70000],\n",
              "       [    28,  89000],\n",
              "       [    34,  43000],\n",
              "       [    30,  79000],\n",
              "       [    20,  36000],\n",
              "       [    26,  80000],\n",
              "       [    35,  22000],\n",
              "       [    35,  39000],\n",
              "       [    49,  74000],\n",
              "       [    39, 134000],\n",
              "       [    41,  71000],\n",
              "       [    58, 101000],\n",
              "       [    47,  47000],\n",
              "       [    55, 130000],\n",
              "       [    52, 114000],\n",
              "       [    40, 142000],\n",
              "       [    46,  22000],\n",
              "       [    48,  96000],\n",
              "       [    52, 150000],\n",
              "       [    59,  42000],\n",
              "       [    35,  58000],\n",
              "       [    47,  43000],\n",
              "       [    60, 108000],\n",
              "       [    49,  65000],\n",
              "       [    40,  78000],\n",
              "       [    46,  96000],\n",
              "       [    59, 143000],\n",
              "       [    41,  80000],\n",
              "       [    35,  91000],\n",
              "       [    37, 144000],\n",
              "       [    60, 102000],\n",
              "       [    35,  60000],\n",
              "       [    37,  53000],\n",
              "       [    36, 126000],\n",
              "       [    56, 133000],\n",
              "       [    40,  72000],\n",
              "       [    42,  80000],\n",
              "       [    35, 147000],\n",
              "       [    39,  42000],\n",
              "       [    40, 107000],\n",
              "       [    49,  86000],\n",
              "       [    38, 112000],\n",
              "       [    46,  79000],\n",
              "       [    40,  57000],\n",
              "       [    37,  80000],\n",
              "       [    46,  82000],\n",
              "       [    53, 143000],\n",
              "       [    42, 149000],\n",
              "       [    38,  59000],\n",
              "       [    50,  88000],\n",
              "       [    56, 104000],\n",
              "       [    41,  72000],\n",
              "       [    51, 146000],\n",
              "       [    35,  50000],\n",
              "       [    57, 122000],\n",
              "       [    41,  52000],\n",
              "       [    35,  97000],\n",
              "       [    44,  39000],\n",
              "       [    37,  52000],\n",
              "       [    48, 134000],\n",
              "       [    37, 146000],\n",
              "       [    50,  44000],\n",
              "       [    52,  90000],\n",
              "       [    41,  72000],\n",
              "       [    40,  57000],\n",
              "       [    58,  95000],\n",
              "       [    45, 131000],\n",
              "       [    35,  77000],\n",
              "       [    36, 144000],\n",
              "       [    55, 125000],\n",
              "       [    35,  72000],\n",
              "       [    48,  90000],\n",
              "       [    42, 108000],\n",
              "       [    40,  75000],\n",
              "       [    37,  74000],\n",
              "       [    47, 144000],\n",
              "       [    40,  61000],\n",
              "       [    43, 133000],\n",
              "       [    59,  76000],\n",
              "       [    60,  42000],\n",
              "       [    39, 106000],\n",
              "       [    57,  26000],\n",
              "       [    57,  74000],\n",
              "       [    38,  71000],\n",
              "       [    49,  88000],\n",
              "       [    52,  38000],\n",
              "       [    50,  36000],\n",
              "       [    59,  88000],\n",
              "       [    35,  61000],\n",
              "       [    37,  70000],\n",
              "       [    52,  21000],\n",
              "       [    48, 141000],\n",
              "       [    37,  93000],\n",
              "       [    37,  62000],\n",
              "       [    48, 138000],\n",
              "       [    41,  79000],\n",
              "       [    37,  78000],\n",
              "       [    39, 134000],\n",
              "       [    49,  89000],\n",
              "       [    55,  39000],\n",
              "       [    37,  77000],\n",
              "       [    35,  57000],\n",
              "       [    36,  63000],\n",
              "       [    42,  73000],\n",
              "       [    43, 112000],\n",
              "       [    45,  79000],\n",
              "       [    46, 117000],\n",
              "       [    58,  38000],\n",
              "       [    48,  74000],\n",
              "       [    37, 137000],\n",
              "       [    37,  79000],\n",
              "       [    40,  60000],\n",
              "       [    42,  54000],\n",
              "       [    51, 134000],\n",
              "       [    47, 113000],\n",
              "       [    36, 125000],\n",
              "       [    38,  50000],\n",
              "       [    42,  70000],\n",
              "       [    39,  96000],\n",
              "       [    38,  50000],\n",
              "       [    49, 141000],\n",
              "       [    39,  79000],\n",
              "       [    39,  75000],\n",
              "       [    54, 104000],\n",
              "       [    35,  55000],\n",
              "       [    45,  32000],\n",
              "       [    36,  60000],\n",
              "       [    52, 138000],\n",
              "       [    53,  82000],\n",
              "       [    41,  52000],\n",
              "       [    48,  30000],\n",
              "       [    48, 131000],\n",
              "       [    41,  60000],\n",
              "       [    41,  72000],\n",
              "       [    42,  75000],\n",
              "       [    36, 118000],\n",
              "       [    47, 107000],\n",
              "       [    38,  51000],\n",
              "       [    48, 119000],\n",
              "       [    42,  65000],\n",
              "       [    40,  65000],\n",
              "       [    57,  60000],\n",
              "       [    36,  54000],\n",
              "       [    58, 144000],\n",
              "       [    35,  79000],\n",
              "       [    38,  55000],\n",
              "       [    39, 122000],\n",
              "       [    53, 104000],\n",
              "       [    35,  75000],\n",
              "       [    38,  65000],\n",
              "       [    47,  51000],\n",
              "       [    47, 105000],\n",
              "       [    41,  63000],\n",
              "       [    53,  72000],\n",
              "       [    54, 108000],\n",
              "       [    39,  77000],\n",
              "       [    38,  61000],\n",
              "       [    38, 113000],\n",
              "       [    37,  75000],\n",
              "       [    42,  90000],\n",
              "       [    37,  57000],\n",
              "       [    36,  99000],\n",
              "       [    60,  34000],\n",
              "       [    54,  70000],\n",
              "       [    41,  72000],\n",
              "       [    40,  71000],\n",
              "       [    42,  54000],\n",
              "       [    43, 129000],\n",
              "       [    53,  34000],\n",
              "       [    47,  50000],\n",
              "       [    42,  79000],\n",
              "       [    42, 104000],\n",
              "       [    59,  29000],\n",
              "       [    58,  47000],\n",
              "       [    46,  88000],\n",
              "       [    38,  71000],\n",
              "       [    54,  26000],\n",
              "       [    60,  46000],\n",
              "       [    60,  83000],\n",
              "       [    39,  73000],\n",
              "       [    59, 130000],\n",
              "       [    37,  80000],\n",
              "       [    46,  32000],\n",
              "       [    46,  74000],\n",
              "       [    42,  53000],\n",
              "       [    41,  87000],\n",
              "       [    58,  23000],\n",
              "       [    42,  64000],\n",
              "       [    48,  33000],\n",
              "       [    44, 139000],\n",
              "       [    49,  28000],\n",
              "       [    57,  33000],\n",
              "       [    56,  60000],\n",
              "       [    49,  39000],\n",
              "       [    39,  71000],\n",
              "       [    47,  34000],\n",
              "       [    48,  35000],\n",
              "       [    48,  33000],\n",
              "       [    47,  23000],\n",
              "       [    45,  45000],\n",
              "       [    60,  42000],\n",
              "       [    39,  59000],\n",
              "       [    46,  41000],\n",
              "       [    51,  23000],\n",
              "       [    50,  20000],\n",
              "       [    36,  33000],\n",
              "       [    49,  36000]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,Y ,\n",
        "                                   random_state=135, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "8gWGWHET2Sp-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import XATTR_SIZE_MAX\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "CQ2LkhvM2fNq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-es2TR82y5F",
        "outputId": "ce421792-b24f-47f8-f64e-6daafeac4998"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.79535913, -1.21175916],\n",
              "       [-0.89622783, -1.09296895],\n",
              "       [-0.05043435,  0.15432828],\n",
              "       [-0.61429667,  0.59979158],\n",
              "       [ 0.79535913,  0.30281605],\n",
              "       [ 0.32547386,  0.3325136 ],\n",
              "       [-0.05043435,  2.29255211],\n",
              "       [-0.42634257,  2.38164477],\n",
              "       [ 1.35922145, -1.41964203],\n",
              "       [-0.05043435,  0.09493318],\n",
              "       [ 0.13751976, -0.29113501],\n",
              "       [-1.74202132,  0.03553807],\n",
              "       [-1.08418194,  1.46102062],\n",
              "       [-0.61429667,  0.15432828],\n",
              "       [-0.70827373,  0.59979158],\n",
              "       [-0.23838846,  0.57009403],\n",
              "       [-1.46009016, -1.50873469],\n",
              "       [ 0.32547386, -0.70690076],\n",
              "       [ 2.11103788, -0.79599342],\n",
              "       [ 1.07729029,  0.15432828],\n",
              "       [-0.23838846, -0.32083257],\n",
              "       [-1.55406721, -0.02385703],\n",
              "       [ 0.70138208,  1.84708881],\n",
              "       [-0.23838846,  0.12463073],\n",
              "       [ 1.64115261, -0.88508607],\n",
              "       [-1.08418194, -1.5681298 ],\n",
              "       [-0.33236551,  0.09493318],\n",
              "       [-0.89622783, -0.40992522],\n",
              "       [-0.52031962,  1.52041573],\n",
              "       [-0.61429667, -1.50873469],\n",
              "       [-1.74202132, -1.30085182],\n",
              "       [-0.80225078,  2.35194722],\n",
              "       [-0.23838846,  0.06523563],\n",
              "       [-1.08418194,  0.3325136 ],\n",
              "       [ 1.2652444 ,  2.29255211],\n",
              "       [ 0.13751976,  1.57981083],\n",
              "       [ 0.98331324,  2.14406434],\n",
              "       [ 0.23149681,  0.18402584],\n",
              "       [-1.27213605,  0.45130382],\n",
              "       [ 1.2652444 ,  1.93618147],\n",
              "       [ 1.45319851,  0.09493318],\n",
              "       [ 0.13751976,  0.30281605],\n",
              "       [ 0.98331324,  1.84708881],\n",
              "       [-1.08418194, -0.49901788],\n",
              "       [ 0.41945092, -0.43962278],\n",
              "       [ 0.98331324, -1.06327139],\n",
              "       [-1.55406721,  0.57009403],\n",
              "       [-0.23838846, -0.55841299],\n",
              "       [-0.05043435,  2.233157  ],\n",
              "       [-0.23838846, -0.35053012],\n",
              "       [-1.64804426,  0.39190871],\n",
              "       [-1.64804426, -0.58811054],\n",
              "       [ 1.07729029, -1.21175916],\n",
              "       [-0.80225078,  0.3325136 ],\n",
              "       [ 0.88933618,  1.31253286],\n",
              "       [ 0.32547386, -0.49901788],\n",
              "       [-0.33236551,  1.2828353 ],\n",
              "       [ 0.79535913, -1.09296895],\n",
              "       [ 1.64115261,  1.66890349],\n",
              "       [-0.14441141, -0.55841299],\n",
              "       [-0.23838846, -0.91478363],\n",
              "       [-0.80225078, -0.23173991],\n",
              "       [ 0.79535913, -1.36024692],\n",
              "       [-0.42634257, -1.21175916],\n",
              "       [-0.23838846,  0.83737201],\n",
              "       [-1.08418194,  0.3325136 ],\n",
              "       [ 0.23149681, -0.64750565],\n",
              "       [-0.14441141,  0.89676711],\n",
              "       [ 0.32547386,  0.30281605],\n",
              "       [-1.27213605, -1.09296895],\n",
              "       [ 2.01706083, -0.79599342],\n",
              "       [ 0.23149681, -0.29113501],\n",
              "       [-0.89622783,  0.54039647],\n",
              "       [-0.70827373, -0.58811054],\n",
              "       [-1.08418194, -1.15236405],\n",
              "       [-0.05043435,  0.2731185 ],\n",
              "       [ 0.0435427 ,  0.3325136 ],\n",
              "       [ 0.23149681,  0.09493318],\n",
              "       [ 0.41945092,  0.3325136 ],\n",
              "       [-1.27213605, -1.47903714],\n",
              "       [ 0.23149681,  0.06523563],\n",
              "       [-1.83599837,  0.51069892],\n",
              "       [ 0.79535913,  1.43132307],\n",
              "       [-1.74202132, -1.47903714],\n",
              "       [-1.27213605, -1.36024692],\n",
              "       [ 0.98331324, -1.18206161],\n",
              "       [ 1.64115261,  1.81739126],\n",
              "       [-0.80225078,  0.18402584],\n",
              "       [-1.08418194,  0.51069892],\n",
              "       [-1.08418194, -1.00387629],\n",
              "       [-0.05043435, -0.46932033],\n",
              "       [-0.05043435,  0.06523563],\n",
              "       [ 0.32547386, -0.26143746],\n",
              "       [-0.70827373, -0.20204235],\n",
              "       [ 0.88933618, -0.76629586],\n",
              "       [-0.23838846, -0.73659831],\n",
              "       [ 0.0435427 ,  0.06523563],\n",
              "       [-0.05043435, -0.40992522],\n",
              "       [-0.23838846, -0.11294969],\n",
              "       [-1.178159  ,  0.54039647],\n",
              "       [ 0.0435427 , -0.23173991],\n",
              "       [-0.89622783, -0.29113501],\n",
              "       [ 0.13751976,  0.24342094],\n",
              "       [-1.3661131 , -1.44933958],\n",
              "       [ 0.0435427 ,  1.31253286],\n",
              "       [ 1.17126734, -0.73659831],\n",
              "       [ 1.54717556, -1.27115427],\n",
              "       [-0.23838846, -0.55841299],\n",
              "       [ 0.70138208, -0.70690076],\n",
              "       [ 0.51342797,  1.2828353 ],\n",
              "       [-0.99020489, -0.32083257],\n",
              "       [-0.14441141,  1.66890349],\n",
              "       [ 1.35922145,  2.05497168],\n",
              "       [-1.27213605, -0.40992522],\n",
              "       [-0.14441141,  1.69860105],\n",
              "       [ 0.0435427 , -0.55841299],\n",
              "       [-1.27213605, -0.32083257],\n",
              "       [ 1.07729029,  0.59979158],\n",
              "       [ 0.98331324, -1.00387629],\n",
              "       [-0.61429667, -1.03357384],\n",
              "       [-0.23838846,  0.09493318],\n",
              "       [ 0.88933618,  1.07495243],\n",
              "       [ 1.17126734, -1.44933958],\n",
              "       [-1.08418194, -1.59782735],\n",
              "       [-0.14441141, -0.26143746],\n",
              "       [-1.27213605, -0.40992522],\n",
              "       [-0.70827373,  0.30281605],\n",
              "       [ 1.54717556,  1.16404509],\n",
              "       [ 0.88933618, -0.55841299],\n",
              "       [ 0.0435427 , -0.11294969],\n",
              "       [-0.70827373,  1.40162552],\n",
              "       [-0.52031962,  1.43132307],\n",
              "       [ 0.98331324, -1.15236405],\n",
              "       [ 0.41945092, -0.46932033],\n",
              "       [-0.23838846, -0.64750565],\n",
              "       [ 1.07729029, -1.21175916],\n",
              "       [ 0.23149681, -0.35053012],\n",
              "       [-1.178159  ,  0.3325136 ],\n",
              "       [-0.05043435, -0.20204235],\n",
              "       [-1.83599837, -0.49901788],\n",
              "       [-0.23838846,  0.18402584],\n",
              "       [-0.99020489, -1.1226665 ],\n",
              "       [ 0.98331324,  0.15432828],\n",
              "       [ 0.88933618, -0.64750565],\n",
              "       [-0.70827373,  1.13434754],\n",
              "       [ 0.32547386, -0.49901788],\n",
              "       [ 0.41945092,  1.04525488],\n",
              "       [ 1.73512967,  1.90648392],\n",
              "       [ 0.32547386,  0.54039647],\n",
              "       [ 2.11103788, -1.03357384],\n",
              "       [-0.70827373,  0.54039647],\n",
              "       [ 2.01706083,  0.21372339],\n",
              "       [-1.3661131 ,  0.39190871],\n",
              "       [ 0.13751976, -0.79599342],\n",
              "       [-1.55406721, -1.5681298 ],\n",
              "       [ 1.92308377, -1.36024692],\n",
              "       [ 1.82910672, -0.26143746],\n",
              "       [-0.23838846, -1.44933958],\n",
              "       [-0.14441141, -0.1723448 ],\n",
              "       [ 0.13751976,  1.10464998],\n",
              "       [-0.52031962, -1.50873469],\n",
              "       [ 1.17126734,  0.57009403],\n",
              "       [-0.61429667,  0.21372339],\n",
              "       [-0.23838846, -0.46932033],\n",
              "       [ 0.13751976,  0.18402584],\n",
              "       [ 0.98331324,  2.05497168],\n",
              "       [ 0.88933618, -1.03357384],\n",
              "       [-0.52031962, -1.50873469],\n",
              "       [-1.08418194,  0.36221116],\n",
              "       [-0.05043435,  0.24342094],\n",
              "       [ 0.23149681,  0.2731185 ],\n",
              "       [-0.23838846,  0.18402584],\n",
              "       [-0.99020489, -0.43962278],\n",
              "       [ 2.11103788,  1.16404509],\n",
              "       [-1.27213605, -1.24145671],\n",
              "       [-1.74202132, -1.41964203],\n",
              "       [-1.83599837, -0.02385703],\n",
              "       [-0.80225078, -0.64750565],\n",
              "       [ 0.98331324,  0.80767445],\n",
              "       [ 1.07729029, -0.88508607],\n",
              "       [-0.14441141,  1.46102062],\n",
              "       [ 0.70138208, -1.09296895],\n",
              "       [ 1.07729029,  0.51069892],\n",
              "       [ 1.92308377,  0.7779769 ],\n",
              "       [-0.99020489,  0.59979158],\n",
              "       [-1.46009016, -0.40992522],\n",
              "       [ 1.92308377,  0.95616222],\n",
              "       [-1.64804426,  0.15432828],\n",
              "       [ 1.07729029, -0.11294969],\n",
              "       [-0.42634257,  0.00584052],\n",
              "       [-0.23838846, -1.36024692],\n",
              "       [-0.33236551, -0.76629586],\n",
              "       [-0.99020489,  0.62948913],\n",
              "       [-0.89622783,  0.48100137],\n",
              "       [-0.99020489, -1.53843224],\n",
              "       [-0.23838846, -0.26143746],\n",
              "       [-0.23838846, -0.88508607],\n",
              "       [-1.3661131 , -0.6178081 ],\n",
              "       [ 0.32547386,  0.09493318],\n",
              "       [-0.80225078, -1.21175916],\n",
              "       [ 0.13751976,  0.12463073],\n",
              "       [ 0.79535913,  0.80767445],\n",
              "       [-0.80225078,  0.42160626],\n",
              "       [-0.99020489,  0.45130382],\n",
              "       [ 1.54717556,  0.03553807],\n",
              "       [-1.08418194, -1.53843224],\n",
              "       [ 1.45319851,  0.39190871],\n",
              "       [ 0.79535913,  0.39190871],\n",
              "       [-0.70827373, -1.53843224],\n",
              "       [ 0.41945092,  0.3325136 ],\n",
              "       [ 1.07729029, -0.97417873],\n",
              "       [ 2.01706083,  0.57009403],\n",
              "       [ 2.11103788, -0.79599342],\n",
              "       [-0.61429667, -0.02385703],\n",
              "       [ 0.32547386,  0.06523563],\n",
              "       [-0.05043435,  0.71858179],\n",
              "       [-0.33236551, -0.76629586],\n",
              "       [-1.46009016, -0.1723448 ],\n",
              "       [ 0.0435427 , -0.23173991],\n",
              "       [ 0.32547386,  0.09493318],\n",
              "       [ 1.35922145,  2.41134232],\n",
              "       [ 1.17126734, -0.97417873],\n",
              "       [ 0.70138208,  0.30281605],\n",
              "       [-1.83599837, -0.73659831],\n",
              "       [ 0.13751976, -0.79599342],\n",
              "       [ 0.0435427 , -0.29113501],\n",
              "       [ 0.88933618, -1.30085182],\n",
              "       [ 1.82910672, -1.27115427],\n",
              "       [-0.14441141, -1.06327139],\n",
              "       [ 1.82910672, -1.06327139],\n",
              "       [-1.27213605,  0.59979158],\n",
              "       [-1.3661131 , -0.1723448 ],\n",
              "       [ 2.01706083,  0.42160626],\n",
              "       [ 0.41945092, -0.43962278],\n",
              "       [-0.42634257, -0.52871544],\n",
              "       [ 0.23149681, -0.26143746],\n",
              "       [-1.55406721,  0.09493318],\n",
              "       [ 0.51342797,  1.90648392],\n",
              "       [-0.61429667, -0.08325214],\n",
              "       [ 0.0435427 , -0.52871544],\n",
              "       [-0.89622783,  0.45130382],\n",
              "       [-1.08418194,  0.09493318],\n",
              "       [-1.3661131 , -1.21175916],\n",
              "       [-1.64804426,  0.39190871],\n",
              "       [-0.99020489,  2.02527413],\n",
              "       [ 1.07729029,  0.57009403],\n",
              "       [-0.23838846,  1.16404509],\n",
              "       [ 0.60740502,  2.08466924],\n",
              "       [ 0.41945092,  1.16404509],\n",
              "       [ 2.01706083, -1.18206161],\n",
              "       [ 1.35922145, -0.91478363],\n",
              "       [ 0.88933618,  1.13434754],\n",
              "       [ 0.0435427 ,  0.06523563],\n",
              "       [-0.52031962,  0.51069892],\n",
              "       [ 2.01706083,  1.81739126],\n",
              "       [-0.80225078, -0.76629586],\n",
              "       [-1.178159  ,  0.62948913],\n",
              "       [ 1.07729029,  2.14406434],\n",
              "       [-0.14441141,  2.233157  ],\n",
              "       [-0.14441141,  0.18402584],\n",
              "       [ 0.88933618, -1.15236405],\n",
              "       [ 0.23149681,  0.18402584],\n",
              "       [ 1.2652444 , -1.36024692],\n",
              "       [-0.61429667, -1.59782735],\n",
              "       [ 0.41945092,  0.18402584],\n",
              "       [ 0.23149681, -0.35053012],\n",
              "       [-0.70827373,  1.96587902],\n",
              "       [-0.05043435,  0.30281605],\n",
              "       [-0.52031962,  2.41134232],\n",
              "       [-0.14441141, -0.43962278],\n",
              "       [ 0.98331324,  1.49071817],\n",
              "       [-1.08418194, -1.59782735],\n",
              "       [-0.05043435,  0.3325136 ],\n",
              "       [ 0.0435427 , -0.55841299],\n",
              "       [ 1.45319851,  1.04525488],\n",
              "       [ 0.41945092, -0.11294969],\n",
              "       [ 0.88933618, -0.52871544],\n",
              "       [-0.61429667,  1.46102062],\n",
              "       [-0.42634257, -1.1226665 ],\n",
              "       [-0.80225078, -0.76629586],\n",
              "       [ 0.98331324,  0.62948913],\n",
              "       [-1.64804426, -1.36024692],\n",
              "       [-0.23838846,  0.65918669],\n",
              "       [ 1.92308377, -0.64750565],\n",
              "       [-1.08418194, -1.09296895],\n",
              "       [ 0.13751976,  0.06523563],\n",
              "       [ 0.13751976,  0.80767445],\n",
              "       [ 2.11103788,  0.98585977],\n",
              "       [ 0.32547386, -1.15236405],\n",
              "       [ 0.70138208, -1.38994448],\n",
              "       [ 0.98331324, -1.06327139],\n",
              "       [-1.64804426,  0.51069892],\n",
              "       [-1.3661131 , -0.08325214],\n",
              "       [ 0.98331324, -0.82569097],\n",
              "       [-0.42634257, -0.26143746],\n",
              "       [-1.64804426, -0.97417873],\n",
              "       [ 0.41945092, -0.14264725],\n",
              "       [ 2.01706083,  2.20345945],\n",
              "       [-0.42634257, -0.82569097],\n",
              "       [-0.52031962,  1.96587902]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikD0Sbcg3frX",
        "outputId": "3be47322-c76b-40ef-d1c5-06e193b477d7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.81163584e+00,  8.97689992e-01],\n",
              "       [-1.10873322e+00,  4.40850302e-01],\n",
              "       [ 2.00397739e-01,  9.83347434e-01],\n",
              "       [ 1.81163584e+00, -3.58619157e-01],\n",
              "       [ 8.04612027e-01, -3.87171638e-01],\n",
              "       [ 9.96953576e-02, -3.30066677e-01],\n",
              "       [-6.05221312e-01,  7.83480070e-01],\n",
              "       [ 8.04612027e-01, -1.44361342e+00],\n",
              "       [ 2.21444537e+00,  2.98087898e-01],\n",
              "       [-1.00702381e-03,  1.12610984e+00],\n",
              "       [ 1.50952870e+00, -1.10098365e+00],\n",
              "       [-1.00803084e+00, -3.87171638e-01],\n",
              "       [ 9.05314409e-01, -1.50071838e+00],\n",
              "       [-1.91435227e+00,  9.82205335e-02],\n",
              "       [-7.05923694e-01, -4.15724119e-01],\n",
              "       [-1.91435227e+00, -1.32940350e+00],\n",
              "       [-1.31013798e+00, -1.44361342e+00],\n",
              "       [-4.03816549e-01, -1.35795598e+00],\n",
              "       [ 3.01100120e-01, -3.87171638e-01],\n",
              "       [ 4.01802502e-01, -2.15856754e-01],\n",
              "       [ 2.01304060e+00,  2.03978922e+00],\n",
              "       [ 1.50952870e+00,  2.01123674e+00],\n",
              "       [-2.02411787e-01, -5.87039003e-01],\n",
              "       [ 8.04612027e-01, -9.01116290e-01],\n",
              "       [-3.03114168e-01, -3.30066677e-01],\n",
              "       [ 3.01100120e-01, -1.59893892e-02],\n",
              "       [-1.10873322e+00, -4.44276599e-01],\n",
              "       [-1.00803084e+00, -8.15458848e-01],\n",
              "       [-3.03114168e-01,  2.12544666e+00],\n",
              "       [-3.03114168e-01, -1.30085102e+00],\n",
              "       [-6.05221312e-01,  1.26887224e+00],\n",
              "       [-8.06626075e-01,  2.12430456e-01],\n",
              "       [-5.04518931e-01, -8.44011329e-01],\n",
              "       [-1.10873322e+00, -4.15724119e-01],\n",
              "       [-1.00803084e+00,  1.83877976e-01],\n",
              "       [ 1.40882632e+00,  1.18321480e+00],\n",
              "       [ 9.96953576e-02,  1.75426441e+00],\n",
              "       [ 1.40882632e+00,  4.97955263e-01],\n",
              "       [-2.01505465e+00,  2.69535418e-01],\n",
              "       [-3.03114168e-01, -1.59893892e-02],\n",
              "       [ 2.00397739e-01,  1.98268426e+00],\n",
              "       [-1.20943560e+00,  3.26640379e-01],\n",
              "       [ 9.96953576e-02, -4.45418698e-02],\n",
              "       [-1.61224513e+00,  2.40982937e-01],\n",
              "       [-1.01709405e-01, -7.30943505e-02],\n",
              "       [-1.01709405e-01, -1.12953614e+00],\n",
              "       [ 1.91233822e+00,  4.11155722e-02],\n",
              "       [-5.04518931e-01,  1.15466232e+00],\n",
              "       [-1.10873322e+00,  6.69270147e-01],\n",
              "       [ 1.00601679e+00,  1.75426441e+00],\n",
              "       [ 2.01304060e+00, -9.86773732e-01],\n",
              "       [-1.00702381e-03, -5.01381561e-01],\n",
              "       [-1.20943560e+00, -8.44011329e-01],\n",
              "       [ 2.00397739e-01, -3.30066677e-01],\n",
              "       [ 1.91233822e+00,  1.41163464e+00],\n",
              "       [-8.06626075e-01, -1.64348079e+00],\n",
              "       [ 4.01802502e-01,  4.97955263e-01],\n",
              "       [-3.03114168e-01,  1.83877976e-01],\n",
              "       [ 1.61023108e+00,  8.97689992e-01],\n",
              "       [ 4.01802502e-01,  1.83877976e-01],\n",
              "       [-4.03816549e-01,  1.21176728e+00],\n",
              "       [ 8.04612027e-01,  4.11155722e-02],\n",
              "       [-3.03114168e-01, -1.35795598e+00],\n",
              "       [ 4.01802502e-01, -7.30943505e-02],\n",
              "       [ 9.96953576e-02,  1.75426441e+00],\n",
              "       [ 6.03207265e-01, -9.58221251e-01],\n",
              "       [ 8.04612027e-01,  4.40850302e-01],\n",
              "       [-1.01709405e-01,  1.83992185e+00],\n",
              "       [ 2.21444537e+00, -7.58353887e-01],\n",
              "       [-3.03114168e-01, -1.44361342e+00],\n",
              "       [ 9.05314409e-01, -6.72696445e-01],\n",
              "       [-1.00803084e+00,  1.44018713e+00],\n",
              "       [-1.01709405e-01, -4.44276599e-01],\n",
              "       [-3.03114168e-01,  1.26773014e-01],\n",
              "       [ 2.00397739e-01, -2.15856754e-01],\n",
              "       [ 5.02504883e-01,  1.61150201e+00],\n",
              "       [-7.05923694e-01, -4.45418698e-02],\n",
              "       [ 4.01802502e-01,  1.25630915e-02],\n",
              "       [-3.03114168e-01, -3.87171638e-01],\n",
              "       [-1.61224513e+00, -1.30085102e+00],\n",
              "       [-1.01709405e-01, -5.87039003e-01],\n",
              "       [-1.91435227e+00,  3.55192860e-01],\n",
              "       [ 2.00397739e-01, -4.44276599e-01],\n",
              "       [-1.01709405e-01,  2.12430456e-01],\n",
              "       [-9.07328456e-01,  2.98087898e-01],\n",
              "       [-1.10873322e+00, -1.50071838e+00],\n",
              "       [ 3.01100120e-01, -6.15591483e-01],\n",
              "       [ 3.01100120e-01, -1.59893892e-02],\n",
              "       [ 4.01802502e-01,  2.18255162e+00],\n",
              "       [-1.00803084e+00,  4.69402782e-01],\n",
              "       [-1.00803084e+00, -1.01532621e+00],\n",
              "       [-1.31013798e+00,  1.83877976e-01],\n",
              "       [ 3.01100120e-01, -2.72961715e-01],\n",
              "       [-1.31013798e+00, -1.12953614e+00],\n",
              "       [-3.03114168e-01, -5.01381561e-01],\n",
              "       [-1.01709405e-01,  6.96680528e-02],\n",
              "       [ 7.03909646e-01, -1.44361342e+00],\n",
              "       [ 9.05314409e-01, -1.41506094e+00],\n",
              "       [ 7.03909646e-01, -1.32940350e+00],\n",
              "       [ 9.05314409e-01,  2.03978922e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variabes to calculate sigmoid function\n",
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)"
      ],
      "metadata": {
        "id": "Vgt9hkf038gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b329b3e7-dbc5-408c-f65e-79c1454c9f26"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entries = len(X_train[:,0])\n"
      ],
      "metadata": {
        "id": "5LL2j3pe7ByI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_0YceD67P7_",
        "outputId": "37ad0388-fbb5-4601-a127-d144c5ac8176"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weights in range(len_x):\n",
        "  w.append(0)"
      ],
      "metadata": {
        "id": "0Vqv4ouK7SFH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2UitfL7cCn",
        "outputId": "c83b9d58-0ed7-404a-c33d-f31fbd269062"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return (1/(1+np.exp(-z)))\n"
      ],
      "metadata": {
        "id": "ZViyyMee7fRn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(inputs):\n",
        "  z=np.dot(inputs,w)+b\n",
        "  h=sigmoid(z)\n",
        "  for i in range((len(h))):\n",
        "    if(h[i]>=0.5):\n",
        "      h[i]=1\n",
        "    else:\n",
        "      h[i]=0\n",
        "  return h\n",
        "  \n"
      ],
      "metadata": {
        "id": "Pm4tu11X7x4f"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y"
      ],
      "metadata": {
        "id": "S5SLUCTi8jrI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize.minpack import shape\n",
        "def loss_func(y,y1):\n",
        "  total_loss=np.sum(-y*np.log(y1)-(1-y)*np.log(1-y1))\n",
        "  m=y.shape[0]\n",
        "  j=total_loss/m\n",
        "  return j"
      ],
      "metadata": {
        "id": "2s1PF2K38mgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4599df-c3b5-444c-ace2-0746d1dc1654"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-d8fb0521e30b>:1: DeprecationWarning: Please use `shape` from the `scipy.optimize` namespace, the `scipy.optimize.minpack` namespace is deprecated.\n",
            "  from scipy.optimize.minpack import shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "  dw.append(0)"
      ],
      "metadata": {
        "id": "y7XMMhLCAGR3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=[]\n",
        "for i in range(3000):\n",
        "    z = np.dot(X_train, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    l = loss_func(y_train, y_pred)\n",
        "    l1.append(l)\n",
        "    dw = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
        "    db = np.mean(y_pred-y_train)\n",
        "    w = w - alpha * dw\n",
        "    b = b - alpha* db\n",
        "    print(\"Round:\",i,\"Weight:\",w,\"Bias:\",b,\"loss:\",l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-bGRoimALtW",
        "outputId": "c815ea08-48bf-418c-e94c-d45e08a40b7d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 0 Weight: [0.03023054 0.0166924 ] Bias: 0.18101660026875221 loss: 0.7261388693815921\n",
            "Round: 1 Weight: [0.05965023 0.03285965] Bias: 0.16250502399567548 loss: 0.7108210184376781\n",
            "Round: 2 Weight: [0.08828017 0.04851757] Bias: 0.1444567152734004 loss: 0.6963254331286269\n",
            "Round: 3 Weight: [0.11614241 0.06368254] Bias: 0.12686225600616502 loss: 0.6826090465755381\n",
            "Round: 4 Weight: [0.14325967 0.07837131] Bias: 0.10971152065029173 loss: 0.6696295905401078\n",
            "Round: 5 Weight: [0.16965512 0.09260085] Bias: 0.0929938229919834 loss: 0.6573458965932152\n",
            "Round: 6 Weight: [0.19535214 0.10638819] Bias: 0.07669805249937081 loss: 0.6457181355414536\n",
            "Round: 7 Weight: [0.22037415 0.11975026] Bias: 0.06081279863071322 loss: 0.6347079994976902\n",
            "Round: 8 Weight: [0.24474443 0.13270379] Bias: 0.04532646221831121 loss: 0.6242788322250574\n",
            "Round: 9 Weight: [0.26848596 0.14526522] Bias: 0.03022735365900458 loss: 0.614395714062855\n",
            "Round: 10 Weight: [0.29162137 0.15745061] Bias: 0.015503778123078103 loss: 0.6050255079610564\n",
            "Round: 11 Weight: [0.31417278 0.1692756 ] Bias: 0.00114410835071933 loss: 0.5961368730167433\n",
            "Round: 12 Weight: [0.33616174 0.18075535] Bias: -0.012863154147626586 loss: 0.5877002515240858\n",
            "Round: 13 Weight: [0.35760919 0.19190448] Bias: -0.026529328516620876 loss: 0.5796878350094562\n",
            "Round: 14 Weight: [0.37853543 0.2027371 ] Bias: -0.039865513557946125 loss: 0.5720735140983525\n",
            "Round: 15 Weight: [0.39896005 0.21326675] Bias: -0.05288255523893513 loss: 0.5648328164073606\n",
            "Round: 16 Weight: [0.41890193 0.22350644] Bias: -0.0655910216601735 loss: 0.5579428360129832\n",
            "Round: 17 Weight: [0.43837924 0.23346857] Bias: -0.07800118448614514 loss: 0.5513821574468687\n",
            "Round: 18 Weight: [0.45740946 0.24316505] Bias: -0.09012300591387735 loss: 0.5451307766200237\n",
            "Round: 19 Weight: [0.47600932 0.25260721] Bias: -0.10196613033617873 loss: 0.5391700205949486\n",
            "Round: 20 Weight: [0.4941949  0.26180585] Bias: -0.1135398799421695 loss: 0.5334824677063129\n",
            "Round: 21 Weight: [0.51198155 0.27077127] Bias: -0.12485325358384253 loss: 0.5280518691757708\n",
            "Round: 22 Weight: [0.52938399 0.27951327] Bias: -0.1359149283202376 loss: 0.5228630730703019\n",
            "Round: 23 Weight: [0.54641628 0.28804118] Bias: -0.14673326312845383 loss: 0.5179019512101265\n",
            "Round: 24 Weight: [0.56309186 0.29636387] Bias: -0.1573163043419965 loss: 0.5131553294353308\n",
            "Round: 25 Weight: [0.57942359 0.30448974] Bias: -0.167671792441318 loss: 0.508610921483363\n",
            "Round: 26 Weight: [0.59542373 0.31242683] Bias: -0.17780716987876538 loss: 0.5042572666063639\n",
            "Round: 27 Weight: [0.61110399 0.32018273] Bias: -0.18772958967069195 loss: 0.5000836709622737\n",
            "Round: 28 Weight: [0.62647558 0.32776468] Bias: -0.1974459245336198 loss: 0.4960801527417976\n",
            "Round: 29 Weight: [0.64154916 0.33517954] Bias: -0.20696277637955993 loss: 0.49223739094030916\n",
            "Round: 30 Weight: [0.65633496 0.34243384] Bias: -0.21628648601846145 loss: 0.48854667764589454\n",
            "Round: 31 Weight: [0.67084271 0.3495338 ] Bias: -0.22542314294384844 loss: 0.4849998736888972\n",
            "Round: 32 Weight: [0.68508174 0.35648529] Bias: -0.23437859510156264 loss: 0.4815893674819182\n",
            "Round: 33 Weight: [0.69906092 0.36329395] Bias: -0.24315845856169657 loss: 0.47830803687012663\n",
            "Round: 34 Weight: [0.71278878 0.36996508] Bias: -0.2517681270307536 loss: 0.4751492138082227\n",
            "Round: 35 Weight: [0.72627342 0.37650377] Bias: -0.2602127811552554 loss: 0.4721066516810664\n",
            "Round: 36 Weight: [0.73952263 0.38291485] Bias: -0.2684973975798228 loss: 0.4691744950887236\n",
            "Round: 37 Weight: [0.75254383 0.3892029 ] Bias: -0.2766267577325301 loss: 0.4663472519226133\n",
            "Round: 38 Weight: [0.76534412 0.39537229] Bias: -0.2846054563183878 loss: 0.46361976756686574\n",
            "Round: 39 Weight: [0.77793033 0.40142721] Bias: -0.2924379095083981 loss: 0.4609872010673856\n",
            "Round: 40 Weight: [0.79030894 0.40737161] Bias: -0.30012836281698907 loss: 0.4584450031200513\n",
            "Round: 41 Weight: [0.80248622 0.41320928] Bias: -0.307680898664962 loss: 0.4559888957386424\n",
            "Round: 42 Weight: [0.81446812 0.41894382] Bias: -0.3150994436285463 loss: 0.4536148534722641\n",
            "Round: 43 Weight: [0.82626038 0.42457869] Bias: -0.32238777537789776 loss: 0.4513190860510336\n",
            "Round: 44 Weight: [0.8378685  0.43011716] Bias: -0.32954952931051396 loss: 0.449098022347509\n",
            "Round: 45 Weight: [0.84929772 0.43556238] Bias: -0.3365882048866836 loss: 0.4469482955496846\n",
            "Round: 46 Weight: [0.86055312 0.44091734] Bias: -0.3435071716753184 loss: 0.44486672944929\n",
            "Round: 47 Weight: [0.87163953 0.4461849 ] Bias: -0.35030967511941047 loss: 0.44285032575660127\n",
            "Round: 48 Weight: [0.88256162 0.4513678 ] Bias: -0.3569988420309791 loss: 0.4408962523599651\n",
            "Round: 49 Weight: [0.89332387 0.45646866] Bias: -0.3635776858257658 loss: 0.43900183245476626\n",
            "Round: 50 Weight: [0.90393056 0.46148998] Bias: -0.37004911150815084 loss: 0.4371645344726403\n",
            "Round: 51 Weight: [0.91438584 0.46643417] Bias: -0.37641592041683525 loss: 0.43538196274735297\n",
            "Round: 52 Weight: [0.92469369 0.47130351] Bias: -0.38268081474178595 loss: 0.43365184885897085\n",
            "Round: 53 Weight: [0.93485792 0.47610022] Bias: -0.388846401822806 loss: 0.4319720436027354\n",
            "Round: 54 Weight: [0.94488221 0.48082639] Bias: -0.3949151982398859 loss: 0.4303405095334739\n",
            "Round: 55 Weight: [0.95477012 0.48548405] Bias: -0.40088963370523173 loss: 0.4287553140404297\n",
            "Round: 56 Weight: [0.96452506 0.49007514] Bias: -0.40677205476656764 loss: 0.4272146229111269\n",
            "Round: 57 Weight: [0.97415032 0.49460153] Bias: -0.41256472833098284 loss: 0.4257166943462941\n",
            "Round: 58 Weight: [0.98364907 0.49906499] Bias: -0.41826984501824693 loss: 0.42425987339101434\n",
            "Round: 59 Weight: [0.99302437 0.50346724] Bias: -0.4238895223521594 loss: 0.4228425867501253\n",
            "Round: 60 Weight: [1.00227917 0.50780993] Bias: -0.42942580779813655 loss: 0.4214633379585312\n",
            "Round: 61 Weight: [1.01141632 0.51209465] Bias: -0.43488068165487415 loss: 0.4201207028794857\n",
            "Round: 62 Weight: [1.02043856 0.51632293] Bias: -0.4402560598075629 loss: 0.4188133255061079\n",
            "Round: 63 Weight: [1.02934856 0.52049622] Bias: -0.445553796349779 loss: 0.41753991404340646\n",
            "Round: 64 Weight: [1.03814888 0.52461593] Bias: -0.45077568608082424 loss: 0.4162992372499281\n",
            "Round: 65 Weight: [1.04684198 0.52868344] Bias: -0.45592346688495267 loss: 0.41509012101983034\n",
            "Round: 66 Weight: [1.05543028 0.53270003] Bias: -0.4609988219985945 loss: 0.41391144518772366\n",
            "Round: 67 Weight: [1.06391609 0.53666698] Bias: -0.46600338217137355 loss: 0.41276214054003535\n",
            "Round: 68 Weight: [1.07230164 0.5405855 ] Bias: -0.47093872772641215 loss: 0.4116411860179407\n",
            "Round: 69 Weight: [1.08058912 0.54445675] Bias: -0.4758063905251284 loss: 0.4105476060980889\n",
            "Round: 70 Weight: [1.08878061 0.54828187] Bias: -0.48060785584145377 loss: 0.4094804683384344\n",
            "Round: 71 Weight: [1.09687815 0.55206195] Bias: -0.48534456415013627 loss: 0.4084388810774743\n",
            "Round: 72 Weight: [1.10488371 0.55579803] Bias: -0.490017912833543 loss: 0.4074219912761045\n",
            "Round: 73 Weight: [1.1127992  0.55949114] Bias: -0.49462925781113726 loss: 0.4064289824921366\n",
            "Round: 74 Weight: [1.12062646 0.56314225] Bias: -0.49917991509557963 loss: 0.40545907297828476\n",
            "Round: 75 Weight: [1.1283673 0.5667523] Bias: -0.5036711622791877 loss: 0.40451151389513085\n",
            "Round: 76 Weight: [1.13602344 0.57032222] Bias: -0.5081042399542858 loss: 0.40358558763122016\n",
            "Round: 77 Weight: [1.14359657 0.57385289] Bias: -0.5124803530707828 loss: 0.40268060622303087\n",
            "Round: 78 Weight: [1.15108834 0.57734515] Bias: -0.5168006722341371 loss: 0.4017959098681033\n",
            "Round: 79 Weight: [1.15850032 0.58079985] Bias: -0.5210663349466914 loss: 0.40093086552511165\n",
            "Round: 80 Weight: [1.16583407 0.58421779] Bias: -0.5252784467952016 loss: 0.4000848655951235\n",
            "Round: 81 Weight: [1.17309108 0.58759972] Bias: -0.5294380825872281 loss: 0.39925732667871133\n",
            "Round: 82 Weight: [1.1802728  0.59094642] Bias: -0.5335462874389141 loss: 0.3984476884039679\n",
            "Round: 83 Weight: [1.18738064 0.59425859] Bias: -0.5376040778165381 loss: 0.3976554123208386\n",
            "Round: 84 Weight: [1.19441599 0.59753696] Bias: -0.5416124425340999 loss: 0.39687998085751064\n",
            "Round: 85 Weight: [1.20138017 0.60078219] Bias: -0.5455723437090766 loss: 0.3961208963349014\n",
            "Round: 86 Weight: [1.2082745  0.60399495] Bias: -0.5494847176783694 loss: 0.3953776800355736\n",
            "Round: 87 Weight: [1.21510022 0.60717589] Bias: -0.5533504758763574 loss: 0.3946498713236568\n",
            "Round: 88 Weight: [1.22185857 0.61032562] Bias: -0.5571705056768684 loss: 0.3939370268125988\n",
            "Round: 89 Weight: [1.22855074 0.61344474] Bias: -0.5609456712007821 loss: 0.3932387195777878\n",
            "Round: 90 Weight: [1.2351779  0.61653385] Bias: -0.5646768140908903 loss: 0.3925545384112913\n",
            "Round: 91 Weight: [1.24174119 0.61959351] Bias: -0.568364754255554 loss: 0.39188408711614614\n",
            "Round: 92 Weight: [1.2482417  0.62262427] Bias: -0.5720102905826133 loss: 0.39122698383780585\n",
            "Round: 93 Weight: [1.25468052 0.62562667] Bias: -0.5756142016249334 loss: 0.39058286043051843\n",
            "Round: 94 Weight: [1.26105869 0.62860123] Bias: -0.5791772462588958 loss: 0.38995136185654977\n",
            "Round: 95 Weight: [1.26737723 0.63154845] Bias: -0.5827001643170766 loss: 0.3893321456163125\n",
            "Round: 96 Weight: [1.27363713 0.63446883] Bias: -0.58618367719629 loss: 0.388724881207585\n",
            "Round: 97 Weight: [1.27983937 0.63736285] Bias: -0.5896284884421138 loss: 0.3881292496121252\n",
            "Round: 98 Weight: [1.2859849  0.64023097] Bias: -0.5930352843109571 loss: 0.3875449428080946\n",
            "Round: 99 Weight: [1.29207463 0.64307364] Bias: -0.5964047343106779 loss: 0.38697166330680965\n",
            "Round: 100 Weight: [1.29810947 0.6458913 ] Bias: -0.5997374917207037 loss: 0.3864091237124336\n",
            "Round: 101 Weight: [1.30409029 0.64868438] Bias: -0.6030341940925644 loss: 0.38585704630331025\n",
            "Round: 102 Weight: [1.31001795 0.6514533 ] Bias: -0.6062954637316985 loss: 0.3853151626337233\n",
            "Round: 103 Weight: [1.31589329 0.65419846] Bias: -0.6095219081613519 loss: 0.3847832131549409\n",
            "Round: 104 Weight: [1.32171713 0.65692026] Bias: -0.6127141205693472 loss: 0.3842609468544773\n",
            "Round: 105 Weight: [1.32749026 0.65961908] Bias: -0.6158726802384643 loss: 0.3837481209125699\n",
            "Round: 106 Weight: [1.33321347 0.6622953 ] Bias: -0.6189981529611357 loss: 0.3832445003749299\n",
            "Round: 107 Weight: [1.33888751 0.66494928] Bias: -0.6220910914391256 loss: 0.3827498578408848\n",
            "Round: 108 Weight: [1.34451312 0.66758138] Bias: -0.62515203566883 loss: 0.3822639731660836\n",
            "Round: 109 Weight: [1.35009104 0.67019194] Bias: -0.628181513312805 loss: 0.38178663317898515\n",
            "Round: 110 Weight: [1.35562198 0.67278131] Bias: -0.6311800400580986 loss: 0.38131763141039776\n",
            "Round: 111 Weight: [1.36110663 0.67534982] Bias: -0.634148119961937 loss: 0.380856767835381\n",
            "Round: 112 Weight: [1.36654566 0.67789778] Bias: -0.6370862457852892 loss: 0.3804038486268632\n",
            "Round: 113 Weight: [1.37193975 0.68042551] Bias: -0.6399948993148072 loss: 0.3799586859203626\n",
            "Round: 114 Weight: [1.37728953 0.68293332] Bias: -0.6428745516736196 loss: 0.3795210975892412\n",
            "Round: 115 Weight: [1.38259566 0.6854215 ] Bias: -0.6457256636214288 loss: 0.37909090702994735\n",
            "Round: 116 Weight: [1.38785875 0.68789035] Bias: -0.6485486858443471 loss: 0.3786679429567403\n",
            "Round: 117 Weight: [1.3930794  0.69034016] Bias: -0.6513440592348821 loss: 0.3782520392054142\n",
            "Round: 118 Weight: [1.39825821 0.6927712 ] Bias: -0.6541122151624658 loss: 0.3778430345455715\n",
            "Round: 119 Weight: [1.40339577 0.69518374] Bias: -0.6568535757349009 loss: 0.37744077250101393\n",
            "Round: 120 Weight: [1.40849265 0.69757806] Bias: -0.659568554051086 loss: 0.3770451011778527\n",
            "Round: 121 Weight: [1.4135494 0.6999544] Bias: -0.6622575544453587 loss: 0.37665587309995374\n",
            "Round: 122 Weight: [1.41856658 0.70231303] Bias: -0.6649209727237849 loss: 0.37627294505135994\n",
            "Round: 123 Weight: [1.42354471 0.70465418] Bias: -0.6675591963927067 loss: 0.37589617792534996\n",
            "Round: 124 Weight: [1.42848432 0.70697812] Bias: -0.6701726048798464 loss: 0.37552543657981274\n",
            "Round: 125 Weight: [1.43338594 0.70928506] Bias: -0.6727615697482534 loss: 0.37516058969863414\n",
            "Round: 126 Weight: [1.43825005 0.71157525] Bias: -0.6753264549033643 loss: 0.374801509658808\n",
            "Round: 127 Weight: [1.44307716 0.71384891] Bias: -0.6778676167934392 loss: 0.37444807240300026\n",
            "Round: 128 Weight: [1.44786775 0.71610627] Bias: -0.6803854046036228 loss: 0.37410015731730917\n",
            "Round: 129 Weight: [1.45262229 0.71834753] Bias: -0.682880160443869 loss: 0.3737576471139774\n",
            "Round: 130 Weight: [1.45734125 0.72057292] Bias: -0.685352219530957 loss: 0.37342042771882517\n",
            "Round: 131 Weight: [1.46202509 0.72278263] Bias: -0.6878019103648187 loss: 0.37308838816318723\n",
            "Round: 132 Weight: [1.46667425 0.72497689] Bias: -0.6902295548993858 loss: 0.37276142048014455\n",
            "Round: 133 Weight: [1.47128918 0.72715588] Bias: -0.6926354687081572 loss: 0.37243941960485605\n",
            "Round: 134 Weight: [1.4758703  0.72931979] Bias: -0.6950199611446803 loss: 0.37212228327880253\n",
            "Round: 135 Weight: [1.48041803 0.73146883] Bias: -0.6973833354981279 loss: 0.37180991195776747\n",
            "Round: 136 Weight: [1.48493279 0.73360318] Bias: -0.6997258891441489 loss: 0.37150220872338535\n",
            "Round: 137 Weight: [1.48941499 0.73572302] Bias: -0.7020479136911615 loss: 0.37119907919810025\n",
            "Round: 138 Weight: [1.49386503 0.73782854] Bias: -0.704349695122251 loss: 0.3709004314633809\n",
            "Round: 139 Weight: [1.49828329 0.7399199 ] Bias: -0.706631513932828 loss: 0.3706061759810516\n",
            "Round: 140 Weight: [1.50267017 0.74199728] Bias: -0.7088936452641956 loss: 0.3703162255175992\n",
            "Round: 141 Weight: [1.50702604 0.74406086] Bias: -0.71113635903317 loss: 0.3700304950713288\n",
            "Round: 142 Weight: [1.51135126 0.7461108 ] Bias: -0.7133599200578902 loss: 0.36974890180224423\n",
            "Round: 143 Weight: [1.51564622 0.74814725] Bias: -0.7155645881799508 loss: 0.3694713649645347\n",
            "Round: 144 Weight: [1.51991126 0.75017039] Bias: -0.717750618382983 loss: 0.36919780584155787\n",
            "Round: 145 Weight: [1.52414673 0.75218037] Bias: -0.7199182609078059 loss: 0.3689281476832116\n",
            "Round: 146 Weight: [1.52835298 0.75417733] Bias: -0.7220677613642652 loss: 0.36866231564559393\n",
            "Round: 147 Weight: [1.53253035 0.75616144] Bias: -0.7241993608398718 loss: 0.36840023673285494\n",
            "Round: 148 Weight: [1.53667917 0.75813284] Bias: -0.7263132960053473 loss: 0.36814183974114817\n",
            "Round: 149 Weight: [1.54079978 0.76009168] Bias: -0.7284097992171811 loss: 0.36788705520459564\n",
            "Round: 150 Weight: [1.54489248 0.76203809] Bias: -0.730489098617298 loss: 0.3676358153431808\n",
            "Round: 151 Weight: [1.5489576  0.76397223] Bias: -0.7325514182299333 loss: 0.36738805401249286\n",
            "Round: 152 Weight: [1.55299545 0.76589422] Bias: -0.734596978055806 loss: 0.3671437066552443\n",
            "Round: 153 Weight: [1.55700634 0.7678042 ] Bias: -0.7366259941636809 loss: 0.3669027102544909\n",
            "Round: 154 Weight: [1.56099056 0.76970231] Bias: -0.7386386787794025 loss: 0.3666650032884848\n",
            "Round: 155 Weight: [1.56494841 0.77158867] Bias: -0.7406352403724855 loss: 0.36643052568709483\n",
            "Round: 156 Weight: [1.56888018 0.77346342] Bias: -0.7426158837403387 loss: 0.3661992187897318\n",
            "Round: 157 Weight: [1.57278616 0.77532667] Bias: -0.7445808100901999 loss: 0.3659710253047182\n",
            "Round: 158 Weight: [1.57666663 0.77717856] Bias: -0.7465302171188546 loss: 0.36574588927004575\n",
            "Round: 159 Weight: [1.58052186 0.7790192 ] Bias: -0.7484642990902087 loss: 0.3655237560154653\n",
            "Round: 160 Weight: [1.58435213 0.78084871] Bias: -0.7503832469107845 loss: 0.3653045721258583\n",
            "Round: 161 Weight: [1.5881577  0.78266721] Bias: -0.7522872482032036 loss: 0.36508828540583804\n",
            "Round: 162 Weight: [1.59193884 0.78447482] Bias: -0.7541764873777219 loss: 0.36487484484553484\n",
            "Round: 163 Weight: [1.59569581 0.78627164] Bias: -0.7560511457018764 loss: 0.36466420058751753\n",
            "Round: 164 Weight: [1.59942886 0.7880578 ] Bias: -0.7579114013683022 loss: 0.3644563038948104\n",
            "Round: 165 Weight: [1.60313824 0.78983339] Bias: -0.7597574295607774 loss: 0.36425110711996045\n",
            "Round: 166 Weight: [1.60682421 0.79159854] Bias: -0.7615894025185498 loss: 0.36404856367511823\n",
            "Round: 167 Weight: [1.61048699 0.79335333] Bias: -0.7634074895989974 loss: 0.3638486280030916\n",
            "Round: 168 Weight: [1.61412684 0.79509789] Bias: -0.7652118573386754 loss: 0.3636512555493373\n",
            "Round: 169 Weight: [1.61774399 0.7968323 ] Bias: -0.7670026695127963 loss: 0.36345640273485524\n",
            "Round: 170 Weight: [1.62133867 0.79855668] Bias: -0.7687800871931921 loss: 0.36326402692995025\n",
            "Round: 171 Weight: [1.62491111 0.80027111] Bias: -0.7705442688048038 loss: 0.3630740864288318\n",
            "Round: 172 Weight: [1.62846153 0.8019757 ] Bias: -0.7722953701807417 loss: 0.36288654042501906\n",
            "Round: 173 Weight: [1.63199016 0.80367055] Bias: -0.7740335446159599 loss: 0.3627013489875221\n",
            "Round: 174 Weight: [1.63549721 0.80535575] Bias: -0.7757589429195851 loss: 0.3625184730377708\n",
            "Round: 175 Weight: [1.63898291 0.80703139] Bias: -0.7774717134659411 loss: 0.36233787432726594\n",
            "Round: 176 Weight: [1.64244745 0.80869756] Bias: -0.7791720022443045 loss: 0.36215951541592384\n",
            "Round: 177 Weight: [1.64589106 0.81035436] Bias: -0.7808599529074315 loss: 0.3619833596510913\n",
            "Round: 178 Weight: [1.64931393 0.81200187] Bias: -0.7825357068188901 loss: 0.36180937114720707\n",
            "Round: 179 Weight: [1.65271627 0.81364018] Bias: -0.7841994030992323 loss: 0.36163751476608574\n",
            "Round: 180 Weight: [1.65609828 0.81526938] Bias: -0.7858511786710404 loss: 0.36146775609780313\n",
            "Round: 181 Weight: [1.65946015 0.81688955] Bias: -0.7874911683028789 loss: 0.3613000614421608\n",
            "Round: 182 Weight: [1.66280208 0.81850077] Bias: -0.7891195046521841 loss: 0.36113439779071127\n",
            "Round: 183 Weight: [1.66612427 0.82010314] Bias: -0.7907363183071205 loss: 0.3609707328093219\n",
            "Round: 184 Weight: [1.66942689 0.82169672] Bias: -0.7923417378274352 loss: 0.36080903482126087\n",
            "Round: 185 Weight: [1.67271014 0.82328161] Bias: -0.7939358897843358 loss: 0.3606492727907867\n",
            "Round: 186 Weight: [1.6759742  0.82485787] Bias: -0.7955188987994217 loss: 0.3604914163072227\n",
            "Round: 187 Weight: [1.67921924 0.82642558] Bias: -0.7970908875826939 loss: 0.3603354355695016\n",
            "Round: 188 Weight: [1.68244546 0.82798483] Bias: -0.7986519769696693 loss: 0.3601813013711636\n",
            "Round: 189 Weight: [1.68565301 0.82953569] Bias: -0.8002022859576245 loss: 0.36002898508579195\n",
            "Round: 190 Weight: [1.68884208 0.83107823] Bias: -0.8017419317409928 loss: 0.3598784586528718\n",
            "Round: 191 Weight: [1.69201284 0.83261253] Bias: -0.8032710297459372 loss: 0.3597296945640584\n",
            "Round: 192 Weight: [1.69516545 0.83413865] Bias: -0.8047896936641233 loss: 0.35958266584984055\n",
            "Round: 193 Weight: [1.69830009 0.83565668] Bias: -0.806298035485713 loss: 0.35943734606658606\n",
            "Round: 194 Weight: [1.70141691 0.83716667] Bias: -0.8077961655315994 loss: 0.3592937092839567\n",
            "Round: 195 Weight: [1.70451607 0.8386687 ] Bias: -0.809284192484905 loss: 0.35915173007268114\n",
            "Round: 196 Weight: [1.70759774 0.84016284] Bias: -0.8107622234217621 loss: 0.35901138349267236\n",
            "Round: 197 Weight: [1.71066208 0.84164916] Bias: -0.812230363841394 loss: 0.35887264508148076\n",
            "Round: 198 Weight: [1.71370923 0.84312772] Bias: -0.8136887176955173 loss: 0.3587354908430694\n",
            "Round: 199 Weight: [1.71673936 0.84459858] Bias: -0.8151373874170817 loss: 0.35859989723690333\n",
            "Round: 200 Weight: [1.71975261 0.84606182] Bias: -0.816576473948366 loss: 0.3584658411673411\n",
            "Round: 201 Weight: [1.72274913 0.84751749] Bias: -0.8180060767684456 loss: 0.35833329997331975\n",
            "Round: 202 Weight: [1.72572907 0.84896567] Bias: -0.8194262939200513 loss: 0.35820225141832357\n",
            "Round: 203 Weight: [1.72869257 0.8504064 ] Bias: -0.8208372220358304 loss: 0.35807267368062784\n",
            "Round: 204 Weight: [1.73163979 0.85183976] Bias: -0.8222389563640308 loss: 0.3579445453438078\n",
            "Round: 205 Weight: [1.73457085 0.85326579] Bias: -0.8236315907936188 loss: 0.3578178453875068\n",
            "Round: 206 Weight: [1.7374859  0.85468458] Bias: -0.8250152178788484 loss: 0.3576925531784527\n",
            "Round: 207 Weight: [1.74038508 0.85609616] Bias: -0.8263899288632934 loss: 0.3575686484617166\n",
            "Round: 208 Weight: [1.74326853 0.85750061] Bias: -0.8277558137033593 loss: 0.35744611135220594\n",
            "Round: 209 Weight: [1.74613637 0.85889797] Bias: -0.8291129610912843 loss: 0.35732492232638446\n",
            "Round: 210 Weight: [1.74898874 0.86028831] Bias: -0.8304614584776463 loss: 0.3572050622142121\n",
            "Round: 211 Weight: [1.75182577 0.86167168] Bias: -0.8318013920933855 loss: 0.3570865121912986\n",
            "Round: 212 Weight: [1.7546476  0.86304813] Bias: -0.8331328469713568 loss: 0.356969253771263\n",
            "Round: 213 Weight: [1.75745434 0.86441773] Bias: -0.8344559069674218 loss: 0.35685326879829443\n",
            "Round: 214 Weight: [1.76024613 0.86578052] Bias: -0.8357706547810938 loss: 0.3567385394399064\n",
            "Round: 215 Weight: [1.76302309 0.86713656] Bias: -0.8370771719757463 loss: 0.3566250481798807\n",
            "Round: 216 Weight: [1.76578535 0.8684859 ] Bias: -0.8383755389983949 loss: 0.3565127778113928\n",
            "Round: 217 Weight: [1.76853302 0.86982859] Bias: -0.8396658351990647 loss: 0.3564017114303154\n",
            "Round: 218 Weight: [1.77126622 0.87116469] Bias: -0.8409481388497521 loss: 0.35629183242869406\n",
            "Round: 219 Weight: [1.77398508 0.87249424] Bias: -0.8422225271629915 loss: 0.35618312448838907\n",
            "Round: 220 Weight: [1.77668971 0.8738173 ] Bias: -0.8434890763100372 loss: 0.35607557157487996\n",
            "Round: 221 Weight: [1.77938022 0.87513391] Bias: -0.8447478614386683 loss: 0.35596915793122713\n",
            "Round: 222 Weight: [1.78205674 0.87644413] Bias: -0.8459989566906271 loss: 0.3558638680721857\n",
            "Round: 223 Weight: [1.78471937 0.877748  ] Bias: -0.8472424352186991 loss: 0.3557596867784677\n",
            "Round: 224 Weight: [1.78736823 0.87904557] Bias: -0.8484783692034444 loss: 0.35565659909114855\n",
            "Round: 225 Weight: [1.79000342 0.88033688] Bias: -0.8497068298695866 loss: 0.3555545903062121\n",
            "Round: 226 Weight: [1.79262506 0.88162199] Bias: -0.8509278875020696 loss: 0.35545364596923257\n",
            "Round: 227 Weight: [1.79523325 0.88290094] Bias: -0.8521416114617897 loss: 0.355353751870187\n",
            "Round: 228 Weight: [1.79782811 0.88417378] Bias: -0.8533480702010092 loss: 0.3552548940383967\n",
            "Round: 229 Weight: [1.80040973 0.88544055] Bias: -0.8545473312784618 loss: 0.35515705873759235\n",
            "Round: 230 Weight: [1.80297821 0.88670129] Bias: -0.8557394613741537 loss: 0.35506023246109986\n",
            "Round: 231 Weight: [1.80553367 0.88795605] Bias: -0.8569245263038705 loss: 0.3549644019271438\n",
            "Round: 232 Weight: [1.80807621 0.88920488] Bias: -0.8581025910333954 loss: 0.3548695540742649\n",
            "Round: 233 Weight: [1.81060592 0.89044781] Bias: -0.8592737196924451 loss: 0.35477567605684823\n",
            "Round: 234 Weight: [1.8131229  0.89168489] Bias: -0.8604379755883312 loss: 0.35468275524075893\n",
            "Round: 235 Weight: [1.81562726 0.89291616] Bias: -0.8615954212193517 loss: 0.3545907791990832\n",
            "Round: 236 Weight: [1.81811908 0.89414166] Bias: -0.862746118287921 loss: 0.3544997357079703\n",
            "Round: 237 Weight: [1.82059847 0.89536144] Bias: -0.8638901277134421 loss: 0.3544096127425746\n",
            "Round: 238 Weight: [1.82306553 0.89657553] Bias: -0.8650275096449288 loss: 0.3543203984730928\n",
            "Round: 239 Weight: [1.82552033 0.89778398] Bias: -0.8661583234733826 loss: 0.35423208126089567\n",
            "Round: 240 Weight: [1.82796298 0.89898682] Bias: -0.86728262784393 loss: 0.35414464965475\n",
            "Round: 241 Weight: [1.83039358 0.90018409] Bias: -0.8684004806677258 loss: 0.3540580923871302\n",
            "Round: 242 Weight: [1.8328122  0.90137584] Bias: -0.8695119391336277 loss: 0.35397239837061506\n",
            "Round: 243 Weight: [1.83521894 0.9025621 ] Bias: -0.8706170597196471 loss: 0.35388755669436883\n",
            "Round: 244 Weight: [1.83761389 0.90374291] Bias: -0.8717158982041814 loss: 0.3538035566207043\n",
            "Round: 245 Weight: [1.83999714 0.90491831] Bias: -0.8728085096770324 loss: 0.3537203875817239\n",
            "Round: 246 Weight: [1.84236877 0.90608833] Bias: -0.8738949485502159 loss: 0.3536380391760403\n",
            "Round: 247 Weight: [1.84472887 0.90725301] Bias: -0.8749752685685669 loss: 0.35355650116556964\n",
            "Round: 248 Weight: [1.84707752 0.90841239] Bias: -0.8760495228201449 loss: 0.35347576347240034\n",
            "Round: 249 Weight: [1.84941481 0.90956651] Bias: -0.8771177637464439 loss: 0.35339581617573146\n",
            "Round: 250 Weight: [1.85174083 0.91071539] Bias: -0.878180043152411 loss: 0.3533166495088815\n",
            "Round: 251 Weight: [1.85405565 0.91185909] Bias: -0.8792364122162786 loss: 0.35323825385636437\n",
            "Round: 252 Weight: [1.85635935 0.91299762] Bias: -0.8802869214992128 loss: 0.3531606197510312\n",
            "Round: 253 Weight: [1.85865202 0.91413103] Bias: -0.8813316209547842 loss: 0.3530837378712765\n",
            "Round: 254 Weight: [1.86093373 0.91525934] Bias: -0.8823705599382624 loss: 0.3530075990383063\n",
            "Round: 255 Weight: [1.86320457 0.91638261] Bias: -0.8834037872157402 loss: 0.3529321942134679\n",
            "Round: 256 Weight: [1.86546461 0.91750085] Bias: -0.8844313509730897 loss: 0.3528575144956374\n",
            "Round: 257 Weight: [1.86771393 0.9186141 ] Bias: -0.8854532988247548 loss: 0.35278355111866727\n",
            "Round: 258 Weight: [1.86995261 0.91972239] Bias: -0.8864696778223832 loss: 0.3527102954488876\n",
            "Round: 259 Weight: [1.87218072 0.92082576] Bias: -0.8874805344633011 loss: 0.3526377389826644\n",
            "Round: 260 Weight: [1.87439834 0.92192424] Bias: -0.8884859146988348 loss: 0.3525658733440095\n",
            "Round: 261 Weight: [1.87660553 0.92301786] Bias: -0.889485863942481 loss: 0.3524946902822443\n",
            "Round: 262 Weight: [1.87880238 0.92410665] Bias: -0.890480427077931 loss: 0.3524241816697124\n",
            "Round: 263 Weight: [1.88098896 0.92519065] Bias: -0.8914696484669496 loss: 0.3523543394995436\n",
            "Round: 264 Weight: [1.88316533 0.92626988] Bias: -0.8924535719571141 loss: 0.35228515588346443\n",
            "Round: 265 Weight: [1.88533158 0.92734437] Bias: -0.8934322408894135 loss: 0.3522166230496571\n",
            "Round: 266 Weight: [1.88748776 0.92841417] Bias: -0.8944056981057146 loss: 0.35214873334066343\n",
            "Round: 267 Weight: [1.88963396 0.92947929] Bias: -0.8953739859560934 loss: 0.35208147921133415\n",
            "Round: 268 Weight: [1.89177023 0.93053976] Bias: -0.8963371463060386 loss: 0.35201485322682086\n",
            "Round: 269 Weight: [1.89389665 0.93159562] Bias: -0.8972952205435265 loss: 0.351948848060612\n",
            "Round: 270 Weight: [1.89601328 0.9326469 ] Bias: -0.8982482495859732 loss: 0.351883456492609\n",
            "Round: 271 Weight: [1.8981202  0.93369362] Bias: -0.899196273887063 loss: 0.35181867140724365\n",
            "Round: 272 Weight: [1.90021746 0.93473581] Bias: -0.9001393334434594 loss: 0.3517544857916346\n",
            "Round: 273 Weight: [1.90230513 0.9357735 ] Bias: -0.9010774678013975 loss: 0.3516908927337828\n",
            "Round: 274 Weight: [1.90438328 0.93680672] Bias: -0.9020107160631629 loss: 0.35162788542080425\n",
            "Round: 275 Weight: [1.90645198 0.9378355 ] Bias: -0.9029391168934576 loss: 0.35156545713719944\n",
            "Round: 276 Weight: [1.90851128 0.93885987] Bias: -0.9038627085256572 loss: 0.3515036012631589\n",
            "Round: 277 Weight: [1.91056125 0.93987985] Bias: -0.9047815287679586 loss: 0.3514423112729033\n",
            "Round: 278 Weight: [1.91260195 0.94089547] Bias: -0.9056956150094235 loss: 0.3513815807330582\n",
            "Round: 279 Weight: [1.91463344 0.94190675] Bias: -0.906605004225918 loss: 0.35132140330106165\n",
            "Round: 280 Weight: [1.91665579 0.94291373] Bias: -0.907509732985951 loss: 0.3512617727236043\n",
            "Round: 281 Weight: [1.91866905 0.94391642] Bias: -0.9084098374564121 loss: 0.3512026828351022\n",
            "Round: 282 Weight: [1.92067329 0.94491487] Bias: -0.9093053534082146 loss: 0.3511441275561988\n",
            "Round: 283 Weight: [1.92266856 0.94590908] Bias: -0.9101963162218399 loss: 0.35108610089229925\n",
            "Round: 284 Weight: [1.92465492 0.94689909] Bias: -0.911082760892791 loss: 0.35102859693213273\n",
            "Round: 285 Weight: [1.92663244 0.94788493] Bias: -0.9119647220369527 loss: 0.3509716098463447\n",
            "Round: 286 Weight: [1.92860117 0.94886661] Bias: -0.9128422338958622 loss: 0.35091513388611634\n",
            "Round: 287 Weight: [1.93056116 0.94984417] Bias: -0.9137153303418921 loss: 0.35085916338181267\n",
            "Round: 288 Weight: [1.93251248 0.95081763] Bias: -0.9145840448833462 loss: 0.350803692741657\n",
            "Round: 289 Weight: [1.93445518 0.951787  ] Bias: -0.9154484106694709 loss: 0.35074871645043104\n",
            "Round: 290 Weight: [1.93638931 0.95275233] Bias: -0.9163084604953835 loss: 0.3506942290682023\n",
            "Round: 291 Weight: [1.93831493 0.95371362] Bias: -0.9171642268069186 loss: 0.3506402252290751\n",
            "Round: 292 Weight: [1.9402321  0.95467092] Bias: -0.9180157417053952 loss: 0.3505866996399668\n",
            "Round: 293 Weight: [1.94214086 0.95562423] Bias: -0.9188630369523051 loss: 0.3505336470794078\n",
            "Round: 294 Weight: [1.94404128 0.95657358] Bias: -0.9197061439739239 loss: 0.35048106239636523\n",
            "Round: 295 Weight: [1.94593341 0.957519  ] Bias: -0.9205450938658476 loss: 0.35042894050908946\n",
            "Round: 296 Weight: [1.94781729 0.9584605 ] Bias: -0.9213799173974543 loss: 0.3503772764039824\n",
            "Round: 297 Weight: [1.94969299 0.95939812] Bias: -0.9222106450162936 loss: 0.3503260651344887\n",
            "Round: 298 Weight: [1.95156054 0.96033188] Bias: -0.9230373068524051 loss: 0.35027530182000755\n",
            "Round: 299 Weight: [1.95342001 0.96126179] Bias: -0.923859932722567 loss: 0.35022498164482585\n",
            "Round: 300 Weight: [1.95527145 0.96218788] Bias: -0.9246785521344751 loss: 0.35017509985707135\n",
            "Round: 301 Weight: [1.9571149  0.96311017] Bias: -0.9254931942908566 loss: 0.35012565176768634\n",
            "Round: 302 Weight: [1.95895041 0.96402868] Bias: -0.926303888093516 loss: 0.3500766327494206\n",
            "Round: 303 Weight: [1.96077804 0.96494344] Bias: -0.9271106621473172 loss: 0.3500280382358431\n",
            "Round: 304 Weight: [1.96259783 0.96585447] Bias: -0.9279135447641016 loss: 0.3499798637203737\n",
            "Round: 305 Weight: [1.96440983 0.96676179] Bias: -0.9287125639665447 loss: 0.349932104755331\n",
            "Round: 306 Weight: [1.96621409 0.96766541] Bias: -0.9295077474919502 loss: 0.3498847569510006\n",
            "Round: 307 Weight: [1.96801066 0.96856537] Bias: -0.9302991227959854 loss: 0.3498378159747185\n",
            "Round: 308 Weight: [1.96979958 0.96946167] Bias: -0.9310867170563564 loss: 0.3497912775499735\n",
            "Round: 309 Weight: [1.97158091 0.97035435] Bias: -0.9318705571764263 loss: 0.34974513745552505\n",
            "Round: 310 Weight: [1.97335468 0.97124342] Bias: -0.9326506697887762 loss: 0.349699391524538\n",
            "Round: 311 Weight: [1.97512094 0.97212891] Bias: -0.9334270812587105 loss: 0.34965403564373393\n",
            "Round: 312 Weight: [1.97687975 0.97301082] Bias: -0.9341998176877077 loss: 0.34960906575255696\n",
            "Round: 313 Weight: [1.97863113 0.97388919] Bias: -0.9349689049168166 loss: 0.34956447784235595\n",
            "Round: 314 Weight: [1.98037515 0.97476404] Bias: -0.9357343685300012 loss: 0.349520267955581\n",
            "Round: 315 Weight: [1.98211184 0.97563538] Bias: -0.9364962338574322 loss: 0.3494764321849956\n",
            "Round: 316 Weight: [1.98384125 0.97650322] Bias: -0.9372545259787285 loss: 0.3494329666729021\n",
            "Round: 317 Weight: [1.98556342 0.9773676 ] Bias: -0.9380092697261488 loss: 0.34938986761038177\n",
            "Round: 318 Weight: [1.98727839 0.97822854] Bias: -0.9387604896877337 loss: 0.3493471312365491\n",
            "Round: 319 Weight: [1.98898621 0.97908604] Bias: -0.9395082102103998 loss: 0.34930475383781856\n",
            "Round: 320 Weight: [1.99068692 0.97994013] Bias: -0.9402524554029862 loss: 0.34926273174718575\n",
            "Round: 321 Weight: [1.99238056 0.98079083] Bias: -0.9409932491392555 loss: 0.3492210613435203\n",
            "Round: 322 Weight: [1.99406718 0.98163815] Bias: -0.9417306150608478 loss: 0.34917973905087263\n",
            "Round: 323 Weight: [1.99574681 0.98248212] Bias: -0.9424645765801904 loss: 0.3491387613377924\n",
            "Round: 324 Weight: [1.9974195  0.98332276] Bias: -0.9431951568833644 loss: 0.3490981247166589\n",
            "Round: 325 Weight: [1.99908528 0.98416007] Bias: -0.943922378932926 loss: 0.3490578257430245\n",
            "Round: 326 Weight: [2.0007442  0.98499409] Bias: -0.944646265470687 loss: 0.34901786101496834\n",
            "Round: 327 Weight: [2.0023963  0.98582482] Bias: -0.9453668390204532 loss: 0.34897822717246213\n",
            "Round: 328 Weight: [2.00404162 0.98665228] Bias: -0.946084121890721 loss: 0.3489389208967476\n",
            "Round: 329 Weight: [2.00568019 0.9874765 ] Bias: -0.9467981361773347 loss: 0.3488999389097237\n",
            "Round: 330 Weight: [2.00731206 0.98829749] Bias: -0.9475089037661032 loss: 0.348861277973346\n",
            "Round: 331 Weight: [2.00893727 0.98911527] Bias: -0.9482164463353788 loss: 0.34882293488903504\n",
            "Round: 332 Weight: [2.01055584 0.98992985] Bias: -0.9489207853585968 loss: 0.3487849064970964\n",
            "Round: 333 Weight: [2.01216783 0.99074126] Bias: -0.9496219421067781 loss: 0.34874718967615026\n",
            "Round: 334 Weight: [2.01377327 0.9915495 ] Bias: -0.9503199376509944 loss: 0.3487097813425702\n",
            "Round: 335 Weight: [2.01537219 0.9923546 ] Bias: -0.9510147928647982 loss: 0.34867267844993316\n",
            "Round: 336 Weight: [2.01696464 0.99315657] Bias: -0.9517065284266151 loss: 0.34863587798847756\n",
            "Round: 337 Weight: [2.01855065 0.99395544] Bias: -0.9523951648221031 loss: 0.3485993769845715\n",
            "Round: 338 Weight: [2.02013026 0.9947512 ] Bias: -0.9530807223464763 loss: 0.3485631725001898\n",
            "Round: 339 Weight: [2.0217035  0.99554389] Bias: -0.953763221106795 loss: 0.3485272616323997\n",
            "Round: 340 Weight: [2.02327041 0.99633352] Bias: -0.954442681024222 loss: 0.3484916415128565\n",
            "Round: 341 Weight: [2.02483102 0.9971201 ] Bias: -0.9551191218362475 loss: 0.34845630930730587\n",
            "Round: 342 Weight: [2.02638538 0.99790365] Bias: -0.9557925630988799 loss: 0.3484212622150964\n",
            "Round: 343 Weight: [2.02793351 0.99868419] Bias: -0.956463024188807 loss: 0.3483864974686996\n",
            "Round: 344 Weight: [2.02947545 0.99946173] Bias: -0.957130524305524 loss: 0.3483520123332376\n",
            "Round: 345 Weight: [2.03101124 1.00023628] Bias: -0.9577950824734329 loss: 0.3483178041060199\n",
            "Round: 346 Weight: [2.03254091 1.00100787] Bias: -0.9584567175439102 loss: 0.3482838701160871\n",
            "Round: 347 Weight: [2.03406449 1.00177651] Bias: -0.9591154481973458 loss: 0.34825020772376175\n",
            "Round: 348 Weight: [2.03558202 1.00254221] Bias: -0.9597712929451535 loss: 0.34821681432020846\n",
            "Round: 349 Weight: [2.03709353 1.00330499] Bias: -0.9604242701317509 loss: 0.34818368732699956\n",
            "Round: 350 Weight: [2.03859906 1.00406487] Bias: -0.9610743979365132 loss: 0.3481508241956886\n",
            "Round: 351 Weight: [2.04009863 1.00482185] Bias: -0.9617216943756983 loss: 0.34811822240739165\n",
            "Round: 352 Weight: [2.04159228 1.00557596] Bias: -0.962366177304345 loss: 0.34808587947237396\n",
            "Round: 353 Weight: [2.04308005 1.0063272 ] Bias: -0.9630078644181443 loss: 0.34805379292964483\n",
            "Round: 354 Weight: [2.04456196 1.0070756 ] Bias: -0.9636467732552845 loss: 0.3480219603465587\n",
            "Round: 355 Weight: [2.04603804 1.00782117] Bias: -0.9642829211982702 loss: 0.34799037931842247\n",
            "Round: 356 Weight: [2.04750834 1.00856392] Bias: -0.9649163254757164 loss: 0.3479590474681093\n",
            "Round: 357 Weight: [2.04897287 1.00930386] Bias: -0.9655470031641167 loss: 0.3479279624456792\n",
            "Round: 358 Weight: [2.05043168 1.01004101] Bias: -0.9661749711895877 loss: 0.3478971219280055\n",
            "Round: 359 Weight: [2.05188479 1.01077539] Bias: -0.9668002463295887 loss: 0.3478665236184068\n",
            "Round: 360 Weight: [2.05333223 1.01150701] Bias: -0.9674228452146174 loss: 0.3478361652462861\n",
            "Round: 361 Weight: [2.05477404 1.01223588] Bias: -0.9680427843298828 loss: 0.3478060445667745\n",
            "Round: 362 Weight: [2.05621023 1.01296202] Bias: -0.9686600800169541 loss: 0.34777615936038137\n",
            "Round: 363 Weight: [2.05764086 1.01368543] Bias: -0.9692747484753881 loss: 0.34774650743265023\n",
            "Round: 364 Weight: [2.05906594 1.01440614] Bias: -0.9698868057643328 loss: 0.34771708661381934\n",
            "Round: 365 Weight: [2.0604855  1.01512416] Bias: -0.9704962678041104 loss: 0.34768789475848877\n",
            "Round: 366 Weight: [2.06189957 1.0158395 ] Bias: -0.9711031503777774 loss: 0.3476589297452917\n",
            "Round: 367 Weight: [2.06330819 1.01655217] Bias: -0.9717074691326647 loss: 0.34763018947657204\n",
            "Round: 368 Weight: [2.06471137 1.01726219] Bias: -0.9723092395818956 loss: 0.34760167187806607\n",
            "Round: 369 Weight: [2.06610916 1.01796957] Bias: -0.972908477105884 loss: 0.3475733748985899\n",
            "Round: 370 Weight: [2.06750157 1.01867432] Bias: -0.9735051969538117 loss: 0.3475452965097318\n",
            "Round: 371 Weight: [2.06888864 1.01937646] Bias: -0.9740994142450861 loss: 0.3475174347055487\n",
            "Round: 372 Weight: [2.0702704 1.020076 ] Bias: -0.9746911439707783 loss: 0.3474897875022682\n",
            "Round: 373 Weight: [2.07164687 1.02077295] Bias: -0.9752804009950415 loss: 0.34746235293799493\n",
            "Round: 374 Weight: [2.07301808 1.02146732] Bias: -0.9758672000565107 loss: 0.3474351290724216\n",
            "Round: 375 Weight: [2.07438405 1.02215914] Bias: -0.9764515557696835 loss: 0.34740811398654414\n",
            "Round: 376 Weight: [2.07574482 1.0228484 ] Bias: -0.9770334826262822 loss: 0.347381305782382\n",
            "Round: 377 Weight: [2.07710042 1.02353513] Bias: -0.9776129949965985 loss: 0.34735470258270235\n",
            "Round: 378 Weight: [2.07845086 1.02421933] Bias: -0.9781901071308193 loss: 0.3473283025307481\n",
            "Round: 379 Weight: [2.07979618 1.02490101] Bias: -0.9787648331603358 loss: 0.3473021037899711\n",
            "Round: 380 Weight: [2.0811364 1.0255802] Bias: -0.9793371870990345 loss: 0.3472761045437689\n",
            "Round: 381 Weight: [2.08247155 1.0262569 ] Bias: -0.9799071828445719 loss: 0.34725030299522514\n",
            "Round: 382 Weight: [2.08380165 1.02693112] Bias: -0.9804748341796317 loss: 0.34722469736685485\n",
            "Round: 383 Weight: [2.08512674 1.02760287] Bias: -0.9810401547731659 loss: 0.34719928590035276\n",
            "Round: 384 Weight: [2.08644683 1.02827218] Bias: -0.9816031581816195 loss: 0.34717406685634633\n",
            "Round: 385 Weight: [2.08776195 1.02893904] Bias: -0.9821638578501392 loss: 0.34714903851415124\n",
            "Round: 386 Weight: [2.08907213 1.02960347] Bias: -0.9827222671137658 loss: 0.3471241991715324\n",
            "Round: 387 Weight: [2.09037739 1.03026549] Bias: -0.9832783991986122 loss: 0.34709954714446645\n",
            "Round: 388 Weight: [2.09167776 1.0309251 ] Bias: -0.9838322672230246 loss: 0.3470750807669097\n",
            "Round: 389 Weight: [2.09297327 1.03158231] Bias: -0.9843838841987304 loss: 0.34705079839056857\n",
            "Round: 390 Weight: [2.09426392 1.03223715] Bias: -0.9849332630319688 loss: 0.347026698384674\n",
            "Round: 391 Weight: [2.09554977 1.03288961] Bias: -0.9854804165246097 loss: 0.3470027791357581\n",
            "Round: 392 Weight: [2.09683081 1.03353971] Bias: -0.9860253573752557 loss: 0.34697903904743604\n",
            "Round: 393 Weight: [2.09810709 1.03418746] Bias: -0.9865680981803311 loss: 0.34695547654018943\n",
            "Round: 394 Weight: [2.09937862 1.03483287] Bias: -0.987108651435157 loss: 0.34693209005115394\n",
            "Round: 395 Weight: [2.10064543 1.03547596] Bias: -0.9876470295350123 loss: 0.3469088780339096\n",
            "Round: 396 Weight: [2.10190753 1.03611672] Bias: -0.9881832447761806 loss: 0.34688583895827463\n",
            "Round: 397 Weight: [2.10316497 1.03675519] Bias: -0.988717309356985 loss: 0.3468629713101016\n",
            "Round: 398 Weight: [2.10441775 1.03739136] Bias: -0.9892492353788089 loss: 0.34684027359107755\n",
            "Round: 399 Weight: [2.1056659  1.03802524] Bias: -0.9897790348471038 loss: 0.346817744318526\n",
            "Round: 400 Weight: [2.10690945 1.03865686] Bias: -0.9903067196723846 loss: 0.34679538202521326\n",
            "Round: 401 Weight: [2.10814842 1.03928621] Bias: -0.9908323016712122 loss: 0.34677318525915546\n",
            "Round: 402 Weight: [2.10938282 1.03991331] Bias: -0.9913557925671638 loss: 0.3467511525834309\n",
            "Round: 403 Weight: [2.11061269 1.04053816] Bias: -0.9918772039917909 loss: 0.3467292825759931\n",
            "Round: 404 Weight: [2.11183804 1.04116079] Bias: -0.9923965474855653 loss: 0.34670757382948764\n",
            "Round: 405 Weight: [2.11305889 1.0417812 ] Bias: -0.992913834498813 loss: 0.34668602495107137\n",
            "Round: 406 Weight: [2.11427528 1.04239939] Bias: -0.9934290763926368 loss: 0.34666463456223423\n",
            "Round: 407 Weight: [2.11548722 1.04301539] Bias: -0.9939422844398271 loss: 0.3466434012986235\n",
            "Round: 408 Weight: [2.11669473 1.0436292 ] Bias: -0.9944534698257618 loss: 0.3466223238098709\n",
            "Round: 409 Weight: [2.11789783 1.04424082] Bias: -0.9949626436492941 loss: 0.34660140075942203\n",
            "Round: 410 Weight: [2.11909655 1.04485028] Bias: -0.9954698169236303 loss: 0.34658063082436813\n",
            "Round: 411 Weight: [2.12029091 1.04545758] Bias: -0.9959750005771962 loss: 0.34656001269528003\n",
            "Round: 412 Weight: [2.12148092 1.04606273] Bias: -0.9964782054544927 loss: 0.3465395450760457\n",
            "Round: 413 Weight: [2.12266662 1.04666573] Bias: -0.9969794423169412 loss: 0.346519226683708\n",
            "Round: 414 Weight: [2.12384801 1.04726661] Bias: -0.9974787218437184 loss: 0.34649905624830696\n",
            "Round: 415 Weight: [2.12502513 1.04786537] Bias: -0.997976054632581 loss: 0.3464790325127225\n",
            "Round: 416 Weight: [2.12619798 1.04846201] Bias: -0.9984714512006798 loss: 0.34645915423252077\n",
            "Round: 417 Weight: [2.1273666  1.04905656] Bias: -0.9989649219853649 loss: 0.34643942017580154\n",
            "Round: 418 Weight: [2.128531   1.04964901] Bias: -0.9994564773449798 loss: 0.34641982912304836\n",
            "Round: 419 Weight: [2.1296912  1.05023939] Bias: -0.9999461275596466 loss: 0.3464003798669809\n",
            "Round: 420 Weight: [2.13084723 1.05082769] Bias: -1.0004338828320418 loss: 0.3463810712124089\n",
            "Round: 421 Weight: [2.13199909 1.05141392] Bias: -1.0009197532881622 loss: 0.3463619019760885\n",
            "Round: 422 Weight: [2.13314682 1.0519981 ] Bias: -1.0014037489780814 loss: 0.3463428709865805\n",
            "Round: 423 Weight: [2.13429043 1.05258024] Bias: -1.001885879876698 loss: 0.34632397708411056\n",
            "Round: 424 Weight: [2.13542994 1.05316034] Bias: -1.0023661558844745 loss: 0.3463052191204313\n",
            "Round: 425 Weight: [2.13656538 1.05373842] Bias: -1.0028445868281664 loss: 0.34628659595868666\n",
            "Round: 426 Weight: [2.13769675 1.05431448] Bias: -1.0033211824615433 loss: 0.3462681064732773\n",
            "Round: 427 Weight: [2.13882408 1.05488853] Bias: -1.0037959524661022 loss: 0.3462497495497291\n",
            "Round: 428 Weight: [2.13994739 1.05546058] Bias: -1.0042689064517705 loss: 0.34623152408456226\n",
            "Round: 429 Weight: [2.1410667  1.05603064] Bias: -1.004740053957602 loss: 0.3462134289851628\n",
            "Round: 430 Weight: [2.14218203 1.05659872] Bias: -1.0052094044524635 loss: 0.3461954631696558\n",
            "Round: 431 Weight: [2.14329339 1.05716482] Bias: -1.0056769673357153 loss: 0.3461776255667808\n",
            "Round: 432 Weight: [2.1444008  1.05772897] Bias: -1.0061427519378805 loss: 0.34615991511576727\n",
            "Round: 433 Weight: [2.14550428 1.05829115] Bias: -1.0066067675213093 loss: 0.34614233076621415\n",
            "Round: 434 Weight: [2.14660386 1.0588514 ] Bias: -1.0070690232808335 loss: 0.34612487147796916\n",
            "Round: 435 Weight: [2.14769954 1.0594097 ] Bias: -1.0075295283444148 loss: 0.3461075362210104\n",
            "Round: 436 Weight: [2.14879135 1.05996607] Bias: -1.0079882917737844 loss: 0.3460903239753297\n",
            "Round: 437 Weight: [2.1498793  1.06052053] Bias: -1.008445322565075 loss: 0.34607323373081716\n",
            "Round: 438 Weight: [2.15096341 1.06107307] Bias: -1.0089006296494465 loss: 0.34605626448714816\n",
            "Round: 439 Weight: [2.15204371 1.06162371] Bias: -1.0093542218937035 loss: 0.34603941525367005\n",
            "Round: 440 Weight: [2.1531202  1.06217245] Bias: -1.0098061081009055 loss: 0.34602268504929284\n",
            "Round: 441 Weight: [2.15419291 1.0627193 ] Bias: -1.010256297010971 loss: 0.3460060729023788\n",
            "Round: 442 Weight: [2.15526185 1.06326428] Bias: -1.010704797301273 loss: 0.3459895778506357\n",
            "Round: 443 Weight: [2.15632703 1.06380738] Bias: -1.0111516175872297 loss: 0.3459731989410101\n",
            "Round: 444 Weight: [2.15738849 1.06434863] Bias: -1.0115967664228858 loss: 0.34595693522958243\n",
            "Round: 445 Weight: [2.15844623 1.06488802] Bias: -1.0120402523014895 loss: 0.345940785781464\n",
            "Round: 446 Weight: [2.15950027 1.06542556] Bias: -1.0124820836560615 loss: 0.3459247496706944\n",
            "Round: 447 Weight: [2.16055063 1.06596126] Bias: -1.0129222688599575 loss: 0.345908825980141\n",
            "Round: 448 Weight: [2.16159732 1.06649513] Bias: -1.0133608162274252 loss: 0.34589301380139964\n",
            "Round: 449 Weight: [2.16264037 1.06702719] Bias: -1.0137977340141533 loss: 0.3458773122346964\n",
            "Round: 450 Weight: [2.16367978 1.06755742] Bias: -1.014233030417816 loss: 0.3458617203887908\n",
            "Round: 451 Weight: [2.16471557 1.06808585] Bias: -1.01466671357861 loss: 0.34584623738088044\n",
            "Round: 452 Weight: [2.16574777 1.06861248] Bias: -1.0150987915797862 loss: 0.34583086233650656\n",
            "Round: 453 Weight: [2.16677638 1.06913732] Bias: -1.0155292724481746 loss: 0.3458155943894608\n",
            "Round: 454 Weight: [2.16780143 1.06966038] Bias: -1.0159581641547037 loss: 0.34580043268169397\n",
            "Round: 455 Weight: [2.16882293 1.07018166] Bias: -1.0163854746149146 loss: 0.34578537636322476\n",
            "Round: 456 Weight: [2.16984089 1.07070117] Bias: -1.0168112116894674 loss: 0.3457704245920507\n",
            "Round: 457 Weight: [2.17085533 1.07121892] Bias: -1.0172353831846448 loss: 0.3457555765340597\n",
            "Round: 458 Weight: [2.17186626 1.07173492] Bias: -1.017657996852847 loss: 0.3457408313629431\n",
            "Round: 459 Weight: [2.17287371 1.07224918] Bias: -1.0180790603930832 loss: 0.3457261882601091\n",
            "Round: 460 Weight: [2.17387769 1.07276169] Bias: -1.0184985814514564 loss: 0.34571164641459845\n",
            "Round: 461 Weight: [2.17487821 1.07327248] Bias: -1.0189165676216438 loss: 0.34569720502300033\n",
            "Round: 462 Weight: [2.17587529 1.07378154] Bias: -1.0193330264453706 loss: 0.3456828632893697\n",
            "Round: 463 Weight: [2.17686894 1.07428888] Bias: -1.0197479654128796 loss: 0.3456686204251455\n",
            "Round: 464 Weight: [2.17785919 1.07479452] Bias: -1.020161391963395 loss: 0.34565447564907004\n",
            "Round: 465 Weight: [2.17884603 1.07529845] Bias: -1.0205733134855808 loss: 0.3456404281871094\n",
            "Round: 466 Weight: [2.1798295  1.07580069] Bias: -1.0209837373179955 loss: 0.34562647727237483\n",
            "Round: 467 Weight: [2.1808096  1.07630125] Bias: -1.02139267074954 loss: 0.3456126221450452\n",
            "Round: 468 Weight: [2.18178634 1.07680012] Bias: -1.0218001210199015 loss: 0.3455988620522902\n",
            "Round: 469 Weight: [2.18275976 1.07729732] Bias: -1.0222060953199925 loss: 0.34558519624819484\n",
            "Round: 470 Weight: [2.18372985 1.07779286] Bias: -1.0226106007923852 loss: 0.34557162399368485\n",
            "Round: 471 Weight: [2.18469663 1.07828673] Bias: -1.0230136445317397 loss: 0.34555814455645256\n",
            "Round: 472 Weight: [2.18566012 1.07877896] Bias: -1.02341523358523 loss: 0.3455447572108847\n",
            "Round: 473 Weight: [2.18662033 1.07926954] Bias: -1.0238153749529628 loss: 0.34553146123798956\n",
            "Round: 474 Weight: [2.18757728 1.07975848] Bias: -1.0242140755883935 loss: 0.3455182559253271\n",
            "Round: 475 Weight: [2.18853098 1.08024579] Bias: -1.0246113423987369 loss: 0.3455051405669377\n",
            "Round: 476 Weight: [2.18948144 1.08073147] Bias: -1.0250071822453732 loss: 0.34549211446327405\n",
            "Round: 477 Weight: [2.19042868 1.08121554] Bias: -1.025401601944251 loss: 0.3454791769211319\n",
            "Round: 478 Weight: [2.19137272 1.081698  ] Bias: -1.0257946082662834 loss: 0.3454663272535827\n",
            "Round: 479 Weight: [2.19231356 1.08217885] Bias: -1.026186207937743 loss: 0.3454535647799073\n",
            "Round: 480 Weight: [2.19325122 1.08265811] Bias: -1.02657640764065 loss: 0.3454408888255297\n",
            "Round: 481 Weight: [2.19418571 1.08313577] Bias: -1.026965214013157 loss: 0.3454282987219522\n",
            "Round: 482 Weight: [2.19511705 1.08361185] Bias: -1.0273526336499306 loss: 0.34541579380669096\n",
            "Round: 483 Weight: [2.19604526 1.08408635] Bias: -1.0277386731025269 loss: 0.34540337342321287\n",
            "Round: 484 Weight: [2.19697033 1.08455928] Bias: -1.0281233388797655 loss: 0.3453910369208724\n",
            "Round: 485 Weight: [2.1978923  1.08503065] Bias: -1.0285066374480971 loss: 0.34537878365485036\n",
            "Round: 486 Weight: [2.19881117 1.08550046] Bias: -1.028888575231969 loss: 0.34536661298609206\n",
            "Round: 487 Weight: [2.19972695 1.08596871] Bias: -1.0292691586141856 loss: 0.3453545242812473\n",
            "Round: 488 Weight: [2.20063966 1.08643542] Bias: -1.0296483939362653 loss: 0.34534251691261064\n",
            "Round: 489 Weight: [2.20154931 1.08690059] Bias: -1.0300262874987942 loss: 0.34533059025806256\n",
            "Round: 490 Weight: [2.20245591 1.08736423] Bias: -1.0304028455617755 loss: 0.3453187437010111\n",
            "Round: 491 Weight: [2.20335948 1.08782634] Bias: -1.030778074344975 loss: 0.3453069766303344\n",
            "Round: 492 Weight: [2.20426003 1.08828693] Bias: -1.0311519800282636 loss: 0.34529528844032364\n",
            "Round: 493 Weight: [2.20515757 1.08874601] Bias: -1.0315245687519556 loss: 0.34528367853062775\n",
            "Round: 494 Weight: [2.20605212 1.08920358] Bias: -1.0318958466171446 loss: 0.3452721463061968\n",
            "Round: 495 Weight: [2.20694369 1.08965965] Bias: -1.0322658196860337 loss: 0.34526069117722835\n",
            "Round: 496 Weight: [2.20783229 1.09011422] Bias: -1.0326344939822647 loss: 0.3452493125591121\n",
            "Round: 497 Weight: [2.20871793 1.0905673 ] Bias: -1.033001875491242 loss: 0.3452380098723778\n",
            "Round: 498 Weight: [2.20960062 1.0910189 ] Bias: -1.0333679701604541 loss: 0.3452267825426414\n",
            "Round: 499 Weight: [2.21048038 1.09146902] Bias: -1.0337327838997918 loss: 0.34521563000055305\n",
            "Round: 500 Weight: [2.21135723 1.09191766] Bias: -1.0340963225818625 loss: 0.34520455168174596\n",
            "Round: 501 Weight: [2.21223116 1.09236485] Bias: -1.0344585920423013 loss: 0.345193547026785\n",
            "Round: 502 Weight: [2.2131022  1.09281057] Bias: -1.0348195980800796 loss: 0.34518261548111656\n",
            "Round: 503 Weight: [2.21397036 1.09325484] Bias: -1.0351793464578103 loss: 0.3451717564950186\n",
            "Round: 504 Weight: [2.21483565 1.09369766] Bias: -1.0355378429020485 loss: 0.3451609695235517\n",
            "Round: 505 Weight: [2.21569807 1.09413904] Bias: -1.0358950931035913 loss: 0.3451502540265105\n",
            "Round: 506 Weight: [2.21655765 1.09457898] Bias: -1.0362511027177728 loss: 0.34513960946837546\n",
            "Round: 507 Weight: [2.2174144  1.09501749] Bias: -1.0366058773647568 loss: 0.3451290353182656\n",
            "Round: 508 Weight: [2.21826832 1.09545458] Bias: -1.0369594226298273 loss: 0.34511853104989154\n",
            "Round: 509 Weight: [2.21911942 1.09589025] Bias: -1.0373117440636737 loss: 0.3451080961415092\n",
            "Round: 510 Weight: [2.21996773 1.0963245 ] Bias: -1.0376628471826752 loss: 0.34509773007587397\n",
            "Round: 511 Weight: [2.22081325 1.09675735] Bias: -1.038012737469182 loss: 0.3450874323401956\n",
            "Round: 512 Weight: [2.22165599 1.09718879] Bias: -1.038361420371793 loss: 0.34507720242609347\n",
            "Round: 513 Weight: [2.22249596 1.09761884] Bias: -1.0387089013056308 loss: 0.3450670398295519\n",
            "Round: 514 Weight: [2.22333319 1.0980475 ] Bias: -1.0390551856526142 loss: 0.3450569440508771\n",
            "Round: 515 Weight: [2.22416766 1.09847477] Bias: -1.0394002787617282 loss: 0.34504691459465386\n",
            "Round: 516 Weight: [2.22499941 1.09890066] Bias: -1.0397441859492904 loss: 0.34503695096970266\n",
            "Round: 517 Weight: [2.22582843 1.09932517] Bias: -1.0400869124992156 loss: 0.34502705268903744\n",
            "Round: 518 Weight: [2.22665475 1.09974832] Bias: -1.040428463663277 loss: 0.3450172192698242\n",
            "Round: 519 Weight: [2.22747837 1.1001701 ] Bias: -1.0407688446613659 loss: 0.34500745023333984\n",
            "Round: 520 Weight: [2.22829929 1.10059053] Bias: -1.041108060681747 loss: 0.3449977451049307\n",
            "Round: 521 Weight: [2.22911755 1.1010096 ] Bias: -1.0414461168813136 loss: 0.34498810341397323\n",
            "Round: 522 Weight: [2.22993313 1.10142732] Bias: -1.0417830183858374 loss: 0.3449785246938337\n",
            "Round: 523 Weight: [2.23074607 1.1018437 ] Bias: -1.0421187702902184 loss: 0.3449690084818288\n",
            "Round: 524 Weight: [2.23155636 1.10225875] Bias: -1.0424533776587306 loss: 0.3449595543191869\n",
            "Round: 525 Weight: [2.23236401 1.10267246] Bias: -1.0427868455252662 loss: 0.3449501617510095\n",
            "Round: 526 Weight: [2.23316904 1.10308484] Bias: -1.043119178893577 loss: 0.34494083032623335\n",
            "Round: 527 Weight: [2.23397146 1.10349591] Bias: -1.0434503827375132 loss: 0.3449315595975929\n",
            "Round: 528 Weight: [2.23477128 1.10390566] Bias: -1.0437804620012605 loss: 0.34492234912158265\n",
            "Round: 529 Weight: [2.23556851 1.10431409] Bias: -1.0441094215995743 loss: 0.3449131984584211\n",
            "Round: 530 Weight: [2.23636316 1.10472122] Bias: -1.0444372664180117 loss: 0.3449041071720139\n",
            "Round: 531 Weight: [2.23715523 1.10512705] Bias: -1.0447640013131616 loss: 0.3448950748299184\n",
            "Round: 532 Weight: [2.23794475 1.10553159] Bias: -1.0450896311128717 loss: 0.3448861010033076\n",
            "Round: 533 Weight: [2.23873172 1.10593483] Bias: -1.0454141606164742 loss: 0.34487718526693567\n",
            "Round: 534 Weight: [2.23951615 1.10633679] Bias: -1.0457375945950094 loss: 0.34486832719910265\n",
            "Round: 535 Weight: [2.24029805 1.10673747] Bias: -1.0460599377914455 loss: 0.3448595263816206\n",
            "Round: 536 Weight: [2.24107743 1.10713687] Bias: -1.0463811949208985 loss: 0.3448507823997794\n",
            "Round: 537 Weight: [2.2418543 1.107535 ] Bias: -1.0467013706708483 loss: 0.3448420948423132\n",
            "Round: 538 Weight: [2.24262867 1.10793186] Bias: -1.0470204697013537 loss: 0.3448334633013673\n",
            "Round: 539 Weight: [2.24340056 1.10832747] Bias: -1.0473384966452641 loss: 0.3448248873724656\n",
            "Round: 540 Weight: [2.24416996 1.10872181] Bias: -1.0476554561084312 loss: 0.3448163666544777\n",
            "Round: 541 Weight: [2.24493689 1.10911491] Bias: -1.0479713526699164 loss: 0.34480790074958695\n",
            "Round: 542 Weight: [2.24570137 1.10950676] Bias: -1.0482861908821977 loss: 0.34479948926325915\n",
            "Round: 543 Weight: [2.2464634  1.10989737] Bias: -1.0485999752713737 loss: 0.34479113180421034\n",
            "Round: 544 Weight: [2.24722298 1.11028674] Bias: -1.048912710337367 loss: 0.34478282798437676\n",
            "Round: 545 Weight: [2.24798014 1.11067487] Bias: -1.0492244005541236 loss: 0.3447745774188832\n",
            "Round: 546 Weight: [2.24873487 1.11106179] Bias: -1.0495350503698124 loss: 0.3447663797260136\n",
            "Round: 547 Weight: [2.24948719 1.11144747] Bias: -1.0498446642070218 loss: 0.3447582345271803\n",
            "Round: 548 Weight: [2.25023712 1.11183194] Bias: -1.0501532464629542 loss: 0.3447501414468946\n",
            "Round: 549 Weight: [2.25098464 1.1122152 ] Bias: -1.050460801509619 loss: 0.34474210011273754\n",
            "Round: 550 Weight: [2.25172979 1.11259725] Bias: -1.0507673336940249 loss: 0.3447341101553306\n",
            "Round: 551 Weight: [2.25247256 1.11297809] Bias: -1.0510728473383675 loss: 0.34472617120830734\n",
            "Round: 552 Weight: [2.25321297 1.11335774] Bias: -1.051377346740218 loss: 0.3447182829082847\n",
            "Round: 553 Weight: [2.25395102 1.11373619] Bias: -1.0516808361727092 loss: 0.34471044489483516\n",
            "Round: 554 Weight: [2.25468673 1.11411344] Bias: -1.0519833198847188 loss: 0.3447026568104585\n",
            "Round: 555 Weight: [2.2554201  1.11448952] Bias: -1.0522848021010525 loss: 0.3446949183005547\n",
            "Round: 556 Weight: [2.25615115 1.11486441] Bias: -1.0525852870226236 loss: 0.3446872290133969\n",
            "Round: 557 Weight: [2.25687987 1.11523812] Bias: -1.0528847788266333 loss: 0.3446795886001042\n",
            "Round: 558 Weight: [2.25760629 1.11561067] Bias: -1.053183281666747 loss: 0.3446719967146149\n",
            "Round: 559 Weight: [2.2583304  1.11598204] Bias: -1.05348079967327 loss: 0.3446644530136606\n",
            "Round: 560 Weight: [2.25905222 1.11635225] Bias: -1.0537773369533219 loss: 0.34465695715674\n",
            "Round: 561 Weight: [2.25977176 1.1167213 ] Bias: -1.0540728975910085 loss: 0.3446495088060933\n",
            "Round: 562 Weight: [2.26048903 1.1170892 ] Bias: -1.0543674856475929 loss: 0.3446421076266761\n",
            "Round: 563 Weight: [2.26120403 1.11745594] Bias: -1.0546611051616641 loss: 0.34463475328613524\n",
            "Round: 564 Weight: [2.26191678 1.11782154] Bias: -1.0549537601493058 loss: 0.344627445454783\n",
            "Round: 565 Weight: [2.26262727 1.118186  ] Bias: -1.055245454604261 loss: 0.34462018380557263\n",
            "Round: 566 Weight: [2.26333553 1.11854932] Bias: -1.0555361924980975 loss: 0.3446129680140744\n",
            "Round: 567 Weight: [2.26404156 1.11891151] Bias: -1.0558259777803707 loss: 0.34460579775845096\n",
            "Round: 568 Weight: [2.26474537 1.11927256] Bias: -1.0561148143787846 loss: 0.34459867271943345\n",
            "Round: 569 Weight: [2.26544696 1.1196325 ] Bias: -1.0564027061993528 loss: 0.34459159258029826\n",
            "Round: 570 Weight: [2.26614635 1.11999131] Bias: -1.0566896571265563 loss: 0.3445845570268435\n",
            "Round: 571 Weight: [2.26684354 1.120349  ] Bias: -1.0569756710235008 loss: 0.3445775657473655\n",
            "Round: 572 Weight: [2.26753854 1.12070559] Bias: -1.0572607517320725 loss: 0.3445706184326366\n",
            "Round: 573 Weight: [2.26823137 1.12106106] Bias: -1.0575449030730921 loss: 0.3445637147758818\n",
            "Round: 574 Weight: [2.26892202 1.12141543] Bias: -1.0578281288464684 loss: 0.3445568544727572\n",
            "Round: 575 Weight: [2.26961051 1.1217687 ] Bias: -1.0581104328313486 loss: 0.3445500372213266\n",
            "Round: 576 Weight: [2.27029685 1.12212088] Bias: -1.0583918187862695 loss: 0.34454326272204094\n",
            "Round: 577 Weight: [2.27098104 1.12247196] Bias: -1.0586722904493056 loss: 0.3445365306777156\n",
            "Round: 578 Weight: [2.27166309 1.12282196] Bias: -1.0589518515382164 loss: 0.3445298407935094\n",
            "Round: 579 Weight: [2.27234301 1.12317087] Bias: -1.0592305057505933 loss: 0.3445231927769033\n",
            "Round: 580 Weight: [2.27302081 1.1235187 ] Bias: -1.0595082567640035 loss: 0.344516586337679\n",
            "Round: 581 Weight: [2.27369649 1.12386546] Bias: -1.0597851082361336 loss: 0.3445100211878988\n",
            "Round: 582 Weight: [2.27437007 1.12421115] Bias: -1.0600610638049321 loss: 0.3445034970418844\n",
            "Round: 583 Weight: [2.27504155 1.12455576] Bias: -1.0603361270887504 loss: 0.34449701361619667\n",
            "Round: 584 Weight: [2.27571094 1.12489932] Bias: -1.0606103016864816 loss: 0.3444905706296158\n",
            "Round: 585 Weight: [2.27637824 1.12524181] Bias: -1.0608835911777 loss: 0.344484167803121\n",
            "Round: 586 Weight: [2.27704348 1.12558325] Bias: -1.061155999122797 loss: 0.3444778048598707\n",
            "Round: 587 Weight: [2.27770664 1.12592363] Bias: -1.0614275290631185 loss: 0.3444714815251835\n",
            "Round: 588 Weight: [2.27836775 1.12626297] Bias: -1.0616981845210984 loss: 0.34446519752651805\n",
            "Round: 589 Weight: [2.2790268  1.12660127] Bias: -1.0619679690003927 loss: 0.3444589525934547\n",
            "Round: 590 Weight: [2.27968382 1.12693852] Bias: -1.0622368859860118 loss: 0.344452746457676\n",
            "Round: 591 Weight: [2.28033879 1.12727473] Bias: -1.0625049389444516 loss: 0.34444657885294805\n",
            "Round: 592 Weight: [2.28099174 1.12760992] Bias: -1.0627721313238234 loss: 0.3444404495151023\n",
            "Round: 593 Weight: [2.28164267 1.12794407] Bias: -1.0630384665539832 loss: 0.34443435818201656\n",
            "Round: 594 Weight: [2.28229158 1.1282772 ] Bias: -1.063303948046659 loss: 0.3444283045935974\n",
            "Round: 595 Weight: [2.28293849 1.12860931] Bias: -1.0635685791955778 loss: 0.344422288491762\n",
            "Round: 596 Weight: [2.2835834  1.12894039] Bias: -1.0638323633765907 loss: 0.34441630962041964\n",
            "Round: 597 Weight: [2.28422632 1.12927047] Bias: -1.0640953039477976 loss: 0.34441036772545536\n",
            "Round: 598 Weight: [2.28486725 1.12959953] Bias: -1.0643574042496708 loss: 0.3444044625547116\n",
            "Round: 599 Weight: [2.28550621 1.12992759] Bias: -1.0646186676051765 loss: 0.3443985938579709\n",
            "Round: 600 Weight: [2.2861432  1.13025464] Bias: -1.0648790973198967 loss: 0.34439276138693925\n",
            "Round: 601 Weight: [2.28677823 1.1305807 ] Bias: -1.0651386966821488 loss: 0.344386964895229\n",
            "Round: 602 Weight: [2.28741131 1.13090576] Bias: -1.0653974689631052 loss: 0.34438120413834206\n",
            "Round: 603 Weight: [2.28804244 1.13122982] Bias: -1.0656554174169113 loss: 0.344375478873653\n",
            "Round: 604 Weight: [2.28867163 1.1315529 ] Bias: -1.065912545280802 loss: 0.34436978886039327\n",
            "Round: 605 Weight: [2.28929888 1.13187499] Bias: -1.0661688557752185 loss: 0.34436413385963455\n",
            "Round: 606 Weight: [2.28992421 1.1321961 ] Bias: -1.0664243521039227 loss: 0.3443585136342726\n",
            "Round: 607 Weight: [2.29054763 1.13251624] Bias: -1.0666790374541117 loss: 0.34435292794901157\n",
            "Round: 608 Weight: [2.29116913 1.13283539] Bias: -1.0669329149965305 loss: 0.34434737657034814\n",
            "Round: 609 Weight: [2.29178873 1.13315358] Bias: -1.0671859878855845 loss: 0.34434185926655575\n",
            "Round: 610 Weight: [2.29240642 1.1334708 ] Bias: -1.0674382592594502 loss: 0.3443363758076694\n",
            "Round: 611 Weight: [2.29302223 1.13378706] Bias: -1.067689732240186 loss: 0.34433092596547016\n",
            "Round: 612 Weight: [2.29363616 1.13410235] Bias: -1.0679404099338403 loss: 0.3443255095134701\n",
            "Round: 613 Weight: [2.29424821 1.13441669] Bias: -1.0681902954305615 loss: 0.3443201262268973\n",
            "Round: 614 Weight: [2.29485839 1.13473007] Bias: -1.0684393918047042 loss: 0.34431477588268095\n",
            "Round: 615 Weight: [2.29546671 1.13504251] Bias: -1.0686877021149355 loss: 0.3443094582594366\n",
            "Round: 616 Weight: [2.29607317 1.13535399] Bias: -1.0689352294043415 loss: 0.34430417313745204\n",
            "Round: 617 Weight: [2.29667778 1.13566454] Bias: -1.0691819767005315 loss: 0.34429892029867215\n",
            "Round: 618 Weight: [2.29728055 1.13597414] Bias: -1.0694279470157417 loss: 0.3442936995266851\n",
            "Round: 619 Weight: [2.29788148 1.1362828 ] Bias: -1.0696731433469386 loss: 0.3442885106067082\n",
            "Round: 620 Weight: [2.29848058 1.13659054] Bias: -1.0699175686759206 loss: 0.34428335332557375\n",
            "Round: 621 Weight: [2.29907786 1.13689734] Bias: -1.070161225969419 loss: 0.3442782274717155\n",
            "Round: 622 Weight: [2.29967333 1.13720322] Bias: -1.0704041181791997 loss: 0.34427313283515454\n",
            "Round: 623 Weight: [2.30026698 1.13750817] Bias: -1.0706462482421606 loss: 0.34426806920748587\n",
            "Round: 624 Weight: [2.30085884 1.1378122 ] Bias: -1.0708876190804322 loss: 0.34426303638186523\n",
            "Round: 625 Weight: [2.30144889 1.13811531] Bias: -1.0711282336014745 loss: 0.34425803415299505\n",
            "Round: 626 Weight: [2.30203716 1.13841752] Bias: -1.0713680946981743 loss: 0.34425306231711233\n",
            "Round: 627 Weight: [2.30262364 1.13871881] Bias: -1.0716072052489412 loss: 0.34424812067197463\n",
            "Round: 628 Weight: [2.30320835 1.13901919] Bias: -1.0718455681178032 loss: 0.34424320901684763\n",
            "Round: 629 Weight: [2.30379129 1.13931867] Bias: -1.0720831861545017 loss: 0.34423832715249225\n",
            "Round: 630 Weight: [2.30437246 1.13961725] Bias: -1.0723200621945848 loss: 0.3442334748811518\n",
            "Round: 631 Weight: [2.30495187 1.13991493] Bias: -1.0725561990595005 loss: 0.3442286520065396\n",
            "Round: 632 Weight: [2.30552953 1.14021172] Bias: -1.0727915995566897 loss: 0.3442238583338266\n",
            "Round: 633 Weight: [2.30610545 1.14050761] Bias: -1.0730262664796766 loss: 0.3442190936696291\n",
            "Round: 634 Weight: [2.30667963 1.14080262] Bias: -1.0732602026081604 loss: 0.34421435782199583\n",
            "Round: 635 Weight: [2.30725207 1.14109674] Bias: -1.073493410708105 loss: 0.3442096506003971\n",
            "Round: 636 Weight: [2.30782279 1.14138998] Bias: -1.0737258935318281 loss: 0.344204971815712\n",
            "Round: 637 Weight: [2.30839179 1.14168234] Bias: -1.0739576538180908 loss: 0.3442003212802166\n",
            "Round: 638 Weight: [2.30895907 1.14197382] Bias: -1.074188694292184 loss: 0.3441956988075725\n",
            "Round: 639 Weight: [2.30952465 1.14226444] Bias: -1.074419017666017 loss: 0.3441911042128152\n",
            "Round: 640 Weight: [2.31008852 1.14255418] Bias: -1.0746486266382027 loss: 0.3441865373123421\n",
            "Round: 641 Weight: [2.3106507  1.14284305] Bias: -1.074877523894144 loss: 0.34418199792390214\n",
            "Round: 642 Weight: [2.31121119 1.14313107] Bias: -1.0751057121061187 loss: 0.3441774858665831\n",
            "Round: 643 Weight: [2.31176999 1.14341822] Bias: -1.075333193933364 loss: 0.34417300096080167\n",
            "Round: 644 Weight: [2.31232712 1.14370451] Bias: -1.0755599720221598 loss: 0.3441685430282917\n",
            "Round: 645 Weight: [2.31288257 1.14398995] Bias: -1.0757860490059121 loss: 0.34416411189209345\n",
            "Round: 646 Weight: [2.31343636 1.14427454] Bias: -1.0760114275052353 loss: 0.34415970737654267\n",
            "Round: 647 Weight: [2.31398848 1.14455828] Bias: -1.076236110128033 loss: 0.34415532930726006\n",
            "Round: 648 Weight: [2.31453896 1.14484117] Bias: -1.0764600994695808 loss: 0.3441509775111398\n",
            "Round: 649 Weight: [2.31508778 1.14512322] Bias: -1.0766833981126045 loss: 0.34414665181634024\n",
            "Round: 650 Weight: [2.31563496 1.14540444] Bias: -1.0769060086273614 loss: 0.3441423520522725\n",
            "Round: 651 Weight: [2.31618051 1.14568481] Bias: -1.0771279335717188 loss: 0.3441380780495905\n",
            "Round: 652 Weight: [2.31672442 1.14596435] Bias: -1.077349175491232 loss: 0.3441338296401805\n",
            "Round: 653 Weight: [2.31726671 1.14624306] Bias: -1.0775697369192234 loss: 0.34412960665715125\n",
            "Round: 654 Weight: [2.31780737 1.14652094] Bias: -1.077789620376858 loss: 0.34412540893482346\n",
            "Round: 655 Weight: [2.31834643 1.146798  ] Bias: -1.0780088283732214 loss: 0.34412123630872016\n",
            "Round: 656 Weight: [2.31888387 1.14707423] Bias: -1.078227363405395 loss: 0.34411708861555684\n",
            "Round: 657 Weight: [2.31941971 1.14734964] Bias: -1.0784452279585313 loss: 0.3441129656932316\n",
            "Round: 658 Weight: [2.31995396 1.14762424] Bias: -1.0786624245059293 loss: 0.34410886738081503\n",
            "Round: 659 Weight: [2.32048661 1.14789802] Bias: -1.0788789555091083 loss: 0.3441047935185414\n",
            "Round: 660 Weight: [2.32101768 1.14817099] Bias: -1.0790948234178812 loss: 0.3441007439477987\n",
            "Round: 661 Weight: [2.32154717 1.14844315] Bias: -1.0793100306704282 loss: 0.3440967185111189\n",
            "Round: 662 Weight: [2.32207508 1.14871451] Bias: -1.0795245796933688 loss: 0.3440927170521693\n",
            "Round: 663 Weight: [2.32260142 1.14898507] Bias: -1.0797384729018333 loss: 0.34408873941574286\n",
            "Round: 664 Weight: [2.3231262  1.14925482] Bias: -1.079951712699535 loss: 0.34408478544774895\n",
            "Round: 665 Weight: [2.32364942 1.14952378] Bias: -1.0801643014788402 loss: 0.3440808549952046\n",
            "Round: 666 Weight: [2.32417109 1.14979194] Bias: -1.0803762416208387 loss: 0.3440769479062251\n",
            "Round: 667 Weight: [2.32469121 1.15005931] Bias: -1.0805875354954135 loss: 0.3440730640300157\n",
            "Round: 668 Weight: [2.32520978 1.15032589] Bias: -1.0807981854613098 loss: 0.34406920321686196\n",
            "Round: 669 Weight: [2.32572682 1.15059168] Bias: -1.0810081938662037 loss: 0.3440653653181216\n",
            "Round: 670 Weight: [2.32624233 1.15085669] Bias: -1.0812175630467697 loss: 0.34406155018621576\n",
            "Round: 671 Weight: [2.32675632 1.15112092] Bias: -1.0814262953287492 loss: 0.3440577576746202\n",
            "Round: 672 Weight: [2.32726878 1.15138438] Bias: -1.0816343930270165 loss: 0.34405398763785683\n",
            "Round: 673 Weight: [2.32777972 1.15164705] Bias: -1.0818418584456457 loss: 0.3440502399314855\n",
            "Round: 674 Weight: [2.32828915 1.15190895] Bias: -1.082048693877977 loss: 0.3440465144120952\n",
            "Round: 675 Weight: [2.32879708 1.15217008] Bias: -1.0822549016066811 loss: 0.3440428109372965\n",
            "Round: 676 Weight: [2.32930351 1.15243045] Bias: -1.0824604839038254 loss: 0.3440391293657127\n",
            "Round: 677 Weight: [2.32980845 1.15269005] Bias: -1.0826654430309375 loss: 0.3440354695569716\n",
            "Round: 678 Weight: [2.33031189 1.15294888] Bias: -1.0828697812390697 loss: 0.3440318313716984\n",
            "Round: 679 Weight: [2.33081385 1.15320696] Bias: -1.083073500768862 loss: 0.34402821467150657\n",
            "Round: 680 Weight: [2.33131433 1.15346427] Bias: -1.0832766038506059 loss: 0.34402461931899064\n",
            "Round: 681 Weight: [2.33181333 1.15372084] Bias: -1.0834790927043054 loss: 0.34402104517771825\n",
            "Round: 682 Weight: [2.33231087 1.15397665] Bias: -1.0836809695397407 loss: 0.3440174921122222\n",
            "Round: 683 Weight: [2.33280694 1.15423171] Bias: -1.0838822365565286 loss: 0.3440139599879927\n",
            "Round: 684 Weight: [2.33330155 1.15448602] Bias: -1.0840828959441842 loss: 0.3440104486714704\n",
            "Round: 685 Weight: [2.33379471 1.15473959] Bias: -1.0842829498821809 loss: 0.34400695803003783\n",
            "Round: 686 Weight: [2.33428641 1.15499241] Bias: -1.084482400540011 loss: 0.3440034879320128\n",
            "Round: 687 Weight: [2.33477667 1.1552445 ] Bias: -1.0846812500772456 loss: 0.3440000382466403\n",
            "Round: 688 Weight: [2.3352655  1.15549585] Bias: -1.0848795006435932 loss: 0.3439966088440858\n",
            "Round: 689 Weight: [2.33575289 1.15574646] Bias: -1.085077154378959 loss: 0.34399319959542735\n",
            "Round: 690 Weight: [2.33623884 1.15599634] Bias: -1.085274213413503 loss: 0.3439898103726486\n",
            "Round: 691 Weight: [2.33672338 1.1562455 ] Bias: -1.085470679867698 loss: 0.34398644104863196\n",
            "Round: 692 Weight: [2.33720649 1.15649392] Bias: -1.0856665558523875 loss: 0.34398309149715095\n",
            "Round: 693 Weight: [2.33768819 1.15674162] Bias: -1.0858618434688418 loss: 0.3439797615928636\n",
            "Round: 694 Weight: [2.33816847 1.1569886 ] Bias: -1.0860565448088155 loss: 0.34397645121130516\n",
            "Round: 695 Weight: [2.33864735 1.15723485] Bias: -1.086250661954603 loss: 0.3439731602288815\n",
            "Round: 696 Weight: [2.33912483 1.15748039] Bias: -1.0864441969790954 loss: 0.3439698885228622\n",
            "Round: 697 Weight: [2.33960092 1.15772522] Bias: -1.0866371519458344 loss: 0.3439666359713734\n",
            "Round: 698 Weight: [2.34007561 1.15796933] Bias: -1.0868295289090681 loss: 0.34396340245339163\n",
            "Round: 699 Weight: [2.34054892 1.15821273] Bias: -1.0870213299138058 loss: 0.3439601878487368\n",
            "Round: 700 Weight: [2.34102084 1.15845542] Bias: -1.0872125569958715 loss: 0.34395699203806585\n",
            "Round: 701 Weight: [2.34149139 1.1586974 ] Bias: -1.0874032121819577 loss: 0.3439538149028657\n",
            "Round: 702 Weight: [2.34196056 1.15893869] Bias: -1.0875932974896794 loss: 0.3439506563254475\n",
            "Round: 703 Weight: [2.34242836 1.15917927] Bias: -1.0877828149276263 loss: 0.34394751618893965\n",
            "Round: 704 Weight: [2.34289481 1.15941915] Bias: -1.0879717664954158 loss: 0.3439443943772814\n",
            "Round: 705 Weight: [2.34335989 1.15965834] Bias: -1.088160154183745 loss: 0.3439412907752172\n",
            "Round: 706 Weight: [2.34382362 1.15989683] Bias: -1.0883479799744422 loss: 0.3439382052682895\n",
            "Round: 707 Weight: [2.34428599 1.16013463] Bias: -1.0885352458405193 loss: 0.3439351377428334\n",
            "Round: 708 Weight: [2.34474703 1.16037174] Bias: -1.0887219537462216 loss: 0.34393208808596964\n",
            "Round: 709 Weight: [2.34520672 1.16060816] Bias: -1.0889081056470793 loss: 0.3439290561855997\n",
            "Round: 710 Weight: [2.34566507 1.1608439 ] Bias: -1.0890937034899573 loss: 0.3439260419303984\n",
            "Round: 711 Weight: [2.3461221  1.16107896] Bias: -1.0892787492131053 loss: 0.3439230452098086\n",
            "Round: 712 Weight: [2.34657779 1.16131333] Bias: -1.0894632447462078 loss: 0.3439200659140358\n",
            "Round: 713 Weight: [2.34703217 1.16154703] Bias: -1.0896471920104325 loss: 0.343917103934041\n",
            "Round: 714 Weight: [2.34748522 1.16178005] Bias: -1.0898305929184795 loss: 0.34391415916153584\n",
            "Round: 715 Weight: [2.34793696 1.1620124 ] Bias: -1.0900134493746303 loss: 0.3439112314889765\n",
            "Round: 716 Weight: [2.34838739 1.16224408] Bias: -1.090195763274795 loss: 0.3439083208095583\n",
            "Round: 717 Weight: [2.34883652 1.16247508] Bias: -1.0903775365065604 loss: 0.34390542701720883\n",
            "Round: 718 Weight: [2.34928434 1.16270542] Bias: -1.0905587709492381 loss: 0.34390255000658415\n",
            "Round: 719 Weight: [2.34973087 1.1629351 ] Bias: -1.090739468473911 loss: 0.34389968967306167\n",
            "Round: 720 Weight: [2.35017611 1.16316411] Bias: -1.0909196309434794 loss: 0.3438968459127354\n",
            "Round: 721 Weight: [2.35062005 1.16339246] Bias: -1.0910992602127092 loss: 0.34389401862241037\n",
            "Round: 722 Weight: [2.35106272 1.16362015] Bias: -1.0912783581282766 loss: 0.34389120769959663\n",
            "Round: 723 Weight: [2.3515041  1.16384719] Bias: -1.0914569265288139 loss: 0.34388841304250495\n",
            "Round: 724 Weight: [2.35194421 1.16407357] Bias: -1.0916349672449555 loss: 0.34388563455004034\n",
            "Round: 725 Weight: [2.35238305 1.16429931] Bias: -1.0918124820993829 loss: 0.34388287212179736\n",
            "Round: 726 Weight: [2.35282062 1.16452439] Bias: -1.0919894729068693 loss: 0.34388012565805476\n",
            "Round: 727 Weight: [2.35325692 1.16474882] Bias: -1.092165941474324 loss: 0.3438773950597705\n",
            "Round: 728 Weight: [2.35369197 1.16497261] Bias: -1.0923418896008372 loss: 0.34387468022857576\n",
            "Round: 729 Weight: [2.35412577 1.16519576] Bias: -1.0925173190777226 loss: 0.3438719810667711\n",
            "Round: 730 Weight: [2.35455831 1.16541826] Bias: -1.092692231688562 loss: 0.3438692974773201\n",
            "Round: 731 Weight: [2.35498961 1.16564012] Bias: -1.0928666292092484 loss: 0.3438666293638451\n",
            "Round: 732 Weight: [2.35541967 1.16586135] Bias: -1.093040513408028 loss: 0.3438639766306225\n",
            "Round: 733 Weight: [2.35584848 1.16608194] Bias: -1.0932138860455447 loss: 0.34386133918257655\n",
            "Round: 734 Weight: [2.35627607 1.1663019 ] Bias: -1.09338674887488 loss: 0.3438587169252757\n",
            "Round: 735 Weight: [2.35670242 1.16652123] Bias: -1.0935591036415973 loss: 0.3438561097649273\n",
            "Round: 736 Weight: [2.35712755 1.16673993] Bias: -1.0937309520837817 loss: 0.3438535176083724\n",
            "Round: 737 Weight: [2.35755146 1.16695801] Bias: -1.0939022959320828 loss: 0.3438509403630817\n",
            "Round: 738 Weight: [2.35797415 1.16717545] Bias: -1.0940731369097552 loss: 0.34384837793715045\n",
            "Round: 739 Weight: [2.35839562 1.16739228] Bias: -1.0942434767326994 loss: 0.34384583023929327\n",
            "Round: 740 Weight: [2.35881589 1.16760849] Bias: -1.0944133171095025 loss: 0.3438432971788403\n",
            "Round: 741 Weight: [2.35923495 1.16782407] Bias: -1.0945826597414785 loss: 0.3438407786657324\n",
            "Round: 742 Weight: [2.35965281 1.16803904] Bias: -1.0947515063227082 loss: 0.343838274610516\n",
            "Round: 743 Weight: [2.36006947 1.1682534 ] Bias: -1.0949198585400792 loss: 0.34383578492433914\n",
            "Round: 744 Weight: [2.36048494 1.16846714] Bias: -1.0950877180733245 loss: 0.3438333095189469\n",
            "Round: 745 Weight: [2.36089921 1.16868027] Bias: -1.0952550865950628 loss: 0.3438308483066766\n",
            "Round: 746 Weight: [2.3613123 1.1688928] Bias: -1.0954219657708366 loss: 0.34382840120045377\n",
            "Round: 747 Weight: [2.36172421 1.16910471] Bias: -1.0955883572591512 loss: 0.3438259681137875\n",
            "Round: 748 Weight: [2.36213494 1.16931602] Bias: -1.0957542627115129 loss: 0.34382354896076617\n",
            "Round: 749 Weight: [2.36254449 1.16952673] Bias: -1.0959196837724674 loss: 0.3438211436560532\n",
            "Round: 750 Weight: [2.36295288 1.16973684] Bias: -1.0960846220796372 loss: 0.3438187521148826\n",
            "Round: 751 Weight: [2.36336009 1.16994635] Bias: -1.0962490792637596 loss: 0.34381637425305484\n",
            "Round: 752 Weight: [2.36376615 1.17015526] Bias: -1.0964130569487236 loss: 0.34381400998693273\n",
            "Round: 753 Weight: [2.36417104 1.17036358] Bias: -1.0965765567516073 loss: 0.34381165923343693\n",
            "Round: 754 Weight: [2.36457478 1.1705713 ] Bias: -1.0967395802827142 loss: 0.3438093219100423\n",
            "Round: 755 Weight: [2.36497736 1.17077844] Bias: -1.096902129145611 loss: 0.34380699793477326\n",
            "Round: 756 Weight: [2.3653788  1.17098498] Bias: -1.0970642049371622 loss: 0.3438046872262003\n",
            "Round: 757 Weight: [2.36577909 1.17119093] Bias: -1.0972258092475677 loss: 0.3438023897034351\n",
            "Round: 758 Weight: [2.36617825 1.1713963 ] Bias: -1.0973869436603976 loss: 0.34380010528612753\n",
            "Round: 759 Weight: [2.36657626 1.17160109] Bias: -1.097547609752628 loss: 0.3437978338944609\n",
            "Round: 760 Weight: [2.36697314 1.1718053 ] Bias: -1.0977078090946768 loss: 0.34379557544914857\n",
            "Round: 761 Weight: [2.3673689  1.17200892] Bias: -1.0978675432504381 loss: 0.34379332987142946\n",
            "Round: 762 Weight: [2.36776352 1.17221197] Bias: -1.098026813777318 loss: 0.3437910970830649\n",
            "Round: 763 Weight: [2.36815702 1.17241444] Bias: -1.0981856222262676 loss: 0.3437888770063342\n",
            "Round: 764 Weight: [2.36854941 1.17261633] Bias: -1.0983439701418196 loss: 0.34378666956403076\n",
            "Round: 765 Weight: [2.36894068 1.17281766] Bias: -1.0985018590621205 loss: 0.3437844746794592\n",
            "Round: 766 Weight: [2.36933083 1.17301841] Bias: -1.0986592905189654 loss: 0.34378229227643037\n",
            "Round: 767 Weight: [2.36971988 1.17321859] Bias: -1.0988162660378316 loss: 0.34378012227925875\n",
            "Round: 768 Weight: [2.37010783 1.17341821] Bias: -1.0989727871379122 loss: 0.34377796461275795\n",
            "Round: 769 Weight: [2.37049467 1.17361726] Bias: -1.0991288553321494 loss: 0.34377581920223754\n",
            "Round: 770 Weight: [2.37088042 1.17381575] Bias: -1.099284472127267 loss: 0.34377368597349905\n",
            "Round: 771 Weight: [2.37126507 1.17401367] Bias: -1.0994396390238035 loss: 0.3437715648528328\n",
            "Round: 772 Weight: [2.37164863 1.17421104] Bias: -1.099594357516145 loss: 0.3437694557670142\n",
            "Round: 773 Weight: [2.37203111 1.17440785] Bias: -1.0997486290925573 loss: 0.34376735864329977\n",
            "Round: 774 Weight: [2.3724125 1.1746041] Bias: -1.0999024552352177 loss: 0.3437652734094244\n",
            "Round: 775 Weight: [2.37279281 1.1747998 ] Bias: -1.1000558374202476 loss: 0.34376319999359706\n",
            "Round: 776 Weight: [2.37317204 1.17499494] Bias: -1.1002087771177438 loss: 0.34376113832449834\n",
            "Round: 777 Weight: [2.3735502  1.17518953] Bias: -1.1003612757918102 loss: 0.3437590883312758\n",
            "Round: 778 Weight: [2.37392729 1.17538358] Bias: -1.1005133349005891 loss: 0.3437570499435416\n",
            "Round: 779 Weight: [2.37430332 1.17557707] Bias: -1.1006649558962922 loss: 0.3437550230913688\n",
            "Round: 780 Weight: [2.37467828 1.17577002] Bias: -1.1008161402252314 loss: 0.3437530077052878\n",
            "Round: 781 Weight: [2.37505218 1.17596243] Bias: -1.10096688932785 loss: 0.3437510037162832\n",
            "Round: 782 Weight: [2.37542503 1.17615429] Bias: -1.1011172046387523 loss: 0.34374901105579075\n",
            "Round: 783 Weight: [2.37579682 1.17634561] Bias: -1.101267087586735 loss: 0.34374702965569365\n",
            "Round: 784 Weight: [2.37616757 1.1765364 ] Bias: -1.1014165395948163 loss: 0.3437450594483197\n",
            "Round: 785 Weight: [2.37653726 1.17672664] Bias: -1.1015655620802665 loss: 0.34374310036643757\n",
            "Round: 786 Weight: [2.37690592 1.17691636] Bias: -1.101714156454637 loss: 0.34374115234325436\n",
            "Round: 787 Weight: [2.37727354 1.17710553] Bias: -1.101862324123791 loss: 0.3437392153124122\n",
            "Round: 788 Weight: [2.37764011 1.17729418] Bias: -1.102010066487931 loss: 0.34373728920798435\n",
            "Round: 789 Weight: [2.37800566 1.17748229] Bias: -1.10215738494163 loss: 0.34373537396447335\n",
            "Round: 790 Weight: [2.37837018 1.17766988] Bias: -1.1023042808738586 loss: 0.34373346951680706\n",
            "Round: 791 Weight: [2.37873367 1.17785693] Bias: -1.102450755668015 loss: 0.3437315758003358\n",
            "Round: 792 Weight: [2.37909614 1.17804347] Bias: -1.102596810701953 loss: 0.34372969275082954\n",
            "Round: 793 Weight: [2.37945758 1.17822948] Bias: -1.1027424473480105 loss: 0.3437278203044748\n",
            "Round: 794 Weight: [2.37981801 1.17841496] Bias: -1.1028876669730376 loss: 0.34372595839787123\n",
            "Round: 795 Weight: [2.38017743 1.17859993] Bias: -1.103032470938425 loss: 0.3437241069680295\n",
            "Round: 796 Weight: [2.38053584 1.17878437] Bias: -1.1031768606001306 loss: 0.34372226595236766\n",
            "Round: 797 Weight: [2.38089324 1.1789683 ] Bias: -1.1033208373087091 loss: 0.34372043528870866\n",
            "Round: 798 Weight: [2.38124963 1.17915172] Bias: -1.103464402409338 loss: 0.3437186149152771\n",
            "Round: 799 Weight: [2.38160503 1.17933462] Bias: -1.1036075572418453 loss: 0.3437168047706964\n",
            "Round: 800 Weight: [2.38195943 1.179517  ] Bias: -1.1037503031407367 loss: 0.3437150047939865\n",
            "Round: 801 Weight: [2.38231283 1.17969888] Bias: -1.1038926414352226 loss: 0.3437132149245602\n",
            "Round: 802 Weight: [2.38266524 1.17988025] Bias: -1.1040345734492443 loss: 0.3437114351022214\n",
            "Round: 803 Weight: [2.38301666 1.1800611 ] Bias: -1.1041761005015016 loss: 0.343709665267161\n",
            "Round: 804 Weight: [2.3833671  1.18024146] Bias: -1.1043172239054788 loss: 0.34370790535995555\n",
            "Round: 805 Weight: [2.38371656 1.1804213 ] Bias: -1.1044579449694705 loss: 0.34370615532156334\n",
            "Round: 806 Weight: [2.38406503 1.18060065] Bias: -1.104598264996608 loss: 0.34370441509332256\n",
            "Round: 807 Weight: [2.38441254 1.18077949] Bias: -1.1047381852848857 loss: 0.3437026846169481\n",
            "Round: 808 Weight: [2.38475906 1.18095784] Bias: -1.104877707127186 loss: 0.3437009638345289\n",
            "Round: 809 Weight: [2.38510462 1.18113568] Bias: -1.1050168318113058 loss: 0.3436992526885258\n",
            "Round: 810 Weight: [2.38544921 1.18131303] Bias: -1.1051555606199814 loss: 0.3436975511217683\n",
            "Round: 811 Weight: [2.38579284 1.18148988] Bias: -1.105293894830914 loss: 0.3436958590774523\n",
            "Round: 812 Weight: [2.38613551 1.18166624] Bias: -1.105431835716794 loss: 0.3436941764991373\n",
            "Round: 813 Weight: [2.38647722 1.18184211] Bias: -1.105569384545328 loss: 0.3436925033307443\n",
            "Round: 814 Weight: [2.38681797 1.18201749] Bias: -1.1057065425792612 loss: 0.3436908395165527\n",
            "Round: 815 Weight: [2.38715778 1.18219238] Bias: -1.1058433110764034 loss: 0.34368918500119783\n",
            "Round: 816 Weight: [2.38749663 1.18236678] Bias: -1.1059796912896536 loss: 0.343687539729669\n",
            "Round: 817 Weight: [2.38783454 1.18254069] Bias: -1.1061156844670235 loss: 0.34368590364730645\n",
            "Round: 818 Weight: [2.38817151 1.18271412] Bias: -1.1062512918516627 loss: 0.3436842766997992\n",
            "Round: 819 Weight: [2.38850753 1.18288707] Bias: -1.1063865146818819 loss: 0.3436826588331823\n",
            "Round: 820 Weight: [2.38884262 1.18305953] Bias: -1.106521354191177 loss: 0.3436810499938346\n",
            "Round: 821 Weight: [2.38917677 1.18323152] Bias: -1.106655811608253 loss: 0.34367945012847656\n",
            "Round: 822 Weight: [2.38951    1.18340302] Bias: -1.106789888157048 loss: 0.3436778591841675\n",
            "Round: 823 Weight: [2.38984229 1.18357405] Bias: -1.1069235850567554 loss: 0.34367627710830334\n",
            "Round: 824 Weight: [2.39017366 1.18374461] Bias: -1.1070569035218487 loss: 0.3436747038486143\n",
            "Round: 825 Weight: [2.39050411 1.18391469] Bias: -1.1071898447621036 loss: 0.34367313935316257\n",
            "Round: 826 Weight: [2.39083364 1.18408429] Bias: -1.1073224099826213 loss: 0.34367158357034006\n",
            "Round: 827 Weight: [2.39116225 1.18425343] Bias: -1.107454600383852 loss: 0.34367003644886573\n",
            "Round: 828 Weight: [2.39148994 1.18442209] Bias: -1.107586417161616 loss: 0.3436684979377839\n",
            "Round: 829 Weight: [2.39181673 1.18459029] Bias: -1.1077178615071284 loss: 0.3436669679864616\n",
            "Round: 830 Weight: [2.3921426  1.18475802] Bias: -1.10784893460702 loss: 0.34366544654458636\n",
            "Round: 831 Weight: [2.39246757 1.18492529] Bias: -1.10797963764336 loss: 0.34366393356216407\n",
            "Round: 832 Weight: [2.39279164 1.18509209] Bias: -1.1081099717936786 loss: 0.3436624289895167\n",
            "Round: 833 Weight: [2.39311481 1.18525843] Bias: -1.1082399382309887 loss: 0.34366093277728027\n",
            "Round: 834 Weight: [2.39343708 1.1854243 ] Bias: -1.1083695381238075 loss: 0.34365944487640243\n",
            "Round: 835 Weight: [2.39375846 1.18558972] Bias: -1.108498772636179 loss: 0.3436579652381404\n",
            "Round: 836 Weight: [2.39407894 1.18575468] Bias: -1.1086276429276951 loss: 0.34365649381405905\n",
            "Round: 837 Weight: [2.39439854 1.18591918] Bias: -1.1087561501535173 loss: 0.3436550305560285\n",
            "Round: 838 Weight: [2.39471725 1.18608323] Bias: -1.1088842954643978 loss: 0.34365357541622177\n",
            "Round: 839 Weight: [2.39503507 1.18624682] Bias: -1.1090120800067014 loss: 0.3436521283471136\n",
            "Round: 840 Weight: [2.39535202 1.18640996] Bias: -1.1091395049224255 loss: 0.34365068930147735\n",
            "Round: 841 Weight: [2.39566809 1.18657264] Bias: -1.1092665713492225 loss: 0.34364925823238346\n",
            "Round: 842 Weight: [2.39598328 1.18673488] Bias: -1.1093932804204194 loss: 0.3436478350931974\n",
            "Round: 843 Weight: [2.3962976  1.18689667] Bias: -1.1095196332650394 loss: 0.3436464198375775\n",
            "Round: 844 Weight: [2.39661105 1.18705801] Bias: -1.1096456310078222 loss: 0.34364501241947304\n",
            "Round: 845 Weight: [2.39692363 1.18721891] Bias: -1.109771274769244 loss: 0.343643612793122\n",
            "Round: 846 Weight: [2.39723534 1.18737936] Bias: -1.109896565665539 loss: 0.3436422209130498\n",
            "Round: 847 Weight: [2.3975462  1.18753937] Bias: -1.1100215048087183 loss: 0.3436408367340662\n",
            "Round: 848 Weight: [2.39785619 1.18769893] Bias: -1.1101460933065912 loss: 0.3436394602112644\n",
            "Round: 849 Weight: [2.39816533 1.18785806] Bias: -1.1102703322627843 loss: 0.3436380913000185\n",
            "Round: 850 Weight: [2.39847362 1.18801675] Bias: -1.1103942227767618 loss: 0.34363672995598166\n",
            "Round: 851 Weight: [2.39878105 1.188175  ] Bias: -1.1105177659438454 loss: 0.34363537613508444\n",
            "Round: 852 Weight: [2.39908763 1.18833281] Bias: -1.1106409628552338 loss: 0.3436340297935326\n",
            "Round: 853 Weight: [2.39939337 1.18849019] Bias: -1.1107638145980219 loss: 0.3436326908878054\n",
            "Round: 854 Weight: [2.39969827 1.18864713] Bias: -1.1108863222552203 loss: 0.34363135937465394\n",
            "Round: 855 Weight: [2.40000232 1.18880364] Bias: -1.1110084869057755 loss: 0.34363003521109875\n",
            "Round: 856 Weight: [2.40030553 1.18895972] Bias: -1.1111303096245875 loss: 0.34362871835442815\n",
            "Round: 857 Weight: [2.40060791 1.18911537] Bias: -1.1112517914825304 loss: 0.3436274087621971\n",
            "Round: 858 Weight: [2.40090945 1.18927059] Bias: -1.1113729335464702 loss: 0.34362610639222424\n",
            "Round: 859 Weight: [2.40121017 1.18942538] Bias: -1.111493736879284 loss: 0.3436248112025911\n",
            "Round: 860 Weight: [2.40151005 1.18957975] Bias: -1.1116142025398794 loss: 0.34362352315163963\n",
            "Round: 861 Weight: [2.40180911 1.18973369] Bias: -1.111734331583212 loss: 0.3436222421979709\n",
            "Round: 862 Weight: [2.40210735 1.18988721] Bias: -1.1118541250603045 loss: 0.343620968300443\n",
            "Round: 863 Weight: [2.40240476 1.19004031] Bias: -1.111973584018265 loss: 0.34361970141816955\n",
            "Round: 864 Weight: [2.40270136 1.19019299] Bias: -1.1120927095003055 loss: 0.3436184415105178\n",
            "Round: 865 Weight: [2.40299714 1.19034524] Bias: -1.1122115025457597 loss: 0.34361718853710704\n",
            "Round: 866 Weight: [2.4032921  1.19049708] Bias: -1.1123299641901014 loss: 0.34361594245780674\n",
            "Round: 867 Weight: [2.40358626 1.1906485 ] Bias: -1.112448095464962 loss: 0.34361470323273524\n",
            "Round: 868 Weight: [2.40387961 1.19079951] Bias: -1.1125658973981492 loss: 0.34361347082225724\n",
            "Round: 869 Weight: [2.40417215 1.1909501 ] Bias: -1.1126833710136639 loss: 0.34361224518698313\n",
            "Round: 870 Weight: [2.40446388 1.19110028] Bias: -1.1128005173317181 loss: 0.3436110262877668\n",
            "Round: 871 Weight: [2.40475482 1.19125004] Bias: -1.1129173373687529 loss: 0.343609814085704\n",
            "Round: 872 Weight: [2.40504496 1.1913994 ] Bias: -1.113033832137455 loss: 0.34360860854213093\n",
            "Round: 873 Weight: [2.4053343  1.19154834] Bias: -1.1131500026467755 loss: 0.3436074096186223\n",
            "Round: 874 Weight: [2.40562284 1.19169688] Bias: -1.1132658499019457 loss: 0.34360621727699003\n",
            "Round: 875 Weight: [2.4059106  1.19184501] Bias: -1.1133813749044947 loss: 0.34360503147928156\n",
            "Round: 876 Weight: [2.40619756 1.19199274] Bias: -1.113496578652267 loss: 0.3436038521877782\n",
            "Round: 877 Weight: [2.40648374 1.19214005] Bias: -1.1136114621394386 loss: 0.34360267936499367\n",
            "Round: 878 Weight: [2.40676914 1.19228697] Bias: -1.1137260263565347 loss: 0.3436015129736724\n",
            "Round: 879 Weight: [2.40705375 1.19243348] Bias: -1.1138402722904457 loss: 0.34360035297678804\n",
            "Round: 880 Weight: [2.40733758 1.1925796 ] Bias: -1.1139542009244443 loss: 0.3435991993375422\n",
            "Round: 881 Weight: [2.40762064 1.19272531] Bias: -1.1140678132382018 loss: 0.3435980520193623\n",
            "Round: 882 Weight: [2.40790292 1.19287062] Bias: -1.1141811102078047 loss: 0.34359691098590084\n",
            "Round: 883 Weight: [2.40818442 1.19301554] Bias: -1.1142940928057714 loss: 0.3435957762010332\n",
            "Round: 884 Weight: [2.40846516 1.19316006] Bias: -1.1144067620010678 loss: 0.3435946476288565\n",
            "Round: 885 Weight: [2.40874513 1.19330418] Bias: -1.114519118759124 loss: 0.34359352523368814\n",
            "Round: 886 Weight: [2.40902433 1.19344792] Bias: -1.11463116404185 loss: 0.3435924089800644\n",
            "Round: 887 Weight: [2.40930277 1.19359125] Bias: -1.1147428988076522 loss: 0.3435912988327383\n",
            "Round: 888 Weight: [2.40958045 1.1937342 ] Bias: -1.1148543240114488 loss: 0.34359019475667935\n",
            "Round: 889 Weight: [2.40985737 1.19387676] Bias: -1.1149654406046858 loss: 0.34358909671707116\n",
            "Round: 890 Weight: [2.41013353 1.19401893] Bias: -1.115076249535353 loss: 0.3435880046793102\n",
            "Round: 891 Weight: [2.41040894 1.1941607 ] Bias: -1.115186751747999 loss: 0.3435869186090048\n",
            "Round: 892 Weight: [2.41068359 1.1943021 ] Bias: -1.1152969481837476 loss: 0.3435858384719731\n",
            "Round: 893 Weight: [2.4109575 1.1944431] Bias: -1.1154068397803125 loss: 0.34358476423424233\n",
            "Round: 894 Weight: [2.41123066 1.19458373] Bias: -1.115516427472013 loss: 0.34358369586204696\n",
            "Round: 895 Weight: [2.41150307 1.19472396] Bias: -1.1156257121897895 loss: 0.3435826333218272\n",
            "Round: 896 Weight: [2.41177474 1.19486382] Bias: -1.115734694861218 loss: 0.3435815765802286\n",
            "Round: 897 Weight: [2.41204567 1.1950033 ] Bias: -1.1158433764105258 loss: 0.34358052560409913\n",
            "Round: 898 Weight: [2.41231586 1.19514239] Bias: -1.1159517577586067 loss: 0.34357948036048924\n",
            "Round: 899 Weight: [2.41258531 1.19528111] Bias: -1.1160598398230355 loss: 0.3435784408166499\n",
            "Round: 900 Weight: [2.41285403 1.19541945] Bias: -1.1161676235180829 loss: 0.3435774069400312\n",
            "Round: 901 Weight: [2.41312202 1.19555741] Bias: -1.11627510975473 loss: 0.34357637869828156\n",
            "Round: 902 Weight: [2.41338927 1.19569499] Bias: -1.1163822994406845 loss: 0.3435753560592456\n",
            "Round: 903 Weight: [2.4136558  1.19583221] Bias: -1.1164891934803927 loss: 0.3435743389909636\n",
            "Round: 904 Weight: [2.41392161 1.19596904] Bias: -1.1165957927750565 loss: 0.34357332746167\n",
            "Round: 905 Weight: [2.41418668 1.19610551] Bias: -1.1167020982226465 loss: 0.3435723214397917\n",
            "Round: 906 Weight: [2.41445104 1.19624161] Bias: -1.1168081107179169 loss: 0.3435713208939473\n",
            "Round: 907 Weight: [2.41471468 1.19637733] Bias: -1.1169138311524194 loss: 0.34357032579294583\n",
            "Round: 908 Weight: [2.4149776  1.19651269] Bias: -1.1170192604145175 loss: 0.3435693361057851\n",
            "Round: 909 Weight: [2.41523981 1.19664768] Bias: -1.117124399389401 loss: 0.343568351801651\n",
            "Round: 910 Weight: [2.4155013 1.1967823] Bias: -1.1172292489590994 loss: 0.34356737284991556\n",
            "Round: 911 Weight: [2.41576209 1.19691655] Bias: -1.1173338100024968 loss: 0.3435663992201365\n",
            "Round: 912 Weight: [2.41602216 1.19705045] Bias: -1.1174380833953448 loss: 0.34356543088205566\n",
            "Round: 913 Weight: [2.41628153 1.19718397] Bias: -1.117542070010277 loss: 0.3435644678055974\n",
            "Round: 914 Weight: [2.4165402  1.19731714] Bias: -1.1176457707168221 loss: 0.3435635099608682\n",
            "Round: 915 Weight: [2.41679816 1.19744994] Bias: -1.1177491863814184 loss: 0.3435625573181549\n",
            "Round: 916 Weight: [2.41705542 1.19758239] Bias: -1.1178523178674267 loss: 0.3435616098479238\n",
            "Round: 917 Weight: [2.41731198 1.19771447] Bias: -1.117955166035144 loss: 0.34356066752081904\n",
            "Round: 918 Weight: [2.41756785 1.1978462 ] Bias: -1.1180577317418177 loss: 0.3435597303076623\n",
            "Round: 919 Weight: [2.41782302 1.19797757] Bias: -1.1181600158416571 loss: 0.34355879817945073\n",
            "Round: 920 Weight: [2.4180775  1.19810858] Bias: -1.118262019185849 loss: 0.34355787110735636\n",
            "Round: 921 Weight: [2.41833129 1.19823924] Bias: -1.118363742622569 loss: 0.3435569490627245\n",
            "Round: 922 Weight: [2.4185844  1.19836955] Bias: -1.1184651869969955 loss: 0.34355603201707346\n",
            "Round: 923 Weight: [2.41883681 1.1984995 ] Bias: -1.118566353151323 loss: 0.3435551199420924\n",
            "Round: 924 Weight: [2.41908855 1.1986291 ] Bias: -1.118667241924775 loss: 0.34355421280964094\n",
            "Round: 925 Weight: [2.4193396  1.19875835] Bias: -1.118767854153616 loss: 0.34355331059174765\n",
            "Round: 926 Weight: [2.41958997 1.19888725] Bias: -1.1188681906711657 loss: 0.3435524132606091\n",
            "Round: 927 Weight: [2.41983966 1.1990158 ] Bias: -1.118968252307811 loss: 0.343551520788589\n",
            "Round: 928 Weight: [2.42008868 1.199144  ] Bias: -1.119068039891019 loss: 0.34355063314821666\n",
            "Round: 929 Weight: [2.42033702 1.19927186] Bias: -1.1191675542453496 loss: 0.3435497503121864\n",
            "Round: 930 Weight: [2.4205847  1.19939937] Bias: -1.1192667961924678 loss: 0.34354887225335584\n",
            "Round: 931 Weight: [2.4208317  1.19952653] Bias: -1.1193657665511565 loss: 0.3435479989447456\n",
            "Round: 932 Weight: [2.42107803 1.19965336] Bias: -1.1194644661373294 loss: 0.34354713035953777\n",
            "Round: 933 Weight: [2.4213237  1.19977984] Bias: -1.1195628957640424 loss: 0.34354626647107483\n",
            "Round: 934 Weight: [2.4215687  1.19990597] Bias: -1.1196610562415066 loss: 0.34354540725285904\n",
            "Round: 935 Weight: [2.42181305 1.20003177] Bias: -1.1197589483771002 loss: 0.343544552678551\n",
            "Round: 936 Weight: [2.42205673 1.20015723] Bias: -1.1198565729753813 loss: 0.3435437027219686\n",
            "Round: 937 Weight: [2.42229975 1.20028235] Bias: -1.1199539308380992 loss: 0.34354285735708645\n",
            "Round: 938 Weight: [2.42254212 1.20040713] Bias: -1.1200510227642069 loss: 0.3435420165580343\n",
            "Round: 939 Weight: [2.42278383 1.20053157] Bias: -1.1201478495498731 loss: 0.34354118029909664\n",
            "Round: 940 Weight: [2.42302489 1.20065568] Bias: -1.1202444119884938 loss: 0.34354034855471116\n",
            "Round: 941 Weight: [2.4232653  1.20077945] Bias: -1.1203407108707046 loss: 0.3435395212994681\n",
            "Round: 942 Weight: [2.42350506 1.20090289] Bias: -1.1204367469843923 loss: 0.34353869850810914\n",
            "Round: 943 Weight: [2.42374418 1.201026  ] Bias: -1.1205325211147066 loss: 0.3435378801555263\n",
            "Round: 944 Weight: [2.42398265 1.20114878] Bias: -1.1206280340440717 loss: 0.3435370662167614\n",
            "Round: 945 Weight: [2.42422048 1.20127122] Bias: -1.1207232865521983 loss: 0.3435362566670047\n",
            "Round: 946 Weight: [2.42445766 1.20139334] Bias: -1.1208182794160944 loss: 0.343535451481594\n",
            "Round: 947 Weight: [2.42469421 1.20151512] Bias: -1.1209130134100775 loss: 0.34353465063601396\n",
            "Round: 948 Weight: [2.42493012 1.20163658] Bias: -1.1210074893057858 loss: 0.3435338541058947\n",
            "Round: 949 Weight: [2.42516539 1.20175771] Bias: -1.1211017078721892 loss: 0.3435330618670116\n",
            "Round: 950 Weight: [2.42540003 1.20187851] Bias: -1.1211956698756016 loss: 0.34353227389528324\n",
            "Round: 951 Weight: [2.42563404 1.20199899] Bias: -1.1212893760796907 loss: 0.3435314901667718\n",
            "Round: 952 Weight: [2.42586742 1.20211915] Bias: -1.1213828272454907 loss: 0.343530710657681\n",
            "Round: 953 Weight: [2.42610017 1.20223898] Bias: -1.121476024131412 loss: 0.343529935344356\n",
            "Round: 954 Weight: [2.42633229 1.20235849] Bias: -1.1215689674932532 loss: 0.3435291642032823\n",
            "Round: 955 Weight: [2.42656379 1.20247768] Bias: -1.1216616580842123 loss: 0.34352839721108436\n",
            "Round: 956 Weight: [2.42679467 1.20259655] Bias: -1.1217540966548967 loss: 0.34352763434452505\n",
            "Round: 957 Weight: [2.42702492 1.2027151 ] Bias: -1.1218462839533345 loss: 0.3435268755805056\n",
            "Round: 958 Weight: [2.42725456 1.20283333] Bias: -1.121938220724986 loss: 0.3435261208960627\n",
            "Round: 959 Weight: [2.42748358 1.20295124] Bias: -1.1220299077127536 loss: 0.34352537026836993\n",
            "Round: 960 Weight: [2.42771199 1.20306883] Bias: -1.1221213456569927 loss: 0.3435246236747355\n",
            "Round: 961 Weight: [2.42793978 1.20318611] Bias: -1.1222125352955228 loss: 0.3435238810926014\n",
            "Round: 962 Weight: [2.42816696 1.20330308] Bias: -1.1223034773636378 loss: 0.3435231424995432\n",
            "Round: 963 Weight: [2.42839352 1.20341973] Bias: -1.1223941725941162 loss: 0.34352240787326876\n",
            "Round: 964 Weight: [2.42861948 1.20353607] Bias: -1.1224846217172326 loss: 0.3435216771916176\n",
            "Round: 965 Weight: [2.42884484 1.20365209] Bias: -1.122574825460767 loss: 0.34352095043256\n",
            "Round: 966 Weight: [2.42906959 1.20376781] Bias: -1.1226647845500162 loss: 0.3435202275741957\n",
            "Round: 967 Weight: [2.42929373 1.20388321] Bias: -1.1227544997078032 loss: 0.3435195085947544\n",
            "Round: 968 Weight: [2.42951728 1.20399831] Bias: -1.122843971654488 loss: 0.343518793472593\n",
            "Round: 969 Weight: [2.42974022 1.20411309] Bias: -1.1229332011079782 loss: 0.3435180821861968\n",
            "Round: 970 Weight: [2.42996257 1.20422757] Bias: -1.1230221887837384 loss: 0.3435173747141769\n",
            "Round: 971 Weight: [2.43018432 1.20434174] Bias: -1.1231109353948006 loss: 0.3435166710352711\n",
            "Round: 972 Weight: [2.43040548 1.20445561] Bias: -1.1231994416517745 loss: 0.34351597112834165\n",
            "Round: 973 Weight: [2.43062604 1.20456917] Bias: -1.1232877082628576 loss: 0.3435152749723753\n",
            "Round: 974 Weight: [2.43084602 1.20468243] Bias: -1.1233757359338448 loss: 0.3435145825464821\n",
            "Round: 975 Weight: [2.4310654  1.20479538] Bias: -1.1234635253681382 loss: 0.3435138938298949\n",
            "Round: 976 Weight: [2.4312842  1.20490803] Bias: -1.1235510772667576 loss: 0.34351320880196873\n",
            "Round: 977 Weight: [2.43150241 1.20502038] Bias: -1.1236383923283497 loss: 0.3435125274421794\n",
            "Round: 978 Weight: [2.43172003 1.20513243] Bias: -1.1237254712491982 loss: 0.3435118497301232\n",
            "Round: 979 Weight: [2.43193708 1.20524418] Bias: -1.1238123147232335 loss: 0.34351117564551625\n",
            "Round: 980 Weight: [2.43215354 1.20535563] Bias: -1.1238989234420425 loss: 0.34351050516819337\n",
            "Round: 981 Weight: [2.43236942 1.20546678] Bias: -1.1239852980948775 loss: 0.34350983827810766\n",
            "Round: 982 Weight: [2.43258473 1.20557764] Bias: -1.1240714393686666 loss: 0.3435091749553294\n",
            "Round: 983 Weight: [2.43279946 1.20568819] Bias: -1.1241573479480231 loss: 0.3435085151800459\n",
            "Round: 984 Weight: [2.43301362 1.20579846] Bias: -1.1242430245152544 loss: 0.34350785893256\n",
            "Round: 985 Weight: [2.4332272  1.20590843] Bias: -1.1243284697503722 loss: 0.3435072061932899\n",
            "Round: 986 Weight: [2.43344021 1.2060181 ] Bias: -1.124413684331101 loss: 0.34350655694276855\n",
            "Round: 987 Weight: [2.43365266 1.20612748] Bias: -1.1244986689328884 loss: 0.34350591116164225\n",
            "Round: 988 Weight: [2.43386454 1.20623657] Bias: -1.1245834242289137 loss: 0.34350526883067056\n",
            "Round: 989 Weight: [2.43407585 1.20634537] Bias: -1.1246679508900972 loss: 0.34350462993072556\n",
            "Round: 990 Weight: [2.43428659 1.20645388] Bias: -1.1247522495851097 loss: 0.3435039944427904\n",
            "Round: 991 Weight: [2.43449678 1.20656209] Bias: -1.124836320980381 loss: 0.34350336234795986\n",
            "Round: 992 Weight: [2.4347064  1.20667002] Bias: -1.1249201657401104 loss: 0.34350273362743855\n",
            "Round: 993 Weight: [2.43491546 1.20677766] Bias: -1.125003784526274 loss: 0.3435021082625408\n",
            "Round: 994 Weight: [2.43512397 1.20688502] Bias: -1.1250871779986347 loss: 0.34350148623468985\n",
            "Round: 995 Weight: [2.43533191 1.20699209] Bias: -1.125170346814751 loss: 0.34350086752541714\n",
            "Round: 996 Weight: [2.43553931 1.20709887] Bias: -1.1252532916299858 loss: 0.3435002521163614\n",
            "Round: 997 Weight: [2.43574615 1.20720537] Bias: -1.1253360130975156 loss: 0.3434996399892685\n",
            "Round: 998 Weight: [2.43595244 1.20731158] Bias: -1.1254185118683389 loss: 0.3434990311259907\n",
            "Round: 999 Weight: [2.43615818 1.20741751] Bias: -1.1255007885912849 loss: 0.3434984255084852\n",
            "Round: 1000 Weight: [2.43636337 1.20752316] Bias: -1.1255828439130227 loss: 0.34349782311881444\n",
            "Round: 1001 Weight: [2.43656801 1.20762853] Bias: -1.12566467847807 loss: 0.3434972239391451\n",
            "Round: 1002 Weight: [2.43677211 1.20773361] Bias: -1.125746292928801 loss: 0.34349662795174757\n",
            "Round: 1003 Weight: [2.43697567 1.20783842] Bias: -1.125827687905456 loss: 0.3434960351389948\n",
            "Round: 1004 Weight: [2.43717868 1.20794295] Bias: -1.1259088640461494 loss: 0.34349544548336225\n",
            "Round: 1005 Weight: [2.43738115 1.2080472 ] Bias: -1.1259898219868782 loss: 0.3434948589674272\n",
            "Round: 1006 Weight: [2.43758309 1.20815117] Bias: -1.1260705623615306 loss: 0.34349427557386764\n",
            "Round: 1007 Weight: [2.43778448 1.20825486] Bias: -1.1261510858018944 loss: 0.34349369528546236\n",
            "Round: 1008 Weight: [2.43798534 1.20835828] Bias: -1.1262313929376655 loss: 0.3434931180850896\n",
            "Round: 1009 Weight: [2.43818567 1.20846142] Bias: -1.1263114843964561 loss: 0.3434925439557268\n",
            "Round: 1010 Weight: [2.43838546 1.20856429] Bias: -1.1263913608038034 loss: 0.3434919728804502\n",
            "Round: 1011 Weight: [2.43858472 1.20866689] Bias: -1.1264710227831771 loss: 0.34349140484243373\n",
            "Round: 1012 Weight: [2.43878345 1.20876921] Bias: -1.1265504709559881 loss: 0.34349083982494905\n",
            "Round: 1013 Weight: [2.43898166 1.20887127] Bias: -1.1266297059415973 loss: 0.3434902778113639\n",
            "Round: 1014 Weight: [2.43917933 1.20897305] Bias: -1.1267087283573223 loss: 0.34348971878514284\n",
            "Round: 1015 Weight: [2.43937648 1.20907456] Bias: -1.1267875388184467 loss: 0.3434891627298456\n",
            "Round: 1016 Weight: [2.43957311 1.2091758 ] Bias: -1.1268661379382279 loss: 0.34348860962912703\n",
            "Round: 1017 Weight: [2.43976921 1.20927677] Bias: -1.126944526327905 loss: 0.3434880594667363\n",
            "Round: 1018 Weight: [2.4399648  1.20937747] Bias: -1.1270227045967067 loss: 0.3434875122265164\n",
            "Round: 1019 Weight: [2.44015986 1.20947791] Bias: -1.1271006733518594 loss: 0.34348696789240357\n",
            "Round: 1020 Weight: [2.44035441 1.20957807] Bias: -1.127178433198595 loss: 0.34348642644842653\n",
            "Round: 1021 Weight: [2.44054844 1.20967798] Bias: -1.127255984740159 loss: 0.3434858878787063\n",
            "Round: 1022 Weight: [2.44074195 1.20977762] Bias: -1.1273333285778184 loss: 0.34348535216745535\n",
            "Round: 1023 Weight: [2.44093495 1.20987699] Bias: -1.1274104653108687 loss: 0.343484819298977\n",
            "Round: 1024 Weight: [2.44112744 1.2099761 ] Bias: -1.127487395536643 loss: 0.3434842892576652\n",
            "Round: 1025 Weight: [2.44131942 1.21007495] Bias: -1.127564119850518 loss: 0.34348376202800335\n",
            "Round: 1026 Weight: [2.44151089 1.21017353] Bias: -1.1276406388459235 loss: 0.34348323759456456\n",
            "Round: 1027 Weight: [2.44170185 1.21027185] Bias: -1.127716953114349 loss: 0.3434827159420104\n",
            "Round: 1028 Weight: [2.44189231 1.21036992] Bias: -1.127793063245351 loss: 0.3434821970550907\n",
            "Round: 1029 Weight: [2.44208226 1.21046772] Bias: -1.1278689698265618 loss: 0.34348168091864295\n",
            "Round: 1030 Weight: [2.4422717  1.21056526] Bias: -1.127944673443696 loss: 0.343481167517592\n",
            "Round: 1031 Weight: [2.44246065 1.21066255] Bias: -1.128020174680558 loss: 0.3434806568369487\n",
            "Round: 1032 Weight: [2.44264909 1.21075958] Bias: -1.1280954741190503 loss: 0.3434801488618105\n",
            "Round: 1033 Weight: [2.44283704 1.21085635] Bias: -1.1281705723391802 loss: 0.3434796435773602\n",
            "Round: 1034 Weight: [2.44302448 1.21095286] Bias: -1.1282454699190672 loss: 0.3434791409688657\n",
            "Round: 1035 Weight: [2.44321143 1.21104912] Bias: -1.1283201674349508 loss: 0.3434786410216793\n",
            "Round: 1036 Weight: [2.44339789 1.21114513] Bias: -1.1283946654611974 loss: 0.34347814372123703\n",
            "Round: 1037 Weight: [2.44358385 1.21124088] Bias: -1.1284689645703079 loss: 0.34347764905305894\n",
            "Round: 1038 Weight: [2.44376932 1.21133637] Bias: -1.1285430653329247 loss: 0.3434771570027475\n",
            "Round: 1039 Weight: [2.4439543  1.21143162] Bias: -1.1286169683178389 loss: 0.34347666755598794\n",
            "Round: 1040 Weight: [2.44413879 1.21152661] Bias: -1.1286906740919977 loss: 0.34347618069854746\n",
            "Round: 1041 Weight: [2.44432279 1.21162135] Bias: -1.1287641832205118 loss: 0.34347569641627446\n",
            "Round: 1042 Weight: [2.44450631 1.21171584] Bias: -1.1288374962666616 loss: 0.34347521469509845\n",
            "Round: 1043 Weight: [2.44468933 1.21181008] Bias: -1.1289106137919052 loss: 0.3434747355210294\n",
            "Round: 1044 Weight: [2.44487188 1.21190407] Bias: -1.1289835363558849 loss: 0.3434742588801573\n",
            "Round: 1045 Weight: [2.44505394 1.21199782] Bias: -1.1290562645164344 loss: 0.3434737847586514\n",
            "Round: 1046 Weight: [2.44523553 1.21209131] Bias: -1.1291287988295857 loss: 0.3434733131427603\n",
            "Round: 1047 Weight: [2.44541663 1.21218456] Bias: -1.1292011398495765 loss: 0.3434728440188108\n",
            "Round: 1048 Weight: [2.44559725 1.21227756] Bias: -1.1292732881288563 loss: 0.34347237737320807\n",
            "Round: 1049 Weight: [2.4457774  1.21237032] Bias: -1.1293452442180938 loss: 0.34347191319243425\n",
            "Round: 1050 Weight: [2.44595707 1.21246283] Bias: -1.1294170086661839 loss: 0.34347145146304947\n",
            "Round: 1051 Weight: [2.44613626 1.2125551 ] Bias: -1.1294885820202538 loss: 0.34347099217168986\n",
            "Round: 1052 Weight: [2.44631499 1.21264712] Bias: -1.1295599648256707 loss: 0.34347053530506777\n",
            "Round: 1053 Weight: [2.44649324 1.2127389 ] Bias: -1.1296311576260478 loss: 0.34347008084997144\n",
            "Round: 1054 Weight: [2.44667102 1.21283044] Bias: -1.1297021609632516 loss: 0.3434696287932644\n",
            "Round: 1055 Weight: [2.44684833 1.21292173] Bias: -1.129772975377408 loss: 0.34346917912188485\n",
            "Round: 1056 Weight: [2.44702517 1.21301279] Bias: -1.1298436014069093 loss: 0.34346873182284543\n",
            "Round: 1057 Weight: [2.44720155 1.21310361] Bias: -1.1299140395884208 loss: 0.34346828688323244\n",
            "Round: 1058 Weight: [2.44737746 1.21319418] Bias: -1.1299842904568878 loss: 0.34346784429020594\n",
            "Round: 1059 Weight: [2.44755291 1.21328452] Bias: -1.1300543545455408 loss: 0.3434674040309988\n",
            "Round: 1060 Weight: [2.44772789 1.21337462] Bias: -1.130124232385904 loss: 0.34346696609291666\n",
            "Round: 1061 Weight: [2.44790242 1.21346448] Bias: -1.1301939245077999 loss: 0.34346653046333697\n",
            "Round: 1062 Weight: [2.44807648 1.21355411] Bias: -1.1302634314393571 loss: 0.3434660971297094\n",
            "Round: 1063 Weight: [2.44825008 1.21364349] Bias: -1.1303327537070165 loss: 0.34346566607955414\n",
            "Round: 1064 Weight: [2.44842323 1.21373265] Bias: -1.1304018918355367 loss: 0.3434652373004628\n",
            "Round: 1065 Weight: [2.44859592 1.21382157] Bias: -1.1304708463480018 loss: 0.3434648107800974\n",
            "Round: 1066 Weight: [2.44876816 1.21391025] Bias: -1.130539617765827 loss: 0.34346438650618955\n",
            "Round: 1067 Weight: [2.44893994 1.2139987 ] Bias: -1.1306082066087646 loss: 0.34346396446654065\n",
            "Round: 1068 Weight: [2.44911127 1.21408692] Bias: -1.1306766133949115 loss: 0.34346354464902135\n",
            "Round: 1069 Weight: [2.44928215 1.2141749 ] Bias: -1.130744838640714 loss: 0.343463127041571\n",
            "Round: 1070 Weight: [2.44945258 1.21426266] Bias: -1.130812882860975 loss: 0.34346271163219694\n",
            "Round: 1071 Weight: [2.44962256 1.21435018] Bias: -1.1308807465688597 loss: 0.3434622984089749\n",
            "Round: 1072 Weight: [2.44979209 1.21443747] Bias: -1.1309484302759025 loss: 0.34346188736004774\n",
            "Round: 1073 Weight: [2.44996118 1.21452453] Bias: -1.1310159344920123 loss: 0.34346147847362585\n",
            "Round: 1074 Weight: [2.45012982 1.21461137] Bias: -1.1310832597254787 loss: 0.3434610717379855\n",
            "Round: 1075 Weight: [2.45029802 1.21469797] Bias: -1.1311504064829787 loss: 0.3434606671414702\n",
            "Round: 1076 Weight: [2.45046578 1.21478435] Bias: -1.1312173752695824 loss: 0.343460264672489\n",
            "Round: 1077 Weight: [2.45063309 1.2148705 ] Bias: -1.131284166588759 loss: 0.34345986431951614\n",
            "Round: 1078 Weight: [2.45079997 1.21495643] Bias: -1.1313507809423826 loss: 0.3434594660710913\n",
            "Round: 1079 Weight: [2.4509664  1.21504212] Bias: -1.1314172188307388 loss: 0.343459069915819\n",
            "Round: 1080 Weight: [2.4511324 1.2151276] Bias: -1.13148348075253 loss: 0.3434586758423677\n",
            "Round: 1081 Weight: [2.45129797 1.21521284] Bias: -1.1315495672048816 loss: 0.34345828383946997\n",
            "Round: 1082 Weight: [2.45146309 1.21529787] Bias: -1.1316154786833483 loss: 0.3434578938959223\n",
            "Round: 1083 Weight: [2.45162779 1.21538267] Bias: -1.1316812156819192 loss: 0.34345750600058383\n",
            "Round: 1084 Weight: [2.45179205 1.21546725] Bias: -1.1317467786930238 loss: 0.34345712014237684\n",
            "Round: 1085 Weight: [2.45195588 1.2155516 ] Bias: -1.1318121682075386 loss: 0.34345673631028606\n",
            "Round: 1086 Weight: [2.45211928 1.21563574] Bias: -1.1318773847147918 loss: 0.34345635449335804\n",
            "Round: 1087 Weight: [2.45228225 1.21571965] Bias: -1.1319424287025701 loss: 0.34345597468070127\n",
            "Round: 1088 Weight: [2.45244479 1.21580335] Bias: -1.1320073006571234 loss: 0.3434555968614854\n",
            "Round: 1089 Weight: [2.45260691 1.21588682] Bias: -1.132072001063171 loss: 0.3434552210249414\n",
            "Round: 1090 Weight: [2.4527686  1.21597007] Bias: -1.132136530403908 loss: 0.3434548471603602\n",
            "Round: 1091 Weight: [2.45292986 1.21605311] Bias: -1.1322008891610094 loss: 0.34345447525709355\n",
            "Round: 1092 Weight: [2.45309071 1.21613593] Bias: -1.1322650778146373 loss: 0.34345410530455295\n",
            "Round: 1093 Weight: [2.45325113 1.21621853] Bias: -1.1323290968434454 loss: 0.3434537372922092\n",
            "Round: 1094 Weight: [2.45341113 1.21630092] Bias: -1.132392946724585 loss: 0.34345337120959263\n",
            "Round: 1095 Weight: [2.45357071 1.21638308] Bias: -1.132456627933711 loss: 0.3434530070462919\n",
            "Round: 1096 Weight: [2.45372987 1.21646504] Bias: -1.132520140944986 loss: 0.34345264479195475\n",
            "Round: 1097 Weight: [2.45388862 1.21654678] Bias: -1.1325834862310882 loss: 0.3434522844362865\n",
            "Round: 1098 Weight: [2.45404695 1.2166283 ] Bias: -1.132646664263214 loss: 0.34345192596905066\n",
            "Round: 1099 Weight: [2.45420486 1.21670961] Bias: -1.1327096755110861 loss: 0.343451569380068\n",
            "Round: 1100 Weight: [2.45436236 1.21679071] Bias: -1.132772520442957 loss: 0.34345121465921635\n",
            "Round: 1101 Weight: [2.45451945 1.21687159] Bias: -1.1328351995256156 loss: 0.34345086179643025\n",
            "Round: 1102 Weight: [2.45467612 1.21695227] Bias: -1.1328977132243918 loss: 0.34345051078170097\n",
            "Round: 1103 Weight: [2.45483239 1.21703273] Bias: -1.1329600620031626 loss: 0.34345016160507563\n",
            "Round: 1104 Weight: [2.45498825 1.21711298] Bias: -1.1330222463243567 loss: 0.3434498142566571\n",
            "Round: 1105 Weight: [2.4551437  1.21719302] Bias: -1.1330842666489602 loss: 0.34344946872660376\n",
            "Round: 1106 Weight: [2.45529874 1.21727285] Bias: -1.133146123436522 loss: 0.343449125005129\n",
            "Round: 1107 Weight: [2.45545337 1.21735247] Bias: -1.1332078171451592 loss: 0.34344878308250115\n",
            "Round: 1108 Weight: [2.4556076  1.21743189] Bias: -1.1332693482315612 loss: 0.343448442949043\n",
            "Round: 1109 Weight: [2.45576143 1.21751109] Bias: -1.1333307171509968 loss: 0.3434481045951312\n",
            "Round: 1110 Weight: [2.45591485 1.21759009] Bias: -1.1333919243573174 loss: 0.34344776801119636\n",
            "Round: 1111 Weight: [2.45606788 1.21766888] Bias: -1.1334529703029639 loss: 0.3434474331877228\n",
            "Round: 1112 Weight: [2.4562205  1.21774747] Bias: -1.1335138554389705 loss: 0.3434471001152477\n",
            "Round: 1113 Weight: [2.45637272 1.21782585] Bias: -1.133574580214971 loss: 0.34344676878436126\n",
            "Round: 1114 Weight: [2.45652455 1.21790403] Bias: -1.1336351450792028 loss: 0.3434464391857063\n",
            "Round: 1115 Weight: [2.45667598 1.217982  ] Bias: -1.1336955504785127 loss: 0.34344611130997776\n",
            "Round: 1116 Weight: [2.45682701 1.21805977] Bias: -1.1337557968583616 loss: 0.3434457851479225\n",
            "Round: 1117 Weight: [2.45697765 1.21813733] Bias: -1.13381588466283 loss: 0.3434454606903394\n",
            "Round: 1118 Weight: [2.45712789 1.21821469] Bias: -1.1338758143346224 loss: 0.3434451379280779\n",
            "Round: 1119 Weight: [2.45727774 1.21829185] Bias: -1.1339355863150726 loss: 0.3434448168520392\n",
            "Round: 1120 Weight: [2.4574272  1.21836881] Bias: -1.133995201044149 loss: 0.3434444974531749\n",
            "Round: 1121 Weight: [2.45757627 1.21844556] Bias: -1.1340546589604588 loss: 0.3434441797224872\n",
            "Round: 1122 Weight: [2.45772495 1.21852212] Bias: -1.1341139605012536 loss: 0.34344386365102814\n",
            "Round: 1123 Weight: [2.45787324 1.21859848] Bias: -1.1341731061024338 loss: 0.3434435492298999\n",
            "Round: 1124 Weight: [2.45802115 1.21867463] Bias: -1.134232096198554 loss: 0.343443236450254\n",
            "Round: 1125 Weight: [2.45816867 1.21875059] Bias: -1.134290931222827 loss: 0.3434429253032914\n",
            "Round: 1126 Weight: [2.4583158  1.21882635] Bias: -1.13434961160713 loss: 0.3434426157802619\n",
            "Round: 1127 Weight: [2.45846255 1.21890191] Bias: -1.1344081377820083 loss: 0.3434423078724641\n",
            "Round: 1128 Weight: [2.45860892 1.21897728] Bias: -1.1344665101766802 loss: 0.3434420015712449\n",
            "Round: 1129 Weight: [2.4587549  1.21905245] Bias: -1.1345247292190423 loss: 0.3434416968679992\n",
            "Round: 1130 Weight: [2.4589005  1.21912742] Bias: -1.1345827953356737 loss: 0.3434413937541701\n",
            "Round: 1131 Weight: [2.45904573 1.21920219] Bias: -1.1346407089518413 loss: 0.34344109222124786\n",
            "Round: 1132 Weight: [2.45919057 1.21927678] Bias: -1.134698470491504 loss: 0.3434407922607701\n",
            "Round: 1133 Weight: [2.45933504 1.21935116] Bias: -1.1347560803773173 loss: 0.34344049386432196\n",
            "Round: 1134 Weight: [2.45947913 1.21942535] Bias: -1.134813539030639 loss: 0.3434401970235343\n",
            "Round: 1135 Weight: [2.45962284 1.21949935] Bias: -1.1348708468715327 loss: 0.3434399017300853\n",
            "Round: 1136 Weight: [2.45976618 1.21957316] Bias: -1.1349280043187726 loss: 0.34343960797569906\n",
            "Round: 1137 Weight: [2.45990915 1.21964677] Bias: -1.1349850117898488 loss: 0.3434393157521454\n",
            "Round: 1138 Weight: [2.46005174 1.2197202 ] Bias: -1.1350418697009712 loss: 0.34343902505124013\n",
            "Round: 1139 Weight: [2.46019396 1.21979343] Bias: -1.1350985784670746 loss: 0.34343873586484414\n",
            "Round: 1140 Weight: [2.46033581 1.21986647] Bias: -1.1351551385018228 loss: 0.3434384481848634\n",
            "Round: 1141 Weight: [2.46047729 1.21993932] Bias: -1.1352115502176132 loss: 0.3434381620032491\n",
            "Round: 1142 Weight: [2.4606184  1.22001198] Bias: -1.1352678140255816 loss: 0.3434378773119967\n",
            "Round: 1143 Weight: [2.46075915 1.22008445] Bias: -1.1353239303356066 loss: 0.343437594103146\n",
            "Round: 1144 Weight: [2.46089953 1.22015673] Bias: -1.1353798995563138 loss: 0.3434373123687809\n",
            "Round: 1145 Weight: [2.46103954 1.22022882] Bias: -1.1354357220950804 loss: 0.34343703210102944\n",
            "Round: 1146 Weight: [2.46117919 1.22030073] Bias: -1.13549139835804 loss: 0.34343675329206275\n",
            "Round: 1147 Weight: [2.46131847 1.22037245] Bias: -1.1355469287500863 loss: 0.34343647593409554\n",
            "Round: 1148 Weight: [2.4614574  1.22044398] Bias: -1.1356023136748783 loss: 0.34343620001938535\n",
            "Round: 1149 Weight: [2.46159596 1.22051532] Bias: -1.1356575535348439 loss: 0.3434359255402328\n",
            "Round: 1150 Weight: [2.46173416 1.22058649] Bias: -1.1357126487311846 loss: 0.34343565248898095\n",
            "Round: 1151 Weight: [2.461872   1.22065746] Bias: -1.1357675996638805 loss: 0.34343538085801517\n",
            "Round: 1152 Weight: [2.46200948 1.22072825] Bias: -1.1358224067316933 loss: 0.3434351106397628\n",
            "Round: 1153 Weight: [2.4621466  1.22079886] Bias: -1.1358770703321717 loss: 0.34343484182669315\n",
            "Round: 1154 Weight: [2.46228337 1.22086928] Bias: -1.1359315908616552 loss: 0.34343457441131703\n",
            "Round: 1155 Weight: [2.46241978 1.22093952] Bias: -1.1359859687152782 loss: 0.34343430838618666\n",
            "Round: 1156 Weight: [2.46255584 1.22100958] Bias: -1.136040204286975 loss: 0.34343404374389525\n",
            "Round: 1157 Weight: [2.46269154 1.22107945] Bias: -1.136094297969483 loss: 0.34343378047707696\n",
            "Round: 1158 Weight: [2.46282689 1.22114914] Bias: -1.1361482501543478 loss: 0.34343351857840654\n",
            "Round: 1159 Weight: [2.46296189 1.22121865] Bias: -1.136202061231927 loss: 0.34343325804059915\n",
            "Round: 1160 Weight: [2.46309654 1.22128799] Bias: -1.1362557315913944 loss: 0.34343299885641\n",
            "Round: 1161 Weight: [2.46323084 1.22135714] Bias: -1.136309261620744 loss: 0.34343274101863436\n",
            "Round: 1162 Weight: [2.46336479 1.22142611] Bias: -1.1363626517067946 loss: 0.3434324845201071\n",
            "Round: 1163 Weight: [2.46349839 1.2214949 ] Bias: -1.1364159022351936 loss: 0.34343222935370277\n",
            "Round: 1164 Weight: [2.46363164 1.22156351] Bias: -1.136469013590421 loss: 0.34343197551233484\n",
            "Round: 1165 Weight: [2.46376455 1.22163195] Bias: -1.1365219861557934 loss: 0.3434317229889558\n",
            "Round: 1166 Weight: [2.46389711 1.22170021] Bias: -1.136574820313469 loss: 0.34343147177655736\n",
            "Round: 1167 Weight: [2.46402933 1.22176829] Bias: -1.1366275164444504 loss: 0.34343122186816916\n",
            "Round: 1168 Weight: [2.46416121 1.22183619] Bias: -1.1366800749285895 loss: 0.3434309732568598\n",
            "Round: 1169 Weight: [2.46429274 1.22190392] Bias: -1.1367324961445908 loss: 0.3434307259357356\n",
            "Round: 1170 Weight: [2.46442393 1.22197147] Bias: -1.1367847804700166 loss: 0.3434304798979407\n",
            "Round: 1171 Weight: [2.46455478 1.22203884] Bias: -1.1368369282812896 loss: 0.3434302351366573\n",
            "Round: 1172 Weight: [2.46468529 1.22210605] Bias: -1.1368889399536974 loss: 0.34342999164510485\n",
            "Round: 1173 Weight: [2.46481546 1.22217307] Bias: -1.136940815861397 loss: 0.34342974941654\n",
            "Round: 1174 Weight: [2.4649453  1.22223993] Bias: -1.136992556377418 loss: 0.3434295084442564\n",
            "Round: 1175 Weight: [2.4650748 1.2223066] Bias: -1.1370441618736669 loss: 0.34342926872158475\n",
            "Round: 1176 Weight: [2.46520396 1.22237311] Bias: -1.137095632720931 loss: 0.34342903024189214\n",
            "Round: 1177 Weight: [2.46533278 1.22243945] Bias: -1.1371469692888818 loss: 0.34342879299858226\n",
            "Round: 1178 Weight: [2.46546128 1.22250561] Bias: -1.1371981719460797 loss: 0.3434285569850946\n",
            "Round: 1179 Weight: [2.46558944 1.2225716 ] Bias: -1.1372492410599773 loss: 0.34342832219490516\n",
            "Round: 1180 Weight: [2.46571726 1.22263742] Bias: -1.1373001769969229 loss: 0.34342808862152535\n",
            "Round: 1181 Weight: [2.46584476 1.22270307] Bias: -1.1373509801221655 loss: 0.34342785625850203\n",
            "Round: 1182 Weight: [2.46597193 1.22276854] Bias: -1.1374016507998574 loss: 0.34342762509941804\n",
            "Round: 1183 Weight: [2.46609876 1.22283385] Bias: -1.1374521893930587 loss: 0.3434273951378907\n",
            "Round: 1184 Weight: [2.46622527 1.22289899] Bias: -1.1375025962637408 loss: 0.3434271663675728\n",
            "Round: 1185 Weight: [2.46635145 1.22296396] Bias: -1.13755287177279 loss: 0.3434269387821513\n",
            "Round: 1186 Weight: [2.4664773  1.22302877] Bias: -1.137603016280012 loss: 0.3434267123753484\n",
            "Round: 1187 Weight: [2.46660283 1.2230934 ] Bias: -1.1376530301441343 loss: 0.34342648714092017\n",
            "Round: 1188 Weight: [2.46672803 1.22315787] Bias: -1.1377029137228114 loss: 0.34342626307265706\n",
            "Round: 1189 Weight: [2.46685291 1.22322217] Bias: -1.1377526673726275 loss: 0.34342604016438344\n",
            "Round: 1190 Weight: [2.46697746 1.2232863 ] Bias: -1.1378022914491004 loss: 0.34342581840995756\n",
            "Round: 1191 Weight: [2.46710169 1.22335027] Bias: -1.1378517863066855 loss: 0.34342559780327114\n",
            "Round: 1192 Weight: [2.4672256  1.22341407] Bias: -1.137901152298779 loss: 0.34342537833824915\n",
            "Round: 1193 Weight: [2.46734919 1.22347771] Bias: -1.1379503897777217 loss: 0.34342516000885004\n",
            "Round: 1194 Weight: [2.46747246 1.22354118] Bias: -1.1379994990948028 loss: 0.3434249428090651\n",
            "Round: 1195 Weight: [2.46759541 1.22360449] Bias: -1.1380484806002633 loss: 0.3434247267329186\n",
            "Round: 1196 Weight: [2.46771804 1.22366763] Bias: -1.1380973346432994 loss: 0.3434245117744673\n",
            "Round: 1197 Weight: [2.46784035 1.22373061] Bias: -1.1381460615720669 loss: 0.34342429792780027\n",
            "Round: 1198 Weight: [2.46796235 1.22379343] Bias: -1.1381946617336838 loss: 0.3434240851870393\n",
            "Round: 1199 Weight: [2.46808403 1.22385608] Bias: -1.1382431354742344 loss: 0.3434238735463378\n",
            "Round: 1200 Weight: [2.4682054  1.22391858] Bias: -1.1382914831387725 loss: 0.3434236629998812\n",
            "Round: 1201 Weight: [2.46832645 1.22398091] Bias: -1.1383397050713253 loss: 0.34342345354188697\n",
            "Round: 1202 Weight: [2.46844719 1.22404308] Bias: -1.1383878016148965 loss: 0.3434232451666035\n",
            "Round: 1203 Weight: [2.46856762 1.22410509] Bias: -1.1384357731114703 loss: 0.3434230378683112\n",
            "Round: 1204 Weight: [2.46868774 1.22416694] Bias: -1.1384836199020143 loss: 0.343422831641321\n",
            "Round: 1205 Weight: [2.46880755 1.22422863] Bias: -1.1385313423264833 loss: 0.34342262647997546\n",
            "Round: 1206 Weight: [2.46892704 1.22429016] Bias: -1.1385789407238227 loss: 0.34342242237864745\n",
            "Round: 1207 Weight: [2.46904623 1.22435153] Bias: -1.1386264154319719 loss: 0.34342221933174083\n",
            "Round: 1208 Weight: [2.46916511 1.22441274] Bias: -1.1386737667878677 loss: 0.3434220173336898\n",
            "Round: 1209 Weight: [2.46928368 1.22447379] Bias: -1.1387209951274477 loss: 0.34342181637895874\n",
            "Round: 1210 Weight: [2.46940195 1.22453469] Bias: -1.138768100785654 loss: 0.3434216164620424\n",
            "Round: 1211 Weight: [2.46951991 1.22459543] Bias: -1.1388150840964362 loss: 0.3434214175774654\n",
            "Round: 1212 Weight: [2.46963757 1.22465601] Bias: -1.1388619453927546 loss: 0.343421219719782\n",
            "Round: 1213 Weight: [2.46975492 1.22471644] Bias: -1.1389086850065842 loss: 0.3434210228835762\n",
            "Round: 1214 Weight: [2.46987197 1.22477671] Bias: -1.1389553032689175 loss: 0.3434208270634615\n",
            "Round: 1215 Weight: [2.46998871 1.22483682] Bias: -1.1390018005097677 loss: 0.34342063225408065\n",
            "Round: 1216 Weight: [2.47010516 1.22489678] Bias: -1.139048177058173 loss: 0.34342043845010534\n",
            "Round: 1217 Weight: [2.4702213  1.22495658] Bias: -1.1390944332421986 loss: 0.34342024564623647\n",
            "Round: 1218 Weight: [2.47033715 1.22501623] Bias: -1.1391405693889407 loss: 0.3434200538372035\n",
            "Round: 1219 Weight: [2.47045269 1.22507573] Bias: -1.1391865858245296 loss: 0.3434198630177649\n",
            "Round: 1220 Weight: [2.47056794 1.22513507] Bias: -1.1392324828741334 loss: 0.34341967318270694\n",
            "Round: 1221 Weight: [2.47068289 1.22519426] Bias: -1.1392782608619603 loss: 0.3434194843268448\n",
            "Round: 1222 Weight: [2.47079755 1.22525329] Bias: -1.1393239201112628 loss: 0.3434192964450216\n",
            "Round: 1223 Weight: [2.4709119  1.22531218] Bias: -1.1393694609443403 loss: 0.3434191095321084\n",
            "Round: 1224 Weight: [2.47102597 1.22537091] Bias: -1.1394148836825426 loss: 0.343418923583004\n",
            "Round: 1225 Weight: [2.47113974 1.22542949] Bias: -1.139460188646273 loss: 0.3434187385926352\n",
            "Round: 1226 Weight: [2.47125321 1.22548792] Bias: -1.1395053761549914 loss: 0.34341855455595577\n",
            "Round: 1227 Weight: [2.47136639 1.2255462 ] Bias: -1.1395504465272175 loss: 0.3434183714679474\n",
            "Round: 1228 Weight: [2.47147928 1.22560432] Bias: -1.1395954000805342 loss: 0.3434181893236185\n",
            "Round: 1229 Weight: [2.47159188 1.2256623 ] Bias: -1.1396402371315904 loss: 0.34341800811800494\n",
            "Round: 1230 Weight: [2.47170419 1.22572013] Bias: -1.1396849579961041 loss: 0.3434178278461692\n",
            "Round: 1231 Weight: [2.47181621 1.22577781] Bias: -1.1397295629888662 loss: 0.3434176485032005\n",
            "Round: 1232 Weight: [2.47192794 1.22583534] Bias: -1.1397740524237425 loss: 0.343417470084215\n",
            "Round: 1233 Weight: [2.47203938 1.22589272] Bias: -1.139818426613678 loss: 0.34341729258435466\n",
            "Round: 1234 Weight: [2.47215054 1.22594996] Bias: -1.1398626858706986 loss: 0.34341711599878855\n",
            "Round: 1235 Weight: [2.47226141 1.22600705] Bias: -1.1399068305059157 loss: 0.3434169403227111\n",
            "Round: 1236 Weight: [2.47237199 1.22606399] Bias: -1.139950860829528 loss: 0.3434167655513432\n",
            "Round: 1237 Weight: [2.47248229 1.22612078] Bias: -1.139994777150825 loss: 0.3434165916799315\n",
            "Round: 1238 Weight: [2.47259231 1.22617743] Bias: -1.1400385797781905 loss: 0.3434164187037482\n",
            "Round: 1239 Weight: [2.47270204 1.22623393] Bias: -1.1400822690191048 loss: 0.34341624661809145\n",
            "Round: 1240 Weight: [2.47281149 1.22629028] Bias: -1.1401258451801481 loss: 0.3434160754182842\n",
            "Round: 1241 Weight: [2.47292065 1.2263465 ] Bias: -1.1401693085670037 loss: 0.34341590509967534\n",
            "Round: 1242 Weight: [2.47302954 1.22640256] Bias: -1.1402126594844606 loss: 0.3434157356576384\n",
            "Round: 1243 Weight: [2.47313814 1.22645848] Bias: -1.1402558982364166 loss: 0.343415567087572\n",
            "Round: 1244 Weight: [2.47324647 1.22651426] Bias: -1.1402990251258813 loss: 0.3434153993848998\n",
            "Round: 1245 Weight: [2.47335452 1.22656989] Bias: -1.1403420404549791 loss: 0.34341523254507\n",
            "Round: 1246 Weight: [2.47346228 1.22662538] Bias: -1.140384944524952 loss: 0.34341506656355547\n",
            "Round: 1247 Weight: [2.47356978 1.22668073] Bias: -1.140427737636163 loss: 0.34341490143585346\n",
            "Round: 1248 Weight: [2.47367699 1.22673594] Bias: -1.1404704200880977 loss: 0.3434147371574854\n",
            "Round: 1249 Weight: [2.47378393 1.226791  ] Bias: -1.1405129921793693 loss: 0.34341457372399714\n",
            "Round: 1250 Weight: [2.47389059 1.22684592] Bias: -1.1405554542077192 loss: 0.34341441113095833\n",
            "Round: 1251 Weight: [2.47399698 1.2269007 ] Bias: -1.1405978064700217 loss: 0.34341424937396253\n",
            "Round: 1252 Weight: [2.4741031  1.22695534] Bias: -1.1406400492622861 loss: 0.34341408844862725\n",
            "Round: 1253 Weight: [2.47420894 1.22700984] Bias: -1.1406821828796594 loss: 0.3434139283505934\n",
            "Round: 1254 Weight: [2.47431451 1.2270642 ] Bias: -1.1407242076164292 loss: 0.34341376907552545\n",
            "Round: 1255 Weight: [2.47441981 1.22711842] Bias: -1.140766123766027 loss: 0.3434136106191113\n",
            "Round: 1256 Weight: [2.47452484 1.2271725 ] Bias: -1.1408079316210304 loss: 0.34341345297706183\n",
            "Round: 1257 Weight: [2.4746296  1.22722644] Bias: -1.1408496314731669 loss: 0.34341329614511135\n",
            "Round: 1258 Weight: [2.47473408 1.22728024] Bias: -1.140891223613315 loss: 0.34341314011901714\n",
            "Round: 1259 Weight: [2.4748383  1.22733391] Bias: -1.140932708331509 loss: 0.3434129848945588\n",
            "Round: 1260 Weight: [2.47494226 1.22738743] Bias: -1.1409740859169402 loss: 0.3434128304675394\n",
            "Round: 1261 Weight: [2.47504594 1.22744082] Bias: -1.1410153566579604 loss: 0.3434126768337838\n",
            "Round: 1262 Weight: [2.47514936 1.22749407] Bias: -1.1410565208420846 loss: 0.34341252398913996\n",
            "Round: 1263 Weight: [2.47525251 1.22754718] Bias: -1.1410975787559936 loss: 0.343412371929478\n",
            "Round: 1264 Weight: [2.4753554  1.22760016] Bias: -1.1411385306855366 loss: 0.34341222065069016\n",
            "Round: 1265 Weight: [2.47545802 1.227653  ] Bias: -1.1411793769157346 loss: 0.3434120701486906\n",
            "Round: 1266 Weight: [2.47556038 1.22770571] Bias: -1.1412201177307821 loss: 0.34341192041941565\n",
            "Round: 1267 Weight: [2.47566248 1.22775828] Bias: -1.1412607534140509 loss: 0.34341177145882357\n",
            "Round: 1268 Weight: [2.47576431 1.22781071] Bias: -1.1413012842480919 loss: 0.34341162326289415\n",
            "Round: 1269 Weight: [2.47586589 1.22786301] Bias: -1.1413417105146382 loss: 0.34341147582762904\n",
            "Round: 1270 Weight: [2.4759672  1.22791518] Bias: -1.1413820324946076 loss: 0.3434113291490508\n",
            "Round: 1271 Weight: [2.47606825 1.22796721] Bias: -1.1414222504681053 loss: 0.34341118322320396\n",
            "Round: 1272 Weight: [2.47616905 1.22801911] Bias: -1.141462364714427 loss: 0.343411038046154\n",
            "Round: 1273 Weight: [2.47626958 1.22807088] Bias: -1.141502375512061 loss: 0.34341089361398747\n",
            "Round: 1274 Weight: [2.47636985 1.22812251] Bias: -1.1415422831386906 loss: 0.3434107499228121\n",
            "Round: 1275 Weight: [2.47646987 1.22817401] Bias: -1.1415820878711975 loss: 0.34341060696875647\n",
            "Round: 1276 Weight: [2.47656964 1.22822538] Bias: -1.141621789985664 loss: 0.34341046474796966\n",
            "Round: 1277 Weight: [2.47666914 1.22827661] Bias: -1.1416613897573755 loss: 0.34341032325662174\n",
            "Round: 1278 Weight: [2.47676839 1.22832772] Bias: -1.1417008874608234 loss: 0.34341018249090316\n",
            "Round: 1279 Weight: [2.47686739 1.22837869] Bias: -1.1417402833697072 loss: 0.34341004244702483\n",
            "Round: 1280 Weight: [2.47696613 1.22842953] Bias: -1.1417795777569377 loss: 0.3434099031212179\n",
            "Round: 1281 Weight: [2.47706462 1.22848025] Bias: -1.141818770894639 loss: 0.3434097645097337\n",
            "Round: 1282 Weight: [2.47716285 1.22853083] Bias: -1.1418578630541512 loss: 0.3434096266088439\n",
            "Round: 1283 Weight: [2.47726084 1.22858128] Bias: -1.1418968545060333 loss: 0.34340948941483973\n",
            "Round: 1284 Weight: [2.47735857 1.2286316 ] Bias: -1.1419357455200654 loss: 0.3434093529240328\n",
            "Round: 1285 Weight: [2.47745605 1.2286818 ] Bias: -1.1419745363652511 loss: 0.3434092171327538\n",
            "Round: 1286 Weight: [2.47755328 1.22873186] Bias: -1.1420132273098202 loss: 0.3434090820373537\n",
            "Round: 1287 Weight: [2.47765027 1.2287818 ] Bias: -1.1420518186212316 loss: 0.34340894763420277\n",
            "Round: 1288 Weight: [2.477747   1.22883161] Bias: -1.1420903105661748 loss: 0.3434088139196903\n",
            "Round: 1289 Weight: [2.47784349 1.22888129] Bias: -1.1421287034105736 loss: 0.34340868089022564\n",
            "Round: 1290 Weight: [2.47793973 1.22893084] Bias: -1.1421669974195874 loss: 0.3434085485422368\n",
            "Round: 1291 Weight: [2.47803572 1.22898027] Bias: -1.1422051928576145 loss: 0.3434084168721711\n",
            "Round: 1292 Weight: [2.47813146 1.22902957] Bias: -1.1422432899882942 loss: 0.34340828587649486\n",
            "Round: 1293 Weight: [2.47822696 1.22907874] Bias: -1.1422812890745093 loss: 0.3434081555516931\n",
            "Round: 1294 Weight: [2.47832222 1.22912779] Bias: -1.1423191903783887 loss: 0.3434080258942699\n",
            "Round: 1295 Weight: [2.47841723 1.22917671] Bias: -1.1423569941613096 loss: 0.343407896900748\n",
            "Round: 1296 Weight: [2.478512   1.22922551] Bias: -1.1423947006839001 loss: 0.34340776856766847\n",
            "Round: 1297 Weight: [2.47860653 1.22927418] Bias: -1.1424323102060414 loss: 0.34340764089159087\n",
            "Round: 1298 Weight: [2.47870081 1.22932273] Bias: -1.1424698229868702 loss: 0.3434075138690935\n",
            "Round: 1299 Weight: [2.47879485 1.22937115] Bias: -1.1425072392847815 loss: 0.3434073874967727\n",
            "Round: 1300 Weight: [2.47888865 1.22941945] Bias: -1.1425445593574304 loss: 0.3434072617712427\n",
            "Round: 1301 Weight: [2.47898222 1.22946763] Bias: -1.1425817834617351 loss: 0.3434071366891364\n",
            "Round: 1302 Weight: [2.47907554 1.22951568] Bias: -1.1426189118538788 loss: 0.34340701224710424\n",
            "Round: 1303 Weight: [2.47916862 1.22956361] Bias: -1.142655944789312 loss: 0.34340688844181455\n",
            "Round: 1304 Weight: [2.47926146 1.22961141] Bias: -1.1426928825227554 loss: 0.3434067652699535\n",
            "Round: 1305 Weight: [2.47935407 1.2296591 ] Bias: -1.1427297253082014 loss: 0.3434066427282252\n",
            "Round: 1306 Weight: [2.47944644 1.22970666] Bias: -1.1427664733989173 loss: 0.3434065208133509\n",
            "Round: 1307 Weight: [2.47953857 1.2297541 ] Bias: -1.1428031270474475 loss: 0.3434063995220696\n",
            "Round: 1308 Weight: [2.47963047 1.22980142] Bias: -1.1428396865056147 loss: 0.34340627885113756\n",
            "Round: 1309 Weight: [2.47972213 1.22984861] Bias: -1.1428761520245236 loss: 0.3434061587973283\n",
            "Round: 1310 Weight: [2.47981356 1.22989569] Bias: -1.1429125238545625 loss: 0.34340603935743286\n",
            "Round: 1311 Weight: [2.47990476 1.22994264] Bias: -1.142948802245406 loss: 0.34340592052825886\n",
            "Round: 1312 Weight: [2.47999572 1.22998948] Bias: -1.1429849874460165 loss: 0.3434058023066313\n",
            "Round: 1313 Weight: [2.48008644 1.2300362 ] Bias: -1.1430210797046474 loss: 0.34340568468939203\n",
            "Round: 1314 Weight: [2.48017694 1.23008279] Bias: -1.1430570792688448 loss: 0.3434055676733995\n",
            "Round: 1315 Weight: [2.4802672  1.23012927] Bias: -1.1430929863854498 loss: 0.3434054512555293\n",
            "Round: 1316 Weight: [2.48035724 1.23017563] Bias: -1.143128801300601 loss: 0.3434053354326731\n",
            "Round: 1317 Weight: [2.48044704 1.23022187] Bias: -1.1431645242597361 loss: 0.3434052202017396\n",
            "Round: 1318 Weight: [2.48053661 1.23026799] Bias: -1.1432001555075955 loss: 0.3434051055596538\n",
            "Round: 1319 Weight: [2.48062596 1.23031399] Bias: -1.1432356952882228 loss: 0.3434049915033568\n",
            "Round: 1320 Weight: [2.48071508 1.23035988] Bias: -1.143271143844968 loss: 0.34340487802980646\n",
            "Round: 1321 Weight: [2.48080396 1.23040565] Bias: -1.14330650142049 loss: 0.34340476513597634\n",
            "Round: 1322 Weight: [2.48089262 1.2304513 ] Bias: -1.1433417682567575 loss: 0.34340465281885635\n",
            "Round: 1323 Weight: [2.48098106 1.23049684] Bias: -1.1433769445950526 loss: 0.34340454107545226\n",
            "Round: 1324 Weight: [2.48106927 1.23054226] Bias: -1.1434120306759723 loss: 0.3434044299027861\n",
            "Round: 1325 Weight: [2.48115725 1.23058756] Bias: -1.1434470267394305 loss: 0.34340431929789517\n",
            "Round: 1326 Weight: [2.48124501 1.23063275] Bias: -1.143481933024661 loss: 0.343404209257833\n",
            "Round: 1327 Weight: [2.48133254 1.23067782] Bias: -1.1435167497702183 loss: 0.3434040997796685\n",
            "Round: 1328 Weight: [2.48141985 1.23072277] Bias: -1.1435514772139812 loss: 0.3434039908604863\n",
            "Round: 1329 Weight: [2.48150694 1.23076761] Bias: -1.1435861155931537 loss: 0.34340388249738624\n",
            "Round: 1330 Weight: [2.48159381 1.23081234] Bias: -1.143620665144268 loss: 0.34340377468748395\n",
            "Round: 1331 Weight: [2.48168045 1.23085695] Bias: -1.1436551261031862 loss: 0.3434036674279102\n",
            "Round: 1332 Weight: [2.48176687 1.23090145] Bias: -1.1436894987051027 loss: 0.34340356071581063\n",
            "Round: 1333 Weight: [2.48185307 1.23094584] Bias: -1.143723783184546 loss: 0.34340345454834686\n",
            "Round: 1334 Weight: [2.48193905 1.23099011] Bias: -1.1437579797753807 loss: 0.34340334892269464\n",
            "Round: 1335 Weight: [2.48202481 1.23103427] Bias: -1.1437920887108104 loss: 0.34340324383604537\n",
            "Round: 1336 Weight: [2.48211036 1.23107831] Bias: -1.1438261102233784 loss: 0.3434031392856049\n",
            "Round: 1337 Weight: [2.48219568 1.23112225] Bias: -1.1438600445449714 loss: 0.3434030352685944\n",
            "Round: 1338 Weight: [2.48228079 1.23116607] Bias: -1.1438938919068202 loss: 0.34340293178224923\n",
            "Round: 1339 Weight: [2.48236568 1.23120978] Bias: -1.1439276525395026 loss: 0.3434028288238197\n",
            "Round: 1340 Weight: [2.48245035 1.23125338] Bias: -1.1439613266729447 loss: 0.3434027263905708\n",
            "Round: 1341 Weight: [2.4825348  1.23129686] Bias: -1.143994914536424 loss: 0.3434026244797816\n",
            "Round: 1342 Weight: [2.48261904 1.23134024] Bias: -1.1440284163585708 loss: 0.34340252308874597\n",
            "Round: 1343 Weight: [2.48270307 1.2313835 ] Bias: -1.1440618323673695 loss: 0.343402422214772\n",
            "Round: 1344 Weight: [2.48278688 1.23142666] Bias: -1.1440951627901623 loss: 0.343402321855182\n",
            "Round: 1345 Weight: [2.48287048 1.2314697 ] Bias: -1.14412840785365 loss: 0.3434022220073126\n",
            "Round: 1346 Weight: [2.48295386 1.23151264] Bias: -1.1441615677838943 loss: 0.3434021226685141\n",
            "Round: 1347 Weight: [2.48303703 1.23155546] Bias: -1.1441946428063197 loss: 0.3434020238361514\n",
            "Round: 1348 Weight: [2.48311999 1.23159818] Bias: -1.1442276331457157 loss: 0.34340192550760307\n",
            "Round: 1349 Weight: [2.48320274 1.23164078] Bias: -1.144260539026239 loss: 0.34340182768026145\n",
            "Round: 1350 Weight: [2.48328528 1.23168328] Bias: -1.1442933606714147 loss: 0.343401730351533\n",
            "Round: 1351 Weight: [2.4833676  1.23172567] Bias: -1.144326098304139 loss: 0.34340163351883757\n",
            "Round: 1352 Weight: [2.48344972 1.23176795] Bias: -1.144358752146681 loss: 0.34340153717960853\n",
            "Round: 1353 Weight: [2.48353163 1.23181013] Bias: -1.144391322420684 loss: 0.3434014413312935\n",
            "Round: 1354 Weight: [2.48361332 1.23185219] Bias: -1.1444238093471693 loss: 0.34340134597135297\n",
            "Round: 1355 Weight: [2.48369481 1.23189415] Bias: -1.1444562131465355 loss: 0.34340125109726105\n",
            "Round: 1356 Weight: [2.4837761 1.231936 ] Bias: -1.1444885340385627 loss: 0.3434011567065053\n",
            "Round: 1357 Weight: [2.48385717 1.23197775] Bias: -1.1445207722424129 loss: 0.34340106279658633\n",
            "Round: 1358 Weight: [2.48393804 1.23201939] Bias: -1.144552927976633 loss: 0.34340096936501824\n",
            "Round: 1359 Weight: [2.4840187  1.23206092] Bias: -1.1445850014591565 loss: 0.34340087640932787\n",
            "Round: 1360 Weight: [2.48409916 1.23210235] Bias: -1.1446169929073047 loss: 0.34340078392705564\n",
            "Round: 1361 Weight: [2.48417941 1.23214367] Bias: -1.144648902537789 loss: 0.3434006919157546\n",
            "Round: 1362 Weight: [2.48425946 1.23218489] Bias: -1.1446807305667133 loss: 0.34340060037299064\n",
            "Round: 1363 Weight: [2.4843393 1.232226 ] Bias: -1.1447124772095751 loss: 0.34340050929634286\n",
            "Round: 1364 Weight: [2.48441894 1.232267  ] Bias: -1.1447441426812683 loss: 0.3434004186834028\n",
            "Round: 1365 Weight: [2.48449837 1.23230791] Bias: -1.144775727196084 loss: 0.34340032853177505\n",
            "Round: 1366 Weight: [2.48457761 1.2323487 ] Bias: -1.1448072309677129 loss: 0.3434002388390765\n",
            "Round: 1367 Weight: [2.48465664 1.2323894 ] Bias: -1.1448386542092475 loss: 0.3434001496029368\n",
            "Round: 1368 Weight: [2.48473547 1.23242999] Bias: -1.1448699971331835 loss: 0.34340006082099805\n",
            "Round: 1369 Weight: [2.4848141  1.23247047] Bias: -1.1449012599514214 loss: 0.3433999724909148\n",
            "Round: 1370 Weight: [2.48489253 1.23251086] Bias: -1.1449324428752694 loss: 0.34339988461035403\n",
            "Round: 1371 Weight: [2.48497076 1.23255114] Bias: -1.144963546115444 loss: 0.3433997971769948\n",
            "Round: 1372 Weight: [2.48504879 1.23259132] Bias: -1.1449945698820723 loss: 0.3433997101885289\n",
            "Round: 1373 Weight: [2.48512663 1.23263139] Bias: -1.1450255143846941 loss: 0.3433996236426595\n",
            "Round: 1374 Weight: [2.48520426 1.23267137] Bias: -1.1450563798322637 loss: 0.3433995375371027\n",
            "Round: 1375 Weight: [2.4852817  1.23271124] Bias: -1.1450871664331512 loss: 0.343399451869586\n",
            "Round: 1376 Weight: [2.48535894 1.23275101] Bias: -1.1451178743951447 loss: 0.3433993666378493\n",
            "Round: 1377 Weight: [2.48543598 1.23279068] Bias: -1.1451485039254519 loss: 0.34339928183964424\n",
            "Round: 1378 Weight: [2.48551283 1.23283025] Bias: -1.1451790552307022 loss: 0.34339919747273406\n",
            "Round: 1379 Weight: [2.48558948 1.23286971] Bias: -1.145209528516948 loss: 0.3433991135348944\n",
            "Round: 1380 Weight: [2.48566593 1.23290908] Bias: -1.145239923989667 loss: 0.343399030023912\n",
            "Round: 1381 Weight: [2.4857422  1.23294835] Bias: -1.1452702418537637 loss: 0.34339894693758544\n",
            "Round: 1382 Weight: [2.48581826 1.23298751] Bias: -1.145300482313571 loss: 0.3433988642737252\n",
            "Round: 1383 Weight: [2.48589414 1.23302658] Bias: -1.1453306455728525 loss: 0.34339878203015256\n",
            "Round: 1384 Weight: [2.48596982 1.23306555] Bias: -1.1453607318348034 loss: 0.3433987002047011\n",
            "Round: 1385 Weight: [2.48604531 1.23310442] Bias: -1.1453907413020532 loss: 0.3433986187952152\n",
            "Round: 1386 Weight: [2.4861206  1.23314319] Bias: -1.1454206741766666 loss: 0.34339853779955104\n",
            "Round: 1387 Weight: [2.48619571 1.23318186] Bias: -1.145450530660146 loss: 0.34339845721557555\n",
            "Round: 1388 Weight: [2.48627062 1.23322043] Bias: -1.1454803109534324 loss: 0.34339837704116727\n",
            "Round: 1389 Weight: [2.48634535 1.23325891] Bias: -1.145510015256908 loss: 0.3433982972742159\n",
            "Round: 1390 Weight: [2.48641988 1.23329729] Bias: -1.1455396437703973 loss: 0.3433982179126218\n",
            "Round: 1391 Weight: [2.48649422 1.23333556] Bias: -1.145569196693169 loss: 0.34339813895429705\n",
            "Round: 1392 Weight: [2.48656838 1.23337375] Bias: -1.1455986742239372 loss: 0.34339806039716403\n",
            "Round: 1393 Weight: [2.48664235 1.23341183] Bias: -1.1456280765608644 loss: 0.34339798223915646\n",
            "Round: 1394 Weight: [2.48671612 1.23344982] Bias: -1.145657403901562 loss: 0.34339790447821883\n",
            "Round: 1395 Weight: [2.48678971 1.23348771] Bias: -1.145686656443092 loss: 0.3433978271123064\n",
            "Round: 1396 Weight: [2.48686312 1.23352551] Bias: -1.1457158343819698 loss: 0.343397750139385\n",
            "Round: 1397 Weight: [2.48693634 1.23356321] Bias: -1.1457449379141644 loss: 0.3433976735574314\n",
            "Round: 1398 Weight: [2.48700937 1.23360081] Bias: -1.145773967235101 loss: 0.343397597364433\n",
            "Round: 1399 Weight: [2.48708221 1.23363832] Bias: -1.1458029225396626 loss: 0.34339752155838754\n",
            "Round: 1400 Weight: [2.48715487 1.23367573] Bias: -1.1458318040221915 loss: 0.3433974461373034\n",
            "Round: 1401 Weight: [2.48722735 1.23371305] Bias: -1.1458606118764907 loss: 0.34339737109919943\n",
            "Round: 1402 Weight: [2.48729964 1.23375027] Bias: -1.1458893462958257 loss: 0.3433972964421048\n",
            "Round: 1403 Weight: [2.48737175 1.2337874 ] Bias: -1.1459180074729265 loss: 0.3433972221640592\n",
            "Round: 1404 Weight: [2.48744367 1.23382443] Bias: -1.1459465955999888 loss: 0.3433971482631123\n",
            "Round: 1405 Weight: [2.48751541 1.23386137] Bias: -1.145975110868676 loss: 0.34339707473732434\n",
            "Round: 1406 Weight: [2.48758697 1.23389822] Bias: -1.1460035534701203 loss: 0.3433970015847654\n",
            "Round: 1407 Weight: [2.48765835 1.23393497] Bias: -1.1460319235949246 loss: 0.34339692880351597\n",
            "Round: 1408 Weight: [2.48772955 1.23397163] Bias: -1.1460602214331643 loss: 0.34339685639166634\n",
            "Round: 1409 Weight: [2.48780056 1.23400819] Bias: -1.1460884471743888 loss: 0.3433967843473171\n",
            "Round: 1410 Weight: [2.4878714  1.23404467] Bias: -1.146116601007623 loss: 0.34339671266857874\n",
            "Round: 1411 Weight: [2.48794206 1.23408105] Bias: -1.1461446831213682 loss: 0.34339664135357123\n",
            "Round: 1412 Weight: [2.48801253 1.23411734] Bias: -1.1461726937036054 loss: 0.3433965704004249\n",
            "Round: 1413 Weight: [2.48808283 1.23415353] Bias: -1.1462006329417955 loss: 0.3433964998072798\n",
            "Round: 1414 Weight: [2.48815295 1.23418964] Bias: -1.1462285010228812 loss: 0.34339642957228544\n",
            "Round: 1415 Weight: [2.48822289 1.23422565] Bias: -1.1462562981332887 loss: 0.3433963596936014\n",
            "Round: 1416 Weight: [2.48829265 1.23426157] Bias: -1.146284024458929 loss: 0.3433962901693963\n",
            "Round: 1417 Weight: [2.48836224 1.2342974 ] Bias: -1.1463116801851996 loss: 0.34339622099784917\n",
            "Round: 1418 Weight: [2.48843165 1.23433314] Bias: -1.1463392654969866 loss: 0.343396152177148\n",
            "Round: 1419 Weight: [2.48850088 1.23436878] Bias: -1.1463667805786653 loss: 0.3433960837054903\n",
            "Round: 1420 Weight: [2.48856994 1.23440434] Bias: -1.1463942256141024 loss: 0.3433960155810833\n",
            "Round: 1421 Weight: [2.48863882 1.23443981] Bias: -1.1464216007866572 loss: 0.3433959478021434\n",
            "Round: 1422 Weight: [2.48870753 1.23447519] Bias: -1.1464489062791834 loss: 0.3433958803668962\n",
            "Round: 1423 Weight: [2.48877606 1.23451047] Bias: -1.1464761422740304 loss: 0.343395813273577\n",
            "Round: 1424 Weight: [2.48884442 1.23454567] Bias: -1.1465033089530448 loss: 0.3433957465204298\n",
            "Round: 1425 Weight: [2.48891261 1.23458078] Bias: -1.1465304064975723 loss: 0.3433956801057084\n",
            "Round: 1426 Weight: [2.48898062 1.2346158 ] Bias: -1.1465574350884586 loss: 0.34339561402767527\n",
            "Round: 1427 Weight: [2.48904846 1.23465073] Bias: -1.1465843949060517 loss: 0.343395548284602\n",
            "Round: 1428 Weight: [2.48911613 1.23468557] Bias: -1.1466112861302025 loss: 0.3433954828747694\n",
            "Round: 1429 Weight: [2.48918362 1.23472033] Bias: -1.146638108940267 loss: 0.3433954177964671\n",
            "Round: 1430 Weight: [2.48925095 1.23475499] Bias: -1.1466648635151075 loss: 0.3433953530479938\n",
            "Round: 1431 Weight: [2.4893181  1.23478957] Bias: -1.146691550033094 loss: 0.34339528862765706\n",
            "Round: 1432 Weight: [2.48938509 1.23482406] Bias: -1.146718168672106 loss: 0.3433952245337732\n",
            "Round: 1433 Weight: [2.4894519  1.23485846] Bias: -1.1467447196095335 loss: 0.3433951607646675\n",
            "Round: 1434 Weight: [2.48951855 1.23489278] Bias: -1.146771203022279 loss: 0.3433950973186737\n",
            "Round: 1435 Weight: [2.48958502 1.234927  ] Bias: -1.1467976190867586 loss: 0.34339503419413453\n",
            "Round: 1436 Weight: [2.48965133 1.23496115] Bias: -1.1468239679789036 loss: 0.3433949713894013\n",
            "Round: 1437 Weight: [2.48971747 1.2349952 ] Bias: -1.1468502498741617 loss: 0.343394908902834\n",
            "Round: 1438 Weight: [2.48978344 1.23502917] Bias: -1.1468764649474992 loss: 0.3433948467328009\n",
            "Round: 1439 Weight: [2.48984925 1.23506305] Bias: -1.1469026133734013 loss: 0.3433947848776789\n",
            "Round: 1440 Weight: [2.48991489 1.23509685] Bias: -1.1469286953258746 loss: 0.3433947233358537\n",
            "Round: 1441 Weight: [2.48998036 1.23513056] Bias: -1.146954710978448 loss: 0.3433946621057189\n",
            "Round: 1442 Weight: [2.49004566 1.23516418] Bias: -1.146980660504174 loss: 0.343394601185677\n",
            "Round: 1443 Weight: [2.4901108  1.23519772] Bias: -1.1470065440756305 loss: 0.3433945405741383\n",
            "Round: 1444 Weight: [2.49017578 1.23523118] Bias: -1.1470323618649223 loss: 0.34339448026952196\n",
            "Round: 1445 Weight: [2.49024059 1.23526455] Bias: -1.1470581140436817 loss: 0.34339442027025496\n",
            "Round: 1446 Weight: [2.49030523 1.23529784] Bias: -1.1470838007830713 loss: 0.3433943605747726\n",
            "Round: 1447 Weight: [2.49036972 1.23533104] Bias: -1.1471094222537839 loss: 0.3433943011815183\n",
            "Round: 1448 Weight: [2.49043403 1.23536415] Bias: -1.147134978626045 loss: 0.3433942420889439\n",
            "Round: 1449 Weight: [2.49049819 1.23539719] Bias: -1.1471604700696134 loss: 0.34339418329550886\n",
            "Round: 1450 Weight: [2.49056218 1.23543014] Bias: -1.1471858967537836 loss: 0.34339412479968084\n",
            "Round: 1451 Weight: [2.49062601 1.235463  ] Bias: -1.147211258847386 loss: 0.34339406659993554\n",
            "Round: 1452 Weight: [2.49068968 1.23549579] Bias: -1.1472365565187892 loss: 0.3433940086947569\n",
            "Round: 1453 Weight: [2.49075319 1.23552849] Bias: -1.147261789935901 loss: 0.34339395108263604\n",
            "Round: 1454 Weight: [2.49081654 1.2355611 ] Bias: -1.1472869592661696 loss: 0.34339389376207247\n",
            "Round: 1455 Weight: [2.49087973 1.23559364] Bias: -1.1473120646765855 loss: 0.3433938367315735\n",
            "Round: 1456 Weight: [2.49094275 1.23562609] Bias: -1.1473371063336824 loss: 0.34339377998965404\n",
            "Round: 1457 Weight: [2.49100562 1.23565846] Bias: -1.1473620844035384 loss: 0.3433937235348367\n",
            "Round: 1458 Weight: [2.49106833 1.23569075] Bias: -1.147386999051778 loss: 0.343393667365652\n",
            "Round: 1459 Weight: [2.49113088 1.23572295] Bias: -1.147411850443573 loss: 0.34339361148063796\n",
            "Round: 1460 Weight: [2.49119327 1.23575508] Bias: -1.1474366387436443 loss: 0.3433935558783402\n",
            "Round: 1461 Weight: [2.4912555  1.23578712] Bias: -1.1474613641162623 loss: 0.3433935005573121\n",
            "Round: 1462 Weight: [2.49131758 1.23581909] Bias: -1.1474860267252491 loss: 0.34339344551611417\n",
            "Round: 1463 Weight: [2.4913795  1.23585097] Bias: -1.1475106267339796 loss: 0.34339339075331493\n",
            "Round: 1464 Weight: [2.49144126 1.23588277] Bias: -1.1475351643053826 loss: 0.3433933362674898\n",
            "Round: 1465 Weight: [2.49150287 1.23591449] Bias: -1.1475596396019425 loss: 0.3433932820572223\n",
            "Round: 1466 Weight: [2.49156432 1.23594613] Bias: -1.1475840527857006 loss: 0.34339322812110246\n",
            "Round: 1467 Weight: [2.49162561 1.23597769] Bias: -1.1476084040182557 loss: 0.3433931744577283\n",
            "Round: 1468 Weight: [2.49168675 1.23600917] Bias: -1.1476326934607666 loss: 0.34339312106570485\n",
            "Round: 1469 Weight: [2.49174773 1.23604057] Bias: -1.147656921273952 loss: 0.3433930679436445\n",
            "Round: 1470 Weight: [2.49180856 1.23607189] Bias: -1.1476810876180932 loss: 0.34339301509016695\n",
            "Round: 1471 Weight: [2.49186924 1.23610313] Bias: -1.1477051926530346 loss: 0.3433929625038987\n",
            "Round: 1472 Weight: [2.49192976 1.23613429] Bias: -1.1477292365381848 loss: 0.34339291018347384\n",
            "Round: 1473 Weight: [2.49199013 1.23616538] Bias: -1.1477532194325188 loss: 0.34339285812753323\n",
            "Round: 1474 Weight: [2.49205035 1.23619638] Bias: -1.1477771414945783 loss: 0.3433928063347249\n",
            "Round: 1475 Weight: [2.49211041 1.23622731] Bias: -1.1478010028824732 loss: 0.343392754803704\n",
            "Round: 1476 Weight: [2.49217032 1.23625816] Bias: -1.1478248037538836 loss: 0.34339270353313256\n",
            "Round: 1477 Weight: [2.49223009 1.23628893] Bias: -1.1478485442660604 loss: 0.34339265252167955\n",
            "Round: 1478 Weight: [2.4922897  1.23631962] Bias: -1.1478722245758264 loss: 0.34339260176802094\n",
            "Round: 1479 Weight: [2.49234915 1.23635023] Bias: -1.1478958448395782 loss: 0.34339255127083956\n",
            "Round: 1480 Weight: [2.49240846 1.23638077] Bias: -1.1479194052132868 loss: 0.3433925010288248\n",
            "Round: 1481 Weight: [2.49246762 1.23641123] Bias: -1.1479429058524995 loss: 0.34339245104067334\n",
            "Round: 1482 Weight: [2.49252663 1.23644161] Bias: -1.1479663469123407 loss: 0.34339240130508847\n",
            "Round: 1483 Weight: [2.49258549 1.23647192] Bias: -1.1479897285475131 loss: 0.3433923518207797\n",
            "Round: 1484 Weight: [2.4926442  1.23650215] Bias: -1.1480130509122994 loss: 0.3433923025864641\n",
            "Round: 1485 Weight: [2.49270276 1.2365323 ] Bias: -1.148036314160563 loss: 0.34339225360086467\n",
            "Round: 1486 Weight: [2.49276118 1.23656238] Bias: -1.1480595184457494 loss: 0.3433922048627115\n",
            "Round: 1487 Weight: [2.49281945 1.23659238] Bias: -1.148082663920888 loss: 0.34339215637074105\n",
            "Round: 1488 Weight: [2.49287757 1.23662231] Bias: -1.1481057507385926 loss: 0.34339210812369636\n",
            "Round: 1489 Weight: [2.49293554 1.23665216] Bias: -1.1481287790510624 loss: 0.343392060120327\n",
            "Round: 1490 Weight: [2.49299336 1.23668193] Bias: -1.148151749010084 loss: 0.343392012359389\n",
            "Round: 1491 Weight: [2.49305104 1.23671163] Bias: -1.1481746607670327 loss: 0.3433919648396449\n",
            "Round: 1492 Weight: [2.49310858 1.23674125] Bias: -1.1481975144728724 loss: 0.3433919175598637\n",
            "Round: 1493 Weight: [2.49316597 1.2367708 ] Bias: -1.1482203102781587 loss: 0.3433918705188206\n",
            "Round: 1494 Weight: [2.49322321 1.23680028] Bias: -1.1482430483330384 loss: 0.3433918237152973\n",
            "Round: 1495 Weight: [2.49328031 1.23682968] Bias: -1.1482657287872513 loss: 0.3433917771480818\n",
            "Round: 1496 Weight: [2.49333727 1.236859  ] Bias: -1.1482883517901321 loss: 0.3433917308159682\n",
            "Round: 1497 Weight: [2.49339408 1.23688825] Bias: -1.1483109174906105 loss: 0.34339168471775733\n",
            "Round: 1498 Weight: [2.49345074 1.23691743] Bias: -1.148333426037213 loss: 0.3433916388522556\n",
            "Round: 1499 Weight: [2.49350727 1.23694653] Bias: -1.1483558775780636 loss: 0.34339159321827606\n",
            "Round: 1500 Weight: [2.49356365 1.23697557] Bias: -1.148378272260886 loss: 0.3433915478146378\n",
            "Round: 1501 Weight: [2.49361989 1.23700452] Bias: -1.1484006102330035 loss: 0.3433915026401658\n",
            "Round: 1502 Weight: [2.49367599 1.23703341] Bias: -1.1484228916413413 loss: 0.3433914576936915\n",
            "Round: 1503 Weight: [2.49373194 1.23706222] Bias: -1.1484451166324263 loss: 0.34339141297405196\n",
            "Round: 1504 Weight: [2.49378776 1.23709095] Bias: -1.1484672853523898 loss: 0.3433913684800907\n",
            "Round: 1505 Weight: [2.49384343 1.23711962] Bias: -1.1484893979469675 loss: 0.3433913242106571\n",
            "Round: 1506 Weight: [2.49389896 1.23714821] Bias: -1.1485114545615014 loss: 0.3433912801646063\n",
            "Round: 1507 Weight: [2.49395435 1.23717673] Bias: -1.1485334553409405 loss: 0.3433912363407995\n",
            "Round: 1508 Weight: [2.49400961 1.23720518] Bias: -1.148555400429842 loss: 0.34339119273810376\n",
            "Round: 1509 Weight: [2.49406472 1.23723356] Bias: -1.1485772899723725 loss: 0.34339114935539217\n",
            "Round: 1510 Weight: [2.49411969 1.23726187] Bias: -1.1485991241123095 loss: 0.3433911061915433\n",
            "Round: 1511 Weight: [2.49417453 1.2372901 ] Bias: -1.1486209029930419 loss: 0.34339106324544183\n",
            "Round: 1512 Weight: [2.49422922 1.23731826] Bias: -1.1486426267575716 loss: 0.3433910205159781\n",
            "Round: 1513 Weight: [2.49428378 1.23734635] Bias: -1.148664295548514 loss: 0.3433909780020484\n",
            "Round: 1514 Weight: [2.4943382  1.23737437] Bias: -1.1486859095081003 loss: 0.34339093570255413\n",
            "Round: 1515 Weight: [2.49439249 1.23740232] Bias: -1.1487074687781775 loss: 0.34339089361640307\n",
            "Round: 1516 Weight: [2.49444663 1.2374302 ] Bias: -1.1487289735002097 loss: 0.34339085174250833\n",
            "Round: 1517 Weight: [2.49450064 1.23745801] Bias: -1.14875042381528 loss: 0.3433908100797884\n",
            "Round: 1518 Weight: [2.49455452 1.23748575] Bias: -1.1487718198640904 loss: 0.34339076862716794\n",
            "Round: 1519 Weight: [2.49460825 1.23751342] Bias: -1.148793161786964 loss: 0.3433907273835767\n",
            "Round: 1520 Weight: [2.49466186 1.23754102] Bias: -1.1488144497238455 loss: 0.34339068634795\n",
            "Round: 1521 Weight: [2.49471532 1.23756855] Bias: -1.1488356838143026 loss: 0.34339064551922904\n",
            "Round: 1522 Weight: [2.49476865 1.23759601] Bias: -1.1488568641975265 loss: 0.34339060489636003\n",
            "Round: 1523 Weight: [2.49482185 1.2376234 ] Bias: -1.148877991012334 loss: 0.3433905644782948\n",
            "Round: 1524 Weight: [2.49487491 1.23765072] Bias: -1.1488990643971673 loss: 0.34339052426399064\n",
            "Round: 1525 Weight: [2.49492784 1.23767797] Bias: -1.1489200844900966 loss: 0.3433904842524102\n",
            "Round: 1526 Weight: [2.49498064 1.23770516] Bias: -1.1489410514288199 loss: 0.34339044444252154\n",
            "Round: 1527 Weight: [2.4950333  1.23773227] Bias: -1.1489619653506644 loss: 0.34339040483329797\n",
            "Round: 1528 Weight: [2.49508583 1.23775932] Bias: -1.1489828263925883 loss: 0.34339036542371804\n",
            "Round: 1529 Weight: [2.49513823 1.2377863 ] Bias: -1.149003634691181 loss: 0.34339032621276566\n",
            "Round: 1530 Weight: [2.49519049 1.23781321] Bias: -1.149024390382664 loss: 0.3433902871994301\n",
            "Round: 1531 Weight: [2.49524263 1.23784005] Bias: -1.1490450936028933 loss: 0.34339024838270565\n",
            "Round: 1532 Weight: [2.49529463 1.23786682] Bias: -1.149065744487359 loss: 0.3433902097615919\n",
            "Round: 1533 Weight: [2.4953465  1.23789353] Bias: -1.149086343171187 loss: 0.3433901713350936\n",
            "Round: 1534 Weight: [2.49539824 1.23792017] Bias: -1.1491068897891403 loss: 0.3433901331022205\n",
            "Round: 1535 Weight: [2.49544985 1.23794674] Bias: -1.1491273844756194 loss: 0.3433900950619877\n",
            "Round: 1536 Weight: [2.49550132 1.23797325] Bias: -1.1491478273646638 loss: 0.34339005721341515\n",
            "Round: 1537 Weight: [2.49555267 1.23799969] Bias: -1.149168218589953 loss: 0.343390019555528\n",
            "Round: 1538 Weight: [2.49560389 1.23802606] Bias: -1.1491885582848074 loss: 0.34338998208735644\n",
            "Round: 1539 Weight: [2.49565498 1.23805237] Bias: -1.1492088465821892 loss: 0.3433899448079355\n",
            "Round: 1540 Weight: [2.49570595 1.23807861] Bias: -1.1492290836147043 loss: 0.34338990771630534\n",
            "Round: 1541 Weight: [2.49575678 1.23810478] Bias: -1.149249269514602 loss: 0.34338987081151107\n",
            "Round: 1542 Weight: [2.49580748 1.23813089] Bias: -1.1492694044137768 loss: 0.34338983409260265\n",
            "Round: 1543 Weight: [2.49585806 1.23815693] Bias: -1.1492894884437694 loss: 0.34338979755863486\n",
            "Round: 1544 Weight: [2.49590851 1.2381829 ] Bias: -1.149309521735768 loss: 0.34338976120866765\n",
            "Round: 1545 Weight: [2.49595883 1.23820881] Bias: -1.1493295044206084 loss: 0.34338972504176546\n",
            "Round: 1546 Weight: [2.49600903 1.23823466] Bias: -1.1493494366287758 loss: 0.3433896890569978\n",
            "Round: 1547 Weight: [2.4960591  1.23826044] Bias: -1.1493693184904055 loss: 0.3433896532534389\n",
            "Round: 1548 Weight: [2.49610904 1.23828615] Bias: -1.149389150135284 loss: 0.3433896176301676\n",
            "Round: 1549 Weight: [2.49615886 1.2383118 ] Bias: -1.1494089316928502 loss: 0.3433895821862679\n",
            "Round: 1550 Weight: [2.49620855 1.23833739] Bias: -1.1494286632921957 loss: 0.34338954692082807\n",
            "Round: 1551 Weight: [2.49625812 1.23836291] Bias: -1.1494483450620667 loss: 0.3433895118329413\n",
            "Round: 1552 Weight: [2.49630756 1.23838837] Bias: -1.1494679771308645 loss: 0.34338947692170546\n",
            "Round: 1553 Weight: [2.49635687 1.23841376] Bias: -1.1494875596266463 loss: 0.34338944218622286\n",
            "Round: 1554 Weight: [2.49640607 1.23843909] Bias: -1.1495070926771267 loss: 0.34338940762560083\n",
            "Round: 1555 Weight: [2.49645514 1.23846435] Bias: -1.1495265764096785 loss: 0.3433893732389508\n",
            "Round: 1556 Weight: [2.49650408 1.23848955] Bias: -1.1495460109513331 loss: 0.34338933902538926\n",
            "Round: 1557 Weight: [2.4965529  1.23851469] Bias: -1.1495653964287826 loss: 0.3433893049840369\n",
            "Round: 1558 Weight: [2.4966016  1.23853977] Bias: -1.14958473296838 loss: 0.34338927111401907\n",
            "Round: 1559 Weight: [2.49665018 1.23856478] Bias: -1.14960402069614 loss: 0.34338923741446553\n",
            "Round: 1560 Weight: [2.49669863 1.23858973] Bias: -1.1496232597377405 loss: 0.34338920388451083\n",
            "Round: 1561 Weight: [2.49674696 1.23861461] Bias: -1.1496424502185234 loss: 0.34338917052329354\n",
            "Round: 1562 Weight: [2.49679517 1.23863943] Bias: -1.1496615922634956 loss: 0.34338913732995696\n",
            "Round: 1563 Weight: [2.49684326 1.23866419] Bias: -1.1496806859973299 loss: 0.3433891043036487\n",
            "Round: 1564 Weight: [2.49689123 1.23868889] Bias: -1.1496997315443656 loss: 0.34338907144352065\n",
            "Round: 1565 Weight: [2.49693908 1.23871353] Bias: -1.1497187290286102 loss: 0.3433890387487293\n",
            "Round: 1566 Weight: [2.4969868 1.2387381] Bias: -1.1497376785737394 loss: 0.3433890062184353\n",
            "Round: 1567 Weight: [2.49703441 1.23876261] Bias: -1.1497565803030994 loss: 0.3433889738518036\n",
            "Round: 1568 Weight: [2.4970819  1.23878706] Bias: -1.1497754343397062 loss: 0.34338894164800354\n",
            "Round: 1569 Weight: [2.49712926 1.23881145] Bias: -1.149794240806248 loss: 0.34338890960620877\n",
            "Round: 1570 Weight: [2.49717651 1.23883578] Bias: -1.1498129998250852 loss: 0.3433888777255971\n",
            "Round: 1571 Weight: [2.49722364 1.23886004] Bias: -1.1498317115182517 loss: 0.3433888460053506\n",
            "Round: 1572 Weight: [2.49727065 1.23888425] Bias: -1.1498503760074557 loss: 0.34338881444465535\n",
            "Round: 1573 Weight: [2.49731754 1.23890839] Bias: -1.1498689934140807 loss: 0.34338878304270204\n",
            "Round: 1574 Weight: [2.49736431 1.23893247] Bias: -1.1498875638591863 loss: 0.34338875179868517\n",
            "Round: 1575 Weight: [2.49741097 1.2389565 ] Bias: -1.1499060874635099 loss: 0.3433887207118034\n",
            "Round: 1576 Weight: [2.49745751 1.23898046] Bias: -1.1499245643474663 loss: 0.34338868978125975\n",
            "Round: 1577 Weight: [2.49750393 1.23900436] Bias: -1.1499429946311495 loss: 0.3433886590062611\n",
            "Round: 1578 Weight: [2.49755023 1.2390282 ] Bias: -1.1499613784343332 loss: 0.34338862838601836\n",
            "Round: 1579 Weight: [2.49759642 1.23905198] Bias: -1.1499797158764724 loss: 0.3433885979197469\n",
            "Round: 1580 Weight: [2.49764249 1.2390757 ] Bias: -1.1499980070767033 loss: 0.34338856760666553\n",
            "Round: 1581 Weight: [2.49768845 1.23909937] Bias: -1.150016252153845 loss: 0.34338853744599757\n",
            "Round: 1582 Weight: [2.49773429 1.23912297] Bias: -1.1500344512264002 loss: 0.3433885074369699\n",
            "Round: 1583 Weight: [2.49778001 1.23914651] Bias: -1.1500526044125556 loss: 0.34338847757881397\n",
            "Round: 1584 Weight: [2.49782562 1.23917   ] Bias: -1.1500707118301838 loss: 0.34338844787076456\n",
            "Round: 1585 Weight: [2.49787112 1.23919342] Bias: -1.1500887735968433 loss: 0.34338841831206063\n",
            "Round: 1586 Weight: [2.4979165  1.23921679] Bias: -1.1501067898297797 loss: 0.34338838890194506\n",
            "Round: 1587 Weight: [2.49796176 1.23924009] Bias: -1.1501247606459264 loss: 0.3433883596396647\n",
            "Round: 1588 Weight: [2.49800692 1.23926334] Bias: -1.1501426861619062 loss: 0.3433883305244701\n",
            "Round: 1589 Weight: [2.49805196 1.23928653] Bias: -1.1501605664940313 loss: 0.3433883015556157\n",
            "Round: 1590 Weight: [2.49809688 1.23930966] Bias: -1.1501784017583048 loss: 0.3433882727323599\n",
            "Round: 1591 Weight: [2.49814169 1.23933273] Bias: -1.150196192070421 loss: 0.3433882440539646\n",
            "Round: 1592 Weight: [2.49818639 1.23935575] Bias: -1.1502139375457665 loss: 0.3433882155196958\n",
            "Round: 1593 Weight: [2.49823098 1.23937871] Bias: -1.1502316382994215 loss: 0.3433881871288232\n",
            "Round: 1594 Weight: [2.49827546 1.23940161] Bias: -1.1502492944461604 loss: 0.3433881588806201\n",
            "Round: 1595 Weight: [2.49831982 1.23942445] Bias: -1.1502669061004525 loss: 0.34338813077436364\n",
            "Round: 1596 Weight: [2.49836407 1.23944723] Bias: -1.1502844733764626 loss: 0.3433881028093346\n",
            "Round: 1597 Weight: [2.49840821 1.23946996] Bias: -1.1503019963880527 loss: 0.34338807498481766\n",
            "Round: 1598 Weight: [2.49845224 1.23949263] Bias: -1.1503194752487824 loss: 0.34338804730010086\n",
            "Round: 1599 Weight: [2.49849616 1.23951524] Bias: -1.1503369100719092 loss: 0.3433880197544761\n",
            "Round: 1600 Weight: [2.49853997 1.2395378 ] Bias: -1.1503543009703903 loss: 0.34338799234723877\n",
            "Round: 1601 Weight: [2.49858367 1.2395603 ] Bias: -1.150371648056883 loss: 0.343387965077688\n",
            "Round: 1602 Weight: [2.49862725 1.23958274] Bias: -1.1503889514437458 loss: 0.34338793794512645\n",
            "Round: 1603 Weight: [2.49867073 1.23960513] Bias: -1.1504062112430384 loss: 0.3433879109488604\n",
            "Round: 1604 Weight: [2.4987141  1.23962746] Bias: -1.150423427566524 loss: 0.3433878840881997\n",
            "Round: 1605 Weight: [2.49875736 1.23964973] Bias: -1.1504406005256684 loss: 0.3433878573624574\n",
            "Round: 1606 Weight: [2.49880051 1.23967195] Bias: -1.1504577302316426 loss: 0.34338783077095075\n",
            "Round: 1607 Weight: [2.49884356 1.23969411] Bias: -1.1504748167953223 loss: 0.3433878043129998\n",
            "Round: 1608 Weight: [2.49888649 1.23971622] Bias: -1.1504918603272893 loss: 0.3433877779879285\n",
            "Round: 1609 Weight: [2.49892932 1.23973827] Bias: -1.1505088609378322 loss: 0.34338775179506426\n",
            "Round: 1610 Weight: [2.49897204 1.23976026] Bias: -1.1505258187369476 loss: 0.34338772573373766\n",
            "Round: 1611 Weight: [2.49901465 1.2397822 ] Bias: -1.15054273383434 loss: 0.3433876998032829\n",
            "Round: 1612 Weight: [2.49905715 1.23980409] Bias: -1.1505596063394237 loss: 0.34338767400303766\n",
            "Round: 1613 Weight: [2.49909955 1.23982592] Bias: -1.150576436361323 loss: 0.3433876483323428\n",
            "Round: 1614 Weight: [2.49914184 1.23984769] Bias: -1.150593224008873 loss: 0.34338762279054263\n",
            "Round: 1615 Weight: [2.49918403 1.23986941] Bias: -1.1506099693906209 loss: 0.34338759737698515\n",
            "Round: 1616 Weight: [2.49922611 1.23989108] Bias: -1.1506266726148262 loss: 0.34338757209102105\n",
            "Round: 1617 Weight: [2.49926808 1.23991269] Bias: -1.150643333789462 loss: 0.34338754693200496\n",
            "Round: 1618 Weight: [2.49930995 1.23993425] Bias: -1.150659953022215 loss: 0.3433875218992944\n",
            "Round: 1619 Weight: [2.49935171 1.23995575] Bias: -1.1506765304204878 loss: 0.3433874969922504\n",
            "Round: 1620 Weight: [2.49939337 1.2399772 ] Bias: -1.150693066091398 loss: 0.34338747221023713\n",
            "Round: 1621 Weight: [2.49943492 1.2399986 ] Bias: -1.1507095601417805 loss: 0.34338744755262224\n",
            "Round: 1622 Weight: [2.49947637 1.24001994] Bias: -1.1507260126781869 loss: 0.3433874230187763\n",
            "Round: 1623 Weight: [2.49951772 1.24004122] Bias: -1.1507424238068873 loss: 0.34338739860807316\n",
            "Round: 1624 Weight: [2.49955896 1.24006246] Bias: -1.1507587936338708 loss: 0.3433873743198902\n",
            "Round: 1625 Weight: [2.4996001  1.24008364] Bias: -1.1507751222648464 loss: 0.34338735015360766\n",
            "Round: 1626 Weight: [2.49964113 1.24010477] Bias: -1.1507914098052432 loss: 0.34338732610860895\n",
            "Round: 1627 Weight: [2.49968206 1.24012584] Bias: -1.150807656360212 loss: 0.34338730218428076\n",
            "Round: 1628 Weight: [2.49972289 1.24014686] Bias: -1.1508238620346256 loss: 0.3433872783800131\n",
            "Round: 1629 Weight: [2.49976361 1.24016783] Bias: -1.1508400269330796 loss: 0.3433872546951985\n",
            "Round: 1630 Weight: [2.49980424 1.24018875] Bias: -1.1508561511598936 loss: 0.3433872311292333\n",
            "Round: 1631 Weight: [2.49984476 1.24020961] Bias: -1.1508722348191112 loss: 0.3433872076815164\n",
            "Round: 1632 Weight: [2.49988518 1.24023042] Bias: -1.1508882780145016 loss: 0.34338718435145005\n",
            "Round: 1633 Weight: [2.4999255  1.24025118] Bias: -1.1509042808495595 loss: 0.34338716113843953\n",
            "Round: 1634 Weight: [2.49996571 1.24027189] Bias: -1.150920243427507 loss: 0.34338713804189297\n",
            "Round: 1635 Weight: [2.50000583 1.24029254] Bias: -1.150936165851293 loss: 0.3433871150612219\n",
            "Round: 1636 Weight: [2.50004584 1.24031315] Bias: -1.1509520482235955 loss: 0.34338709219584035\n",
            "Round: 1637 Weight: [2.50008576 1.2403337 ] Bias: -1.1509678906468208 loss: 0.34338706944516595\n",
            "Round: 1638 Weight: [2.50012557 1.2403542 ] Bias: -1.1509836932231052 loss: 0.3433870468086186\n",
            "Round: 1639 Weight: [2.50016529 1.24037464] Bias: -1.1509994560543158 loss: 0.3433870242856218\n",
            "Round: 1640 Weight: [2.5002049  1.24039504] Bias: -1.1510151792420504 loss: 0.3433870018756016\n",
            "Round: 1641 Weight: [2.50024442 1.24041539] Bias: -1.1510308628876398 loss: 0.34338697957798714\n",
            "Round: 1642 Weight: [2.50028383 1.24043568] Bias: -1.1510465070921467 loss: 0.3433869573922106\n",
            "Round: 1643 Weight: [2.50032315 1.24045592] Bias: -1.151062111956368 loss: 0.34338693531770664\n",
            "Round: 1644 Weight: [2.50036237 1.24047612] Bias: -1.1510776775808345 loss: 0.3433869133539133\n",
            "Round: 1645 Weight: [2.50040149 1.24049626] Bias: -1.151093204065812 loss: 0.3433868915002713\n",
            "Round: 1646 Weight: [2.50044051 1.24051635] Bias: -1.1511086915113022 loss: 0.34338686975622407\n",
            "Round: 1647 Weight: [2.50047943 1.24053639] Bias: -1.1511241400170436 loss: 0.34338684812121784\n",
            "Round: 1648 Weight: [2.50051826 1.24055638] Bias: -1.1511395496825112 loss: 0.34338682659470215\n",
            "Round: 1649 Weight: [2.50055699 1.24057632] Bias: -1.1511549206069187 loss: 0.34338680517612885\n",
            "Round: 1650 Weight: [2.50059562 1.24059621] Bias: -1.1511702528892183 loss: 0.3433867838649529\n",
            "Round: 1651 Weight: [2.50063415 1.24061605] Bias: -1.1511855466281014 loss: 0.34338676266063173\n",
            "Round: 1652 Weight: [2.50067259 1.24063585] Bias: -1.1512008019219997 loss: 0.3433867415626258\n",
            "Round: 1653 Weight: [2.50071093 1.24065559] Bias: -1.1512160188690859 loss: 0.34338672057039815\n",
            "Round: 1654 Weight: [2.50074918 1.24067528] Bias: -1.1512311975672742 loss: 0.34338669968341484\n",
            "Round: 1655 Weight: [2.50078733 1.24069492] Bias: -1.151246338114221 loss: 0.3433866789011443\n",
            "Round: 1656 Weight: [2.50082538 1.24071451] Bias: -1.151261440607326 loss: 0.34338665822305775\n",
            "Round: 1657 Weight: [2.50086334 1.24073406] Bias: -1.1512765051437326 loss: 0.3433866376486296\n",
            "Round: 1658 Weight: [2.5009012  1.24075355] Bias: -1.1512915318203283 loss: 0.3433866171773361\n",
            "Round: 1659 Weight: [2.50093897 1.240773  ] Bias: -1.151306520733746 loss: 0.34338659680865685\n",
            "Round: 1660 Weight: [2.50097664 1.24079239] Bias: -1.1513214719803648 loss: 0.3433865765420737\n",
            "Round: 1661 Weight: [2.50101422 1.24081174] Bias: -1.1513363856563101 loss: 0.3433865563770715\n",
            "Round: 1662 Weight: [2.5010517  1.24083104] Bias: -1.1513512618574544 loss: 0.34338653631313737\n",
            "Round: 1663 Weight: [2.50108909 1.24085029] Bias: -1.1513661006794187 loss: 0.34338651634976125\n",
            "Round: 1664 Weight: [2.50112639 1.2408695 ] Bias: -1.151380902217572 loss: 0.34338649648643566\n",
            "Round: 1665 Weight: [2.50116359 1.24088865] Bias: -1.1513956665670335 loss: 0.3433864767226558\n",
            "Round: 1666 Weight: [2.5012007  1.24090776] Bias: -1.1514103938226719 loss: 0.34338645705791904\n",
            "Round: 1667 Weight: [2.50123772 1.24092682] Bias: -1.1514250840791067 loss: 0.3433864374917259\n",
            "Round: 1668 Weight: [2.50127464 1.24094583] Bias: -1.1514397374307093 loss: 0.34338641802357905\n",
            "Round: 1669 Weight: [2.50131147 1.24096479] Bias: -1.151454353971603 loss: 0.3433863986529836\n",
            "Round: 1670 Weight: [2.50134821 1.24098371] Bias: -1.1514689337956636 loss: 0.34338637937944766\n",
            "Round: 1671 Weight: [2.50138486 1.24100258] Bias: -1.151483476996521 loss: 0.3433863602024815\n",
            "Round: 1672 Weight: [2.50142141 1.2410214 ] Bias: -1.151497983667559 loss: 0.3433863411215978\n",
            "Round: 1673 Weight: [2.50145788 1.24104017] Bias: -1.1515124539019164 loss: 0.3433863221363121\n",
            "Round: 1674 Weight: [2.50149425 1.2410589 ] Bias: -1.1515268877924876 loss: 0.3433863032461419\n",
            "Round: 1675 Weight: [2.50153053 1.24107758] Bias: -1.1515412854319231 loss: 0.3433862844506076\n",
            "Round: 1676 Weight: [2.50156672 1.24109621] Bias: -1.1515556469126305 loss: 0.34338626574923203\n",
            "Round: 1677 Weight: [2.50160282 1.2411148 ] Bias: -1.1515699723267747 loss: 0.3433862471415401\n",
            "Round: 1678 Weight: [2.50163882 1.24113334] Bias: -1.1515842617662795 loss: 0.3433862286270593\n",
            "Round: 1679 Weight: [2.50167474 1.24115183] Bias: -1.1515985153228268 loss: 0.3433862102053198\n",
            "Round: 1680 Weight: [2.50171057 1.24117028] Bias: -1.1516127330878587 loss: 0.3433861918758537\n",
            "Round: 1681 Weight: [2.50174631 1.24118868] Bias: -1.1516269151525775 loss: 0.34338617363819574\n",
            "Round: 1682 Weight: [2.50178196 1.24120703] Bias: -1.1516410616079462 loss: 0.34338615549188317\n",
            "Round: 1683 Weight: [2.50181751 1.24122534] Bias: -1.1516551725446893 loss: 0.3433861374364554\n",
            "Round: 1684 Weight: [2.50185298 1.2412436 ] Bias: -1.151669248053294 loss: 0.343386119471454\n",
            "Round: 1685 Weight: [2.50188837 1.24126182] Bias: -1.15168328822401 loss: 0.3433861015964234\n",
            "Round: 1686 Weight: [2.50192366 1.24127999] Bias: -1.1516972931468508 loss: 0.3433860838109099\n",
            "Round: 1687 Weight: [2.50195886 1.24129812] Bias: -1.151711262911594 loss: 0.3433860661144622\n",
            "Round: 1688 Weight: [2.50199398 1.2413162 ] Bias: -1.151725197607782 loss: 0.34338604850663124\n",
            "Round: 1689 Weight: [2.502029   1.24133423] Bias: -1.1517390973247228 loss: 0.3433860309869706\n",
            "Round: 1690 Weight: [2.50206394 1.24135222] Bias: -1.1517529621514906 loss: 0.3433860135550359\n",
            "Round: 1691 Weight: [2.5020988  1.24137017] Bias: -1.1517667921769263 loss: 0.3433859962103848\n",
            "Round: 1692 Weight: [2.50213356 1.24138807] Bias: -1.1517805874896383 loss: 0.3433859789525775\n",
            "Round: 1693 Weight: [2.50216824 1.24140592] Bias: -1.151794348178003 loss: 0.34338596178117636\n",
            "Round: 1694 Weight: [2.50220283 1.24142373] Bias: -1.1518080743301657 loss: 0.34338594469574596\n",
            "Round: 1695 Weight: [2.50223733 1.2414415 ] Bias: -1.1518217660340409 loss: 0.34338592769585313\n",
            "Round: 1696 Weight: [2.50227175 1.24145922] Bias: -1.151835423377313 loss: 0.3433859107810668\n",
            "Round: 1697 Weight: [2.50230608 1.24147689] Bias: -1.1518490464474371 loss: 0.34338589395095825\n",
            "Round: 1698 Weight: [2.50234033 1.24149452] Bias: -1.15186263533164 loss: 0.34338587720510066\n",
            "Round: 1699 Weight: [2.50237449 1.24151211] Bias: -1.1518761901169194 loss: 0.34338586054307\n",
            "Round: 1700 Weight: [2.50240856 1.24152966] Bias: -1.1518897108900468 loss: 0.3433858439644435\n",
            "Round: 1701 Weight: [2.50244255 1.24154716] Bias: -1.1519031977375658 loss: 0.34338582746880114\n",
            "Round: 1702 Weight: [2.50247645 1.24156461] Bias: -1.151916650745794 loss: 0.3433858110557252\n",
            "Round: 1703 Weight: [2.50251027 1.24158202] Bias: -1.1519300700008237 loss: 0.3433857947247994\n",
            "Round: 1704 Weight: [2.50254401 1.24159939] Bias: -1.151943455588522 loss: 0.3433857784756102\n",
            "Round: 1705 Weight: [2.50257765 1.24161672] Bias: -1.1519568075945315 loss: 0.3433857623077457\n",
            "Round: 1706 Weight: [2.50261122 1.241634  ] Bias: -1.1519701261042712 loss: 0.34338574622079665\n",
            "Round: 1707 Weight: [2.5026447  1.24165124] Bias: -1.151983411202937 loss: 0.3433857302143553\n",
            "Round: 1708 Weight: [2.5026781  1.24166843] Bias: -1.1519966629755023 loss: 0.34338571428801634\n",
            "Round: 1709 Weight: [2.50271141 1.24168559] Bias: -1.1520098815067183 loss: 0.3433856984413764\n",
            "Round: 1710 Weight: [2.50274464 1.2417027 ] Bias: -1.152023066881115 loss: 0.3433856826740341\n",
            "Round: 1711 Weight: [2.50277779 1.24171976] Bias: -1.152036219183002 loss: 0.3433856669855902\n",
            "Round: 1712 Weight: [2.50281085 1.24173679] Bias: -1.1520493384964683 loss: 0.34338565137564747\n",
            "Round: 1713 Weight: [2.50284383 1.24175377] Bias: -1.1520624249053837 loss: 0.3433856358438107\n",
            "Round: 1714 Weight: [2.50287673 1.24177071] Bias: -1.152075478493399 loss: 0.3433856203896866\n",
            "Round: 1715 Weight: [2.50290955 1.2417876 ] Bias: -1.1520884993439469 loss: 0.3433856050128841\n",
            "Round: 1716 Weight: [2.50294228 1.24180445] Bias: -1.152101487540242 loss: 0.34338558971301375\n",
            "Round: 1717 Weight: [2.50297493 1.24182127] Bias: -1.1521144431652823 loss: 0.3433855744896885\n",
            "Round: 1718 Weight: [2.5030075  1.24183804] Bias: -1.152127366301849 loss: 0.3433855593425229\n",
            "Round: 1719 Weight: [2.50303999 1.24185476] Bias: -1.1521402570325072 loss: 0.34338554427113366\n",
            "Round: 1720 Weight: [2.5030724  1.24187145] Bias: -1.152153115439607 loss: 0.34338552927513943\n",
            "Round: 1721 Weight: [2.50310472 1.24188809] Bias: -1.1521659416052836 loss: 0.3433855143541608\n",
            "Round: 1722 Weight: [2.50313697 1.2419047 ] Bias: -1.1521787356114583 loss: 0.34338549950782016\n",
            "Round: 1723 Weight: [2.50316913 1.24192126] Bias: -1.1521914975398384 loss: 0.3433854847357419\n",
            "Round: 1724 Weight: [2.50320122 1.24193777] Bias: -1.1522042274719186 loss: 0.3433854700375525\n",
            "Round: 1725 Weight: [2.50323322 1.24195425] Bias: -1.1522169254889811 loss: 0.3433854554128799\n",
            "Round: 1726 Weight: [2.50326514 1.24197069] Bias: -1.1522295916720962 loss: 0.3433854408613543\n",
            "Round: 1727 Weight: [2.50329699 1.24198708] Bias: -1.152242226102123 loss: 0.3433854263826078\n",
            "Round: 1728 Weight: [2.50332875 1.24200344] Bias: -1.1522548288597099 loss: 0.3433854119762739\n",
            "Round: 1729 Weight: [2.50336044 1.24201975] Bias: -1.1522674000252953 loss: 0.34338539764198867\n",
            "Round: 1730 Weight: [2.50339204 1.24203602] Bias: -1.1522799396791081 loss: 0.34338538337938934\n",
            "Round: 1731 Weight: [2.50342357 1.24205226] Bias: -1.1522924479011682 loss: 0.3433853691881155\n",
            "Round: 1732 Weight: [2.50345501 1.24206845] Bias: -1.152304924771287 loss: 0.3433853550678083\n",
            "Round: 1733 Weight: [2.50348638 1.2420846 ] Bias: -1.1523173703690686 loss: 0.3433853410181107\n",
            "Round: 1734 Weight: [2.50351767 1.24210071] Bias: -1.1523297847739091 loss: 0.3433853270386676\n",
            "Round: 1735 Weight: [2.50354888 1.24211678] Bias: -1.1523421680649986 loss: 0.3433853131291257\n",
            "Round: 1736 Weight: [2.50358001 1.24213281] Bias: -1.1523545203213206 loss: 0.34338529928913325\n",
            "Round: 1737 Weight: [2.50361107 1.2421488 ] Bias: -1.1523668416216535 loss: 0.3433852855183407\n",
            "Round: 1738 Weight: [2.50364205 1.24216475] Bias: -1.1523791320445704 loss: 0.3433852718163999\n",
            "Round: 1739 Weight: [2.50367295 1.24218066] Bias: -1.1523913916684403 loss: 0.3433852581829647\n",
            "Round: 1740 Weight: [2.50370377 1.24219653] Bias: -1.1524036205714279 loss: 0.34338524461769043\n",
            "Round: 1741 Weight: [2.50373452 1.24221236] Bias: -1.1524158188314948 loss: 0.3433852311202346\n",
            "Round: 1742 Weight: [2.50376518 1.24222815] Bias: -1.1524279865263998 loss: 0.343385217690256\n",
            "Round: 1743 Weight: [2.50379578 1.2422439 ] Bias: -1.1524401237336996 loss: 0.3433852043274154\n",
            "Round: 1744 Weight: [2.50382629 1.24225961] Bias: -1.1524522305307494 loss: 0.34338519103137544\n",
            "Round: 1745 Weight: [2.50385673 1.24227528] Bias: -1.1524643069947027 loss: 0.34338517780180006\n",
            "Round: 1746 Weight: [2.50388709 1.24229091] Bias: -1.152476353202513 loss: 0.34338516463835517\n",
            "Round: 1747 Weight: [2.50391738 1.24230651] Bias: -1.1524883692309338 loss: 0.3433851515407085\n",
            "Round: 1748 Weight: [2.50394759 1.24232206] Bias: -1.1525003551565185 loss: 0.34338513850852903\n",
            "Round: 1749 Weight: [2.50397773 1.24233758] Bias: -1.1525123110556221 loss: 0.3433851255414878\n",
            "Round: 1750 Weight: [2.50400779 1.24235306] Bias: -1.1525242370044013 loss: 0.34338511263925753\n",
            "Round: 1751 Weight: [2.50403777 1.2423685 ] Bias: -1.1525361330788146 loss: 0.3433850998015122\n",
            "Round: 1752 Weight: [2.50406768 1.24238389] Bias: -1.1525479993546235 loss: 0.3433850870279279\n",
            "Round: 1753 Weight: [2.50409752 1.24239926] Bias: -1.1525598359073925 loss: 0.34338507431818216\n",
            "Round: 1754 Weight: [2.50412728 1.24241458] Bias: -1.15257164281249 loss: 0.343385061671954\n",
            "Round: 1755 Weight: [2.50415696 1.24242986] Bias: -1.1525834201450884 loss: 0.3433850490889245\n",
            "Round: 1756 Weight: [2.50418658 1.24244511] Bias: -1.1525951679801654 loss: 0.3433850365687757\n",
            "Round: 1757 Weight: [2.50421611 1.24246032] Bias: -1.1526068863925036 loss: 0.343385024111192\n",
            "Round: 1758 Weight: [2.50424558 1.24247549] Bias: -1.1526185754566918 loss: 0.3433850117158588\n",
            "Round: 1759 Weight: [2.50427497 1.24249062] Bias: -1.152630235247125 loss: 0.3433849993824634\n",
            "Round: 1760 Weight: [2.50430428 1.24250571] Bias: -1.1526418658380053 loss: 0.34338498711069454\n",
            "Round: 1761 Weight: [2.50433353 1.24252077] Bias: -1.1526534673033422 loss: 0.3433849749002427\n",
            "Round: 1762 Weight: [2.5043627  1.24253579] Bias: -1.152665039716953 loss: 0.3433849627507997\n",
            "Round: 1763 Weight: [2.50439179 1.24255077] Bias: -1.152676583152464 loss: 0.3433849506620592\n",
            "Round: 1764 Weight: [2.50442082 1.24256572] Bias: -1.1526880976833096 loss: 0.3433849386337162\n",
            "Round: 1765 Weight: [2.50444977 1.24258062] Bias: -1.1526995833827347 loss: 0.3433849266654673\n",
            "Round: 1766 Weight: [2.50447865 1.24259549] Bias: -1.152711040323794 loss: 0.34338491475701055\n",
            "Round: 1767 Weight: [2.50450746 1.24261032] Bias: -1.1527224685793522 loss: 0.34338490290804574\n",
            "Round: 1768 Weight: [2.50453619 1.24262512] Bias: -1.1527338682220858 loss: 0.343384891118274\n",
            "Round: 1769 Weight: [2.50456486 1.24263988] Bias: -1.1527452393244826 loss: 0.34338487938739803\n",
            "Round: 1770 Weight: [2.50459345 1.2426546 ] Bias: -1.1527565819588423 loss: 0.3433848677151222\n",
            "Round: 1771 Weight: [2.50462197 1.24266928] Bias: -1.1527678961972774 loss: 0.343384856101152\n",
            "Round: 1772 Weight: [2.50465042 1.24268393] Bias: -1.1527791821117137 loss: 0.3433848445451948\n",
            "Round: 1773 Weight: [2.5046788  1.24269854] Bias: -1.1527904397738902 loss: 0.34338483304695905\n",
            "Round: 1774 Weight: [2.5047071  1.24271311] Bias: -1.1528016692553604 loss: 0.34338482160615513\n",
            "Round: 1775 Weight: [2.50473534 1.24272765] Bias: -1.1528128706274923 loss: 0.3433848102224945\n",
            "Round: 1776 Weight: [2.5047635  1.24274215] Bias: -1.152824043961469 loss: 0.34338479889569035\n",
            "Round: 1777 Weight: [2.5047916  1.24275662] Bias: -1.152835189328289 loss: 0.3433847876254572\n",
            "Round: 1778 Weight: [2.50481962 1.24277105] Bias: -1.1528463067987675 loss: 0.34338477641151094\n",
            "Round: 1779 Weight: [2.50484758 1.24278544] Bias: -1.152857396443536 loss: 0.34338476525356904\n",
            "Round: 1780 Weight: [2.50487546 1.2427998 ] Bias: -1.1528684583330429 loss: 0.3433847541513503\n",
            "Round: 1781 Weight: [2.50490328 1.24281412] Bias: -1.1528794925375545 loss: 0.3433847431045751\n",
            "Round: 1782 Weight: [2.50493102 1.24282841] Bias: -1.1528904991271551 loss: 0.34338473211296505\n",
            "Round: 1783 Weight: [2.5049587  1.24284266] Bias: -1.1529014781717477 loss: 0.34338472117624314\n",
            "Round: 1784 Weight: [2.50498631 1.24285687] Bias: -1.152912429741054 loss: 0.3433847102941341\n",
            "Round: 1785 Weight: [2.50501385 1.24287105] Bias: -1.152923353904616 loss: 0.34338469946636346\n",
            "Round: 1786 Weight: [2.50504131 1.24288519] Bias: -1.152934250731795 loss: 0.3433846886926587\n",
            "Round: 1787 Weight: [2.50506872 1.2428993 ] Bias: -1.1529451202917733 loss: 0.34338467797274863\n",
            "Round: 1788 Weight: [2.50509605 1.24291337] Bias: -1.1529559626535542 loss: 0.3433846673063631\n",
            "Round: 1789 Weight: [2.50512331 1.24292741] Bias: -1.1529667778859622 loss: 0.3433846566932333\n",
            "Round: 1790 Weight: [2.50515051 1.24294141] Bias: -1.1529775660576442 loss: 0.3433846461330923\n",
            "Round: 1791 Weight: [2.50517763 1.24295538] Bias: -1.1529883272370693 loss: 0.343384635625674\n",
            "Round: 1792 Weight: [2.50520469 1.24296931] Bias: -1.1529990614925296 loss: 0.34338462517071394\n",
            "Round: 1793 Weight: [2.50523169 1.24298321] Bias: -1.1530097688921408 loss: 0.3433846147679488\n",
            "Round: 1794 Weight: [2.50525861 1.24299707] Bias: -1.153020449503842 loss: 0.3433846044171167\n",
            "Round: 1795 Weight: [2.50528547 1.2430109 ] Bias: -1.1530311033953975 loss: 0.34338459411795724\n",
            "Round: 1796 Weight: [2.50531226 1.24302469] Bias: -1.1530417306343959 loss: 0.34338458387021104\n",
            "Round: 1797 Weight: [2.50533898 1.24303845] Bias: -1.153052331288251 loss: 0.34338457367362\n",
            "Round: 1798 Weight: [2.50536564 1.24305218] Bias: -1.1530629054242028 loss: 0.3433845635279278\n",
            "Round: 1799 Weight: [2.50539223 1.24306587] Bias: -1.153073453109317 loss: 0.34338455343287894\n",
            "Round: 1800 Weight: [2.50541875 1.24307952] Bias: -1.1530839744104866 loss: 0.34338454338821917\n",
            "Round: 1801 Weight: [2.50544521 1.24309315] Bias: -1.1530944693944318 loss: 0.3433845333936962\n",
            "Round: 1802 Weight: [2.5054716  1.24310673] Bias: -1.1531049381277 loss: 0.3433845234490582\n",
            "Round: 1803 Weight: [2.50549793 1.24312029] Bias: -1.153115380676667 loss: 0.3433845135540549\n",
            "Round: 1804 Weight: [2.50552419 1.24313381] Bias: -1.153125797107537 loss: 0.3433845037084375\n",
            "Round: 1805 Weight: [2.50555038 1.2431473 ] Bias: -1.1531361874863437 loss: 0.34338449391195836\n",
            "Round: 1806 Weight: [2.50557651 1.24316075] Bias: -1.1531465518789497 loss: 0.3433844841643708\n",
            "Round: 1807 Weight: [2.50560257 1.24317417] Bias: -1.1531568903510478 loss: 0.34338447446542997\n",
            "Round: 1808 Weight: [2.50562857 1.24318755] Bias: -1.1531672029681617 loss: 0.3433844648148916\n",
            "Round: 1809 Weight: [2.50565451 1.24320091] Bias: -1.153177489795645 loss: 0.343384455212513\n",
            "Round: 1810 Weight: [2.50568038 1.24321422] Bias: -1.1531877508986836 loss: 0.3433844456580529\n",
            "Round: 1811 Weight: [2.50570618 1.24322751] Bias: -1.1531979863422945 loss: 0.3433844361512706\n",
            "Round: 1812 Weight: [2.50573192 1.24324076] Bias: -1.1532081961913272 loss: 0.3433844266919275\n",
            "Round: 1813 Weight: [2.50575759 1.24325398] Bias: -1.1532183805104639 loss: 0.3433844172797854\n",
            "Round: 1814 Weight: [2.5057832  1.24326717] Bias: -1.1532285393642199 loss: 0.34338440791460784\n",
            "Round: 1815 Weight: [2.50580875 1.24328032] Bias: -1.153238672816944 loss: 0.3433843985961593\n",
            "Round: 1816 Weight: [2.50583424 1.24329344] Bias: -1.1532487809328191 loss: 0.3433843893242055\n",
            "Round: 1817 Weight: [2.50585965 1.24330653] Bias: -1.1532588637758627 loss: 0.3433843800985132\n",
            "Round: 1818 Weight: [2.50588501 1.24331959] Bias: -1.1532689214099268 loss: 0.3433843709188507\n",
            "Round: 1819 Weight: [2.5059103  1.24333261] Bias: -1.1532789538986992 loss: 0.3433843617849871\n",
            "Round: 1820 Weight: [2.50593553 1.2433456 ] Bias: -1.1532889613057034 loss: 0.3433843526966929\n",
            "Round: 1821 Weight: [2.5059607  1.24335856] Bias: -1.1532989436942989 loss: 0.34338434365373965\n",
            "Round: 1822 Weight: [2.5059858  1.24337148] Bias: -1.153308901127682 loss: 0.3433843346559001\n",
            "Round: 1823 Weight: [2.50601085 1.24338437] Bias: -1.1533188336688862 loss: 0.3433843257029482\n",
            "Round: 1824 Weight: [2.50603582 1.24339723] Bias: -1.1533287413807825 loss: 0.34338431679465875\n",
            "Round: 1825 Weight: [2.50606074 1.24341006] Bias: -1.15333862432608 loss: 0.34338430793080815\n",
            "Round: 1826 Weight: [2.50608559 1.24342286] Bias: -1.153348482567326 loss: 0.34338429911117346\n",
            "Round: 1827 Weight: [2.50611039 1.24343562] Bias: -1.1533583161669065 loss: 0.34338429033553336\n",
            "Round: 1828 Weight: [2.50613512 1.24344836] Bias: -1.1533681251870473 loss: 0.3433842816036671\n",
            "Round: 1829 Weight: [2.50615978 1.24346106] Bias: -1.1533779096898136 loss: 0.3433842729153555\n",
            "Round: 1830 Weight: [2.50618439 1.24347373] Bias: -1.1533876697371108 loss: 0.3433842642703802\n",
            "Round: 1831 Weight: [2.50620894 1.24348636] Bias: -1.1533974053906848 loss: 0.34338425566852415\n",
            "Round: 1832 Weight: [2.50623342 1.24349897] Bias: -1.1534071167121225 loss: 0.34338424710957116\n",
            "Round: 1833 Weight: [2.50625784 1.24351155] Bias: -1.1534168037628523 loss: 0.34338423859330636\n",
            "Round: 1834 Weight: [2.50628221 1.24352409] Bias: -1.1534264666041443 loss: 0.3433842301195159\n",
            "Round: 1835 Weight: [2.50630651 1.2435366 ] Bias: -1.153436105297111 loss: 0.34338422168798693\n",
            "Round: 1836 Weight: [2.50633075 1.24354908] Bias: -1.1534457199027075 loss: 0.34338421329850766\n",
            "Round: 1837 Weight: [2.50635493 1.24356153] Bias: -1.153455310481732 loss: 0.3433842049508674\n",
            "Round: 1838 Weight: [2.50637905 1.24357395] Bias: -1.1534648770948264 loss: 0.34338419664485686\n",
            "Round: 1839 Weight: [2.50640311 1.24358634] Bias: -1.1534744198024764 loss: 0.343384188380267\n",
            "Round: 1840 Weight: [2.50642711 1.24359869] Bias: -1.1534839386650122 loss: 0.34338418015689076\n",
            "Round: 1841 Weight: [2.50645104 1.24361102] Bias: -1.1534934337426084 loss: 0.3433841719745214\n",
            "Round: 1842 Weight: [2.50647492 1.24362331] Bias: -1.153502905095285 loss: 0.34338416383295384\n",
            "Round: 1843 Weight: [2.50649874 1.24363558] Bias: -1.1535123527829079 loss: 0.34338415573198344\n",
            "Round: 1844 Weight: [2.50652251 1.24364781] Bias: -1.1535217768651884 loss: 0.34338414767140685\n",
            "Round: 1845 Weight: [2.50654621 1.24366001] Bias: -1.153531177401685 loss: 0.34338413965102194\n",
            "Round: 1846 Weight: [2.50656985 1.24367219] Bias: -1.1535405544518023 loss: 0.34338413167062737\n",
            "Round: 1847 Weight: [2.50659343 1.24368433] Bias: -1.1535499080747926 loss: 0.34338412373002264\n",
            "Round: 1848 Weight: [2.50661696 1.24369644] Bias: -1.1535592383297557 loss: 0.3433841158290088\n",
            "Round: 1849 Weight: [2.50664042 1.24370852] Bias: -1.1535685452756395 loss: 0.3433841079673874\n",
            "Round: 1850 Weight: [2.50666383 1.24372057] Bias: -1.15357782897124 loss: 0.3433841001449611\n",
            "Round: 1851 Weight: [2.50668718 1.2437326 ] Bias: -1.1535870894752027 loss: 0.34338409236153394\n",
            "Round: 1852 Weight: [2.50671047 1.24374459] Bias: -1.153596326846022 loss: 0.3433840846169104\n",
            "Round: 1853 Weight: [2.5067337  1.24375655] Bias: -1.153605541142042 loss: 0.3433840769108961\n",
            "Round: 1854 Weight: [2.50675687 1.24376848] Bias: -1.153614732421457 loss: 0.343384069243298\n",
            "Round: 1855 Weight: [2.50677999 1.24378038] Bias: -1.1536239007423112 loss: 0.34338406161392365\n",
            "Round: 1856 Weight: [2.50680305 1.24379225] Bias: -1.1536330461625006 loss: 0.3433840540225815\n",
            "Round: 1857 Weight: [2.50682605 1.2438041 ] Bias: -1.153642168739772 loss: 0.3433840464690814\n",
            "Round: 1858 Weight: [2.50684899 1.24381591] Bias: -1.1536512685317235 loss: 0.3433840389532337\n",
            "Round: 1859 Weight: [2.50687188 1.24382769] Bias: -1.1536603455958059 loss: 0.34338403147485\n",
            "Round: 1860 Weight: [2.50689471 1.24383945] Bias: -1.153669399989322 loss: 0.34338402403374274\n",
            "Round: 1861 Weight: [2.50691748 1.24385117] Bias: -1.1536784317694275 loss: 0.3433840166297252\n",
            "Round: 1862 Weight: [2.5069402  1.24386287] Bias: -1.1536874409931317 loss: 0.34338400926261203\n",
            "Round: 1863 Weight: [2.50696286 1.24387453] Bias: -1.1536964277172972 loss: 0.3433840019322182\n",
            "Round: 1864 Weight: [2.50698546 1.24388617] Bias: -1.1537053919986404 loss: 0.34338399463836006\n",
            "Round: 1865 Weight: [2.50700801 1.24389778] Bias: -1.1537143338937326 loss: 0.3433839873808547\n",
            "Round: 1866 Weight: [2.5070305  1.24390936] Bias: -1.1537232534589994 loss: 0.3433839801595202\n",
            "Round: 1867 Weight: [2.50705293 1.24392091] Bias: -1.153732150750722 loss: 0.34338397297417533\n",
            "Round: 1868 Weight: [2.50707531 1.24393243] Bias: -1.153741025825037 loss: 0.3433839658246403\n",
            "Round: 1869 Weight: [2.50709763 1.24394392] Bias: -1.1537498787379366 loss: 0.34338395871073574\n",
            "Round: 1870 Weight: [2.5071199  1.24395539] Bias: -1.15375870954527 loss: 0.34338395163228325\n",
            "Round: 1871 Weight: [2.50714211 1.24396682] Bias: -1.1537675183027423 loss: 0.3433839445891056\n",
            "Round: 1872 Weight: [2.50716426 1.24397823] Bias: -1.1537763050659164 loss: 0.3433839375810261\n",
            "Round: 1873 Weight: [2.50718636 1.24398961] Bias: -1.1537850698902123 loss: 0.34338393060786926\n",
            "Round: 1874 Weight: [2.50720841 1.24400096] Bias: -1.153793812830908 loss: 0.3433839236694603\n",
            "Round: 1875 Weight: [2.5072304  1.24401228] Bias: -1.1538025339431397 loss: 0.3433839167656251\n",
            "Round: 1876 Weight: [2.50725233 1.24402358] Bias: -1.153811233281902 loss: 0.34338390989619116\n",
            "Round: 1877 Weight: [2.50727421 1.24403484] Bias: -1.1538199109020484 loss: 0.34338390306098593\n",
            "Round: 1878 Weight: [2.50729604 1.24404608] Bias: -1.1538285668582922 loss: 0.34338389625983834\n",
            "Round: 1879 Weight: [2.50731781 1.24405729] Bias: -1.153837201205206 loss: 0.3433838894925781\n",
            "Round: 1880 Weight: [2.50733953 1.24406847] Bias: -1.153845813997223 loss: 0.34338388275903536\n",
            "Round: 1881 Weight: [2.50736119 1.24407962] Bias: -1.1538544052886361 loss: 0.34338387605904164\n",
            "Round: 1882 Weight: [2.5073828  1.24409075] Bias: -1.1538629751335998 loss: 0.34338386939242915\n",
            "Round: 1883 Weight: [2.50740435 1.24410185] Bias: -1.1538715235861292 loss: 0.3433838627590309\n",
            "Round: 1884 Weight: [2.50742585 1.24411292] Bias: -1.1538800507001012 loss: 0.34338385615868056\n",
            "Round: 1885 Weight: [2.5074473  1.24412396] Bias: -1.153888556529255 loss: 0.34338384959121304\n",
            "Round: 1886 Weight: [2.5074687  1.24413497] Bias: -1.1538970411271912 loss: 0.34338384305646374\n",
            "Round: 1887 Weight: [2.50749004 1.24414596] Bias: -1.1539055045473738 loss: 0.34338383655426913\n",
            "Round: 1888 Weight: [2.50751132 1.24415692] Bias: -1.1539139468431299 loss: 0.3433838300844662\n",
            "Round: 1889 Weight: [2.50753256 1.24416786] Bias: -1.1539223680676494 loss: 0.343383823646893\n",
            "Round: 1890 Weight: [2.50755374 1.24417876] Bias: -1.1539307682739863 loss: 0.34338381724138844\n",
            "Round: 1891 Weight: [2.50757487 1.24418964] Bias: -1.1539391475150589 loss: 0.34338381086779196\n",
            "Round: 1892 Weight: [2.50759595 1.24420049] Bias: -1.1539475058436495 loss: 0.3433838045259442\n",
            "Round: 1893 Weight: [2.50761697 1.24421132] Bias: -1.1539558433124057 loss: 0.34338379821568615\n",
            "Round: 1894 Weight: [2.50763794 1.24422211] Bias: -1.15396415997384 loss: 0.34338379193686014\n",
            "Round: 1895 Weight: [2.50765886 1.24423288] Bias: -1.1539724558803304 loss: 0.34338378568930866\n",
            "Round: 1896 Weight: [2.50767973 1.24424363] Bias: -1.153980731084121 loss: 0.34338377947287557\n",
            "Round: 1897 Weight: [2.50770054 1.24425434] Bias: -1.1539889856373222 loss: 0.34338377328740505\n",
            "Round: 1898 Weight: [2.5077213  1.24426503] Bias: -1.1539972195919108 loss: 0.3433837671327426\n",
            "Round: 1899 Weight: [2.50774201 1.2442757 ] Bias: -1.1540054329997305 loss: 0.34338376100873386\n",
            "Round: 1900 Weight: [2.50776267 1.24428633] Bias: -1.1540136259124925 loss: 0.34338375491522555\n",
            "Round: 1901 Weight: [2.50778328 1.24429694] Bias: -1.1540217983817758 loss: 0.3433837488520655\n",
            "Round: 1902 Weight: [2.50780384 1.24430753] Bias: -1.154029950459027 loss: 0.34338374281910167\n",
            "Round: 1903 Weight: [2.50782434 1.24431809] Bias: -1.1540380821955616 loss: 0.3433837368161833\n",
            "Round: 1904 Weight: [2.5078448  1.24432862] Bias: -1.1540461936425632 loss: 0.34338373084316004\n",
            "Round: 1905 Weight: [2.5078652  1.24433912] Bias: -1.1540542848510849 loss: 0.34338372489988245\n",
            "Round: 1906 Weight: [2.50788555 1.2443496 ] Bias: -1.1540623558720489 loss: 0.3433837189862019\n",
            "Round: 1907 Weight: [2.50790585 1.24436005] Bias: -1.1540704067562475 loss: 0.3433837131019704\n",
            "Round: 1908 Weight: [2.5079261  1.24437048] Bias: -1.1540784375543427 loss: 0.34338370724704076\n",
            "Round: 1909 Weight: [2.5079463  1.24438088] Bias: -1.1540864483168674 loss: 0.34338370142126656\n",
            "Round: 1910 Weight: [2.50796645 1.24439125] Bias: -1.1540944390942247 loss: 0.343383695624502\n",
            "Round: 1911 Weight: [2.50798655 1.2444016 ] Bias: -1.1541024099366892 loss: 0.343383689856602\n",
            "Round: 1912 Weight: [2.5080066  1.24441193] Bias: -1.154110360894407 loss: 0.34338368411742237\n",
            "Round: 1913 Weight: [2.5080266  1.24442222] Bias: -1.1541182920173958 loss: 0.34338367840681966\n",
            "Round: 1914 Weight: [2.50804655 1.24443249] Bias: -1.1541262033555453 loss: 0.34338367272465087\n",
            "Round: 1915 Weight: [2.50806645 1.24444274] Bias: -1.154134094958618 loss: 0.343383667070774\n",
            "Round: 1916 Weight: [2.50808631 1.24445296] Bias: -1.1541419668762494 loss: 0.3433836614450476\n",
            "Round: 1917 Weight: [2.50810611 1.24446316] Bias: -1.1541498191579473 loss: 0.34338365584733105\n",
            "Round: 1918 Weight: [2.50812586 1.24447333] Bias: -1.1541576518530938 loss: 0.34338365027748435\n",
            "Round: 1919 Weight: [2.50814556 1.24448347] Bias: -1.1541654650109443 loss: 0.34338364473536825\n",
            "Round: 1920 Weight: [2.50816521 1.24449359] Bias: -1.1541732586806286 loss: 0.34338363922084414\n",
            "Round: 1921 Weight: [2.50818482 1.24450368] Bias: -1.154181032911151 loss: 0.3433836337337741\n",
            "Round: 1922 Weight: [2.50820437 1.24451375] Bias: -1.1541887877513906 loss: 0.3433836282740211\n",
            "Round: 1923 Weight: [2.50822388 1.24452379] Bias: -1.1541965232501012 loss: 0.3433836228414485\n",
            "Round: 1924 Weight: [2.50824334 1.24453381] Bias: -1.1542042394559129 loss: 0.3433836174359206\n",
            "Round: 1925 Weight: [2.50826275 1.24454381] Bias: -1.1542119364173307 loss: 0.3433836120573021\n",
            "Round: 1926 Weight: [2.50828211 1.24455377] Bias: -1.154219614182736 loss: 0.3433836067054587\n",
            "Round: 1927 Weight: [2.50830142 1.24456372] Bias: -1.1542272728003873 loss: 0.3433836013802567\n",
            "Round: 1928 Weight: [2.50832069 1.24457364] Bias: -1.154234912318419 loss: 0.3433835960815628\n",
            "Round: 1929 Weight: [2.50833991 1.24458353] Bias: -1.154242532784843 loss: 0.3433835908092447\n",
            "Round: 1930 Weight: [2.50835908 1.2445934 ] Bias: -1.1542501342475482 loss: 0.34338358556317045\n",
            "Round: 1931 Weight: [2.5083782  1.24460325] Bias: -1.154257716754302 loss: 0.3433835803432093\n",
            "Round: 1932 Weight: [2.50839727 1.24461307] Bias: -1.1542652803527493 loss: 0.34338357514923046\n",
            "Round: 1933 Weight: [2.5084163  1.24462286] Bias: -1.1542728250904135 loss: 0.3433835699811044\n",
            "Round: 1934 Weight: [2.50843528 1.24463263] Bias: -1.1542803510146966 loss: 0.34338356483870175\n",
            "Round: 1935 Weight: [2.50845421 1.24464238] Bias: -1.15428785817288 loss: 0.34338355972189427\n",
            "Round: 1936 Weight: [2.50847309 1.2446521 ] Bias: -1.154295346612124 loss: 0.34338355463055387\n",
            "Round: 1937 Weight: [2.50849193 1.2446618 ] Bias: -1.1543028163794686 loss: 0.34338354956455336\n",
            "Round: 1938 Weight: [2.50851072 1.24467148] Bias: -1.1543102675218342 loss: 0.3433835445237664\n",
            "Round: 1939 Weight: [2.50852946 1.24468113] Bias: -1.154317700086021 loss: 0.34338353950806694\n",
            "Round: 1940 Weight: [2.50854816 1.24469075] Bias: -1.1543251141187099 loss: 0.3433835345173295\n",
            "Round: 1941 Weight: [2.50856681 1.24470036] Bias: -1.1543325096664627 loss: 0.3433835295514297\n",
            "Round: 1942 Weight: [2.50858541 1.24470993] Bias: -1.1543398867757229 loss: 0.3433835246102434\n",
            "Round: 1943 Weight: [2.50860397 1.24471949] Bias: -1.154347245492815 loss: 0.34338351969364717\n",
            "Round: 1944 Weight: [2.50862248 1.24472902] Bias: -1.1543545858639452 loss: 0.3433835148015182\n",
            "Round: 1945 Weight: [2.50864095 1.24473853] Bias: -1.1543619079352025 loss: 0.34338350993373423\n",
            "Round: 1946 Weight: [2.50865937 1.24474801] Bias: -1.1543692117525581 loss: 0.3433835050901739\n",
            "Round: 1947 Weight: [2.50867774 1.24475747] Bias: -1.1543764973618658 loss: 0.343383500270716\n",
            "Round: 1948 Weight: [2.50869607 1.24476691] Bias: -1.1543837648088624 loss: 0.34338349547524033\n",
            "Round: 1949 Weight: [2.50871435 1.24477632] Bias: -1.1543910141391684 loss: 0.3433834907036271\n",
            "Round: 1950 Weight: [2.50873259 1.24478571] Bias: -1.1543982453982882 loss: 0.3433834859557571\n",
            "Round: 1951 Weight: [2.50875078 1.24479507] Bias: -1.1544054586316095 loss: 0.3433834812315121\n",
            "Round: 1952 Weight: [2.50876892 1.24480442] Bias: -1.1544126538844046 loss: 0.3433834765307736\n",
            "Round: 1953 Weight: [2.50878702 1.24481374] Bias: -1.1544198312018308 loss: 0.34338347185342466\n",
            "Round: 1954 Weight: [2.50880508 1.24482303] Bias: -1.15442699062893 loss: 0.3433834671993483\n",
            "Round: 1955 Weight: [2.50882309 1.2448323 ] Bias: -1.154434132210629 loss: 0.34338346256842855\n",
            "Round: 1956 Weight: [2.50884105 1.24484155] Bias: -1.154441255991741 loss: 0.3433834579605496\n",
            "Round: 1957 Weight: [2.50885897 1.24485078] Bias: -1.154448362016964 loss: 0.3433834533755966\n",
            "Round: 1958 Weight: [2.50887685 1.24485999] Bias: -1.1544554503308828 loss: 0.3433834488134548\n",
            "Round: 1959 Weight: [2.50889468 1.24486917] Bias: -1.1544625209779684 loss: 0.34338344427401063\n",
            "Round: 1960 Weight: [2.50891247 1.24487832] Bias: -1.1544695740025783 loss: 0.34338343975715074\n",
            "Round: 1961 Weight: [2.50893021 1.24488746] Bias: -1.1544766094489574 loss: 0.3433834352627622\n",
            "Round: 1962 Weight: [2.50894791 1.24489657] Bias: -1.1544836273612376 loss: 0.3433834307907329\n",
            "Round: 1963 Weight: [2.50896557 1.24490566] Bias: -1.1544906277834384 loss: 0.34338342634095154\n",
            "Round: 1964 Weight: [2.50898318 1.24491473] Bias: -1.1544976107594676 loss: 0.34338342191330673\n",
            "Round: 1965 Weight: [2.50900074 1.24492377] Bias: -1.1545045763331205 loss: 0.3433834175076882\n",
            "Round: 1966 Weight: [2.50901827 1.2449328 ] Bias: -1.1545115245480817 loss: 0.3433834131239858\n",
            "Round: 1967 Weight: [2.50903575 1.24494179] Bias: -1.1545184554479238 loss: 0.3433834087620903\n",
            "Round: 1968 Weight: [2.50905318 1.24495077] Bias: -1.1545253690761088 loss: 0.3433834044218927\n",
            "Round: 1969 Weight: [2.50907057 1.24495973] Bias: -1.1545322654759882 loss: 0.34338340010328494\n",
            "Round: 1970 Weight: [2.50908792 1.24496866] Bias: -1.1545391446908029 loss: 0.34338339580615923\n",
            "Round: 1971 Weight: [2.50910523 1.24497757] Bias: -1.1545460067636837 loss: 0.34338339153040826\n",
            "Round: 1972 Weight: [2.50912249 1.24498646] Bias: -1.154552851737652 loss: 0.3433833872759253\n",
            "Round: 1973 Weight: [2.50913971 1.24499532] Bias: -1.1545596796556192 loss: 0.34338338304260446\n",
            "Round: 1974 Weight: [2.50915689 1.24500417] Bias: -1.1545664905603878 loss: 0.34338337883034\n",
            "Round: 1975 Weight: [2.50917402 1.24501299] Bias: -1.1545732844946515 loss: 0.3433833746390267\n",
            "Round: 1976 Weight: [2.50919112 1.24502179] Bias: -1.154580061500995 loss: 0.3433833704685603\n",
            "Round: 1977 Weight: [2.50920817 1.24503057] Bias: -1.1545868216218944 loss: 0.34338336631883665\n",
            "Round: 1978 Weight: [2.50922517 1.24503932] Bias: -1.1545935648997188 loss: 0.34338336218975224\n",
            "Round: 1979 Weight: [2.50924214 1.24504806] Bias: -1.1546002913767284 loss: 0.34338335808120407\n",
            "Round: 1980 Weight: [2.50925906 1.24505677] Bias: -1.1546070010950766 loss: 0.3433833539930896\n",
            "Round: 1981 Weight: [2.50927594 1.24506546] Bias: -1.1546136940968093 loss: 0.34338334992530717\n",
            "Round: 1982 Weight: [2.50929278 1.24507413] Bias: -1.1546203704238653 loss: 0.343383345877755\n",
            "Round: 1983 Weight: [2.50930957 1.24508278] Bias: -1.154627030118077 loss: 0.3433833418503324\n",
            "Round: 1984 Weight: [2.50932633 1.2450914 ] Bias: -1.1546336732211702 loss: 0.34338333784293884\n",
            "Round: 1985 Weight: [2.50934304 1.24510001] Bias: -1.154640299774765 loss: 0.3433833338554745\n",
            "Round: 1986 Weight: [2.50935971 1.24510859] Bias: -1.1546469098203749 loss: 0.34338332988783976\n",
            "Round: 1987 Weight: [2.50937634 1.24511715] Bias: -1.1546535033994085 loss: 0.34338332593993587\n",
            "Round: 1988 Weight: [2.50939293 1.24512569] Bias: -1.154660080553169 loss: 0.3433833220116643\n",
            "Round: 1989 Weight: [2.50940947 1.24513421] Bias: -1.1546666413228546 loss: 0.34338331810292727\n",
            "Round: 1990 Weight: [2.50942598 1.24514271] Bias: -1.1546731857495585 loss: 0.34338331421362717\n",
            "Round: 1991 Weight: [2.50944244 1.24515119] Bias: -1.1546797138742697 loss: 0.34338331034366715\n",
            "Round: 1992 Weight: [2.50945887 1.24515964] Bias: -1.154686225737873 loss: 0.3433833064929506\n",
            "Round: 1993 Weight: [2.50947525 1.24516808] Bias: -1.1546927213811489 loss: 0.34338330266138173\n",
            "Round: 1994 Weight: [2.50949159 1.24517649] Bias: -1.154699200844775 loss: 0.3433832988488649\n",
            "Round: 1995 Weight: [2.50950789 1.24518489] Bias: -1.1547056641693247 loss: 0.3433832950553052\n",
            "Round: 1996 Weight: [2.50952415 1.24519326] Bias: -1.154712111395269 loss: 0.343383291280608\n",
            "Round: 1997 Weight: [2.50954037 1.24520161] Bias: -1.1547185425629756 loss: 0.3433832875246792\n",
            "Round: 1998 Weight: [2.50955655 1.24520994] Bias: -1.1547249577127097 loss: 0.3433832837874252\n",
            "Round: 1999 Weight: [2.50957269 1.24521825] Bias: -1.1547313568846345 loss: 0.34338328006875296\n",
            "Round: 2000 Weight: [2.50958879 1.24522654] Bias: -1.1547377401188108 loss: 0.34338327636856975\n",
            "Round: 2001 Weight: [2.50960485 1.24523481] Bias: -1.1547441074551978 loss: 0.3433832726867833\n",
            "Round: 2002 Weight: [2.50962087 1.24524305] Bias: -1.1547504589336532 loss: 0.343383269023302\n",
            "Round: 2003 Weight: [2.50963685 1.24525128] Bias: -1.1547567945939334 loss: 0.34338326537803443\n",
            "Round: 2004 Weight: [2.50965279 1.24525949] Bias: -1.1547631144756938 loss: 0.3433832617508899\n",
            "Round: 2005 Weight: [2.50966869 1.24526767] Bias: -1.1547694186184891 loss: 0.3433832581417779\n",
            "Round: 2006 Weight: [2.50968455 1.24527584] Bias: -1.1547757070617737 loss: 0.34338325455060875\n",
            "Round: 2007 Weight: [2.50970037 1.24528398] Bias: -1.1547819798449017 loss: 0.34338325097729266\n",
            "Round: 2008 Weight: [2.50971615 1.24529211] Bias: -1.1547882370071274 loss: 0.3433832474217408\n",
            "Round: 2009 Weight: [2.50973189 1.24530022] Bias: -1.1547944785876052 loss: 0.34338324388386454\n",
            "Round: 2010 Weight: [2.5097476 1.2453083] Bias: -1.15480070462539 loss: 0.34338324036357587\n",
            "Round: 2011 Weight: [2.50976326 1.24531636] Bias: -1.154806915159438 loss: 0.343383236860787\n",
            "Round: 2012 Weight: [2.50977889 1.24532441] Bias: -1.154813110228606 loss: 0.3433832333754106\n",
            "Round: 2013 Weight: [2.50979447 1.24533243] Bias: -1.154819289871653 loss: 0.34338322990736\n",
            "Round: 2014 Weight: [2.50981002 1.24534044] Bias: -1.1548254541272382 loss: 0.3433832264565487\n",
            "Round: 2015 Weight: [2.50982553 1.24534842] Bias: -1.1548316030339243 loss: 0.34338322302289087\n",
            "Round: 2016 Weight: [2.509841   1.24535639] Bias: -1.1548377366301747 loss: 0.3433832196063009\n",
            "Round: 2017 Weight: [2.50985643 1.24536433] Bias: -1.1548438549543563 loss: 0.3433832162066939\n",
            "Round: 2018 Weight: [2.50987182 1.24537226] Bias: -1.154849958044738 loss: 0.34338321282398493\n",
            "Round: 2019 Weight: [2.50988718 1.24538016] Bias: -1.1548560459394919 loss: 0.34338320945808987\n",
            "Round: 2020 Weight: [2.50990249 1.24538805] Bias: -1.154862118676693 loss: 0.343383206108925\n",
            "Round: 2021 Weight: [2.50991777 1.24539592] Bias: -1.1548681762943198 loss: 0.34338320277640677\n",
            "Round: 2022 Weight: [2.50993301 1.24540376] Bias: -1.1548742188302545 loss: 0.3433831994604522\n",
            "Round: 2023 Weight: [2.50994822 1.24541159] Bias: -1.1548802463222834 loss: 0.3433831961609789\n",
            "Round: 2024 Weight: [2.50996338 1.2454194 ] Bias: -1.1548862588080964 loss: 0.3433831928779047\n",
            "Round: 2025 Weight: [2.50997851 1.24542719] Bias: -1.1548922563252881 loss: 0.3433831896111476\n",
            "Round: 2026 Weight: [2.5099936  1.24543496] Bias: -1.154898238911358 loss: 0.3433831863606266\n",
            "Round: 2027 Weight: [2.51000865 1.24544271] Bias: -1.15490420660371 loss: 0.3433831831262606\n",
            "Round: 2028 Weight: [2.51002366 1.24545044] Bias: -1.1549101594396538 loss: 0.34338317990796907\n",
            "Round: 2029 Weight: [2.51003864 1.24545815] Bias: -1.154916097456404 loss: 0.34338317670567187\n",
            "Round: 2030 Weight: [2.51005358 1.24546584] Bias: -1.1549220206910804 loss: 0.3433831735192895\n",
            "Round: 2031 Weight: [2.51006848 1.24547351] Bias: -1.1549279291807097 loss: 0.34338317034874244\n",
            "Round: 2032 Weight: [2.51008335 1.24548117] Bias: -1.1549338229622241 loss: 0.34338316719395173\n",
            "Round: 2033 Weight: [2.51009818 1.2454888 ] Bias: -1.1549397020724623 loss: 0.3433831640548391\n",
            "Round: 2034 Weight: [2.51011297 1.24549642] Bias: -1.1549455665481696 loss: 0.3433831609313262\n",
            "Round: 2035 Weight: [2.51012772 1.24550401] Bias: -1.1549514164259982 loss: 0.34338315782333545\n",
            "Round: 2036 Weight: [2.51014244 1.24551159] Bias: -1.1549572517425073 loss: 0.3433831547307893\n",
            "Round: 2037 Weight: [2.51015712 1.24551915] Bias: -1.1549630725341633 loss: 0.343383151653611\n",
            "Round: 2038 Weight: [2.51017177 1.24552669] Bias: -1.1549688788373407 loss: 0.34338314859172375\n",
            "Round: 2039 Weight: [2.51018638 1.24553421] Bias: -1.1549746706883213 loss: 0.3433831455450517\n",
            "Round: 2040 Weight: [2.51020095 1.24554171] Bias: -1.154980448123295 loss: 0.34338314251351865\n",
            "Round: 2041 Weight: [2.51021549 1.2455492 ] Bias: -1.1549862111783602 loss: 0.34338313949704924\n",
            "Round: 2042 Weight: [2.51022999 1.24555666] Bias: -1.1549919598895237 loss: 0.34338313649556873\n",
            "Round: 2043 Weight: [2.51024445 1.24556411] Bias: -1.1549976942927014 loss: 0.34338313350900207\n",
            "Round: 2044 Weight: [2.51025888 1.24557154] Bias: -1.1550034144237176 loss: 0.3433831305372752\n",
            "Round: 2045 Weight: [2.51027327 1.24557895] Bias: -1.1550091203183064 loss: 0.343383127580314\n",
            "Round: 2046 Weight: [2.51028763 1.24558634] Bias: -1.1550148120121109 loss: 0.343383124638045\n",
            "Round: 2047 Weight: [2.51030195 1.24559371] Bias: -1.1550204895406841 loss: 0.343383121710395\n",
            "Round: 2048 Weight: [2.51031623 1.24560107] Bias: -1.1550261529394894 loss: 0.34338311879729116\n",
            "Round: 2049 Weight: [2.51033048 1.2456084 ] Bias: -1.1550318022438997 loss: 0.3433831158986611\n",
            "Round: 2050 Weight: [2.51034469 1.24561572] Bias: -1.1550374374891985 loss: 0.3433831130144325\n",
            "Round: 2051 Weight: [2.51035887 1.24562302] Bias: -1.15504305871058 loss: 0.3433831101445338\n",
            "Round: 2052 Weight: [2.51037302 1.2456303 ] Bias: -1.1550486659431494 loss: 0.3433831072888935\n",
            "Round: 2053 Weight: [2.51038712 1.24563757] Bias: -1.1550542592219228 loss: 0.34338310444744075\n",
            "Round: 2054 Weight: [2.5104012  1.24564481] Bias: -1.1550598385818278 loss: 0.3433831016201046\n",
            "Round: 2055 Weight: [2.51041524 1.24565204] Bias: -1.1550654040577035 loss: 0.343383098806815\n",
            "Round: 2056 Weight: [2.51042924 1.24565925] Bias: -1.1550709556843006 loss: 0.34338309600750183\n",
            "Round: 2057 Weight: [2.51044321 1.24566644] Bias: -1.1550764934962823 loss: 0.3433830932220956\n",
            "Round: 2058 Weight: [2.51045714 1.24567362] Bias: -1.1550820175282235 loss: 0.34338309045052684\n",
            "Round: 2059 Weight: [2.51047104 1.24568077] Bias: -1.1550875278146118 loss: 0.34338308769272674\n",
            "Round: 2060 Weight: [2.5104849  1.24568791] Bias: -1.1550930243898476 loss: 0.34338308494862685\n",
            "Round: 2061 Weight: [2.51049873 1.24569503] Bias: -1.1550985072882443 loss: 0.34338308221815866\n",
            "Round: 2062 Weight: [2.51051253 1.24570213] Bias: -1.155103976544028 loss: 0.34338307950125446\n",
            "Round: 2063 Weight: [2.51052629 1.24570922] Bias: -1.1551094321913389 loss: 0.34338307679784674\n",
            "Round: 2064 Weight: [2.51054002 1.24571629] Bias: -1.15511487426423 loss: 0.34338307410786806\n",
            "Round: 2065 Weight: [2.51055371 1.24572334] Bias: -1.1551203027966688 loss: 0.3433830714312517\n",
            "Round: 2066 Weight: [2.51056737 1.24573037] Bias: -1.1551257178225363 loss: 0.34338306876793123\n",
            "Round: 2067 Weight: [2.51058099 1.24573738] Bias: -1.1551311193756282 loss: 0.3433830661178402\n",
            "Round: 2068 Weight: [2.51059458 1.24574438] Bias: -1.1551365074896545 loss: 0.34338306348091274\n",
            "Round: 2069 Weight: [2.51060814 1.24575136] Bias: -1.1551418821982398 loss: 0.34338306085708353\n",
            "Round: 2070 Weight: [2.51062166 1.24575832] Bias: -1.155147243534924 loss: 0.3433830582462871\n",
            "Round: 2071 Weight: [2.51063515 1.24576527] Bias: -1.1551525915331617 loss: 0.34338305564845856\n",
            "Round: 2072 Weight: [2.51064861 1.2457722 ] Bias: -1.1551579262263232 loss: 0.3433830530635335\n",
            "Round: 2073 Weight: [2.51066203 1.24577911] Bias: -1.1551632476476943 loss: 0.34338305049144774\n",
            "Round: 2074 Weight: [2.51067542 1.245786  ] Bias: -1.1551685558304765 loss: 0.3433830479321369\n",
            "Round: 2075 Weight: [2.51068878 1.24579288] Bias: -1.1551738508077876 loss: 0.3433830453855379\n",
            "Round: 2076 Weight: [2.5107021  1.24579974] Bias: -1.1551791326126613 loss: 0.3433830428515871\n",
            "Round: 2077 Weight: [2.51071539 1.24580658] Bias: -1.155184401278048 loss: 0.3433830403302216\n",
            "Round: 2078 Weight: [2.51072865 1.24581341] Bias: -1.1551896568368145 loss: 0.34338303782137874\n",
            "Round: 2079 Weight: [2.51074187 1.24582021] Bias: -1.1551948993217451 loss: 0.34338303532499626\n",
            "Round: 2080 Weight: [2.51075506 1.24582701] Bias: -1.1552001287655407 loss: 0.34338303284101207\n",
            "Round: 2081 Weight: [2.51076822 1.24583378] Bias: -1.1552053452008193 loss: 0.3433830303693644\n",
            "Round: 2082 Weight: [2.51078135 1.24584054] Bias: -1.155210548660117 loss: 0.34338302790999176\n",
            "Round: 2083 Weight: [2.51079444 1.24584728] Bias: -1.1552157391758875 loss: 0.3433830254628332\n",
            "Round: 2084 Weight: [2.5108075 1.245854 ] Bias: -1.155220916780502 loss: 0.34338302302782786\n",
            "Round: 2085 Weight: [2.51082053 1.24586071] Bias: -1.1552260815062507 loss: 0.34338302060491527\n",
            "Round: 2086 Weight: [2.51083352 1.2458674 ] Bias: -1.1552312333853414 loss: 0.3433830181940351\n",
            "Round: 2087 Weight: [2.51084649 1.24587408] Bias: -1.1552363724499009 loss: 0.34338301579512764\n",
            "Round: 2088 Weight: [2.51085942 1.24588073] Bias: -1.1552414987319746 loss: 0.34338301340813304\n",
            "Round: 2089 Weight: [2.51087232 1.24588737] Bias: -1.155246612263527 loss: 0.3433830110329921\n",
            "Round: 2090 Weight: [2.51088518 1.245894  ] Bias: -1.155251713076442 loss: 0.343383008669646\n",
            "Round: 2091 Weight: [2.51089802 1.24590061] Bias: -1.1552568012025226 loss: 0.34338300631803576\n",
            "Round: 2092 Weight: [2.51091082 1.2459072 ] Bias: -1.1552618766734917 loss: 0.34338300397810306\n",
            "Round: 2093 Weight: [2.51092359 1.24591377] Bias: -1.155266939520992 loss: 0.3433830016497898\n",
            "Round: 2094 Weight: [2.51093633 1.24592033] Bias: -1.1552719897765862 loss: 0.34338299933303823\n",
            "Round: 2095 Weight: [2.51094904 1.24592688] Bias: -1.155277027471757 loss: 0.34338299702779057\n",
            "Round: 2096 Weight: [2.51096171 1.2459334 ] Bias: -1.155282052637908 loss: 0.34338299473398975\n",
            "Round: 2097 Weight: [2.51097436 1.24593991] Bias: -1.1552870653063634 loss: 0.3433829924515788\n",
            "Round: 2098 Weight: [2.51098697 1.24594641] Bias: -1.155292065508368 loss: 0.3433829901805008\n",
            "Round: 2099 Weight: [2.51099955 1.24595288] Bias: -1.155297053275088 loss: 0.34338298792069966\n",
            "Round: 2100 Weight: [2.5110121  1.24595935] Bias: -1.1553020286376103 loss: 0.34338298567211906\n",
            "Round: 2101 Weight: [2.51102462 1.24596579] Bias: -1.155306991626944 loss: 0.34338298343470314\n",
            "Round: 2102 Weight: [2.51103711 1.24597222] Bias: -1.1553119422740197 loss: 0.34338298120839644\n",
            "Round: 2103 Weight: [2.51104957 1.24597863] Bias: -1.1553168806096894 loss: 0.3433829789931436\n",
            "Round: 2104 Weight: [2.51106199 1.24598503] Bias: -1.155321806664728 loss: 0.3433829767888897\n",
            "Round: 2105 Weight: [2.51107439 1.24599141] Bias: -1.1553267204698319 loss: 0.3433829745955798\n",
            "Round: 2106 Weight: [2.51108675 1.24599778] Bias: -1.1553316220556205 loss: 0.34338297241315957\n",
            "Round: 2107 Weight: [2.51109909 1.24600413] Bias: -1.1553365114526355 loss: 0.34338297024157494\n",
            "Round: 2108 Weight: [2.51111139 1.24601046] Bias: -1.155341388691342 loss: 0.34338296808077184\n",
            "Round: 2109 Weight: [2.51112366 1.24601678] Bias: -1.1553462538021275 loss: 0.34338296593069656\n",
            "Round: 2110 Weight: [2.5111359  1.24602309] Bias: -1.1553511068153035 loss: 0.3433829637912959\n",
            "Round: 2111 Weight: [2.51114812 1.24602937] Bias: -1.1553559477611046 loss: 0.3433829616625166\n",
            "Round: 2112 Weight: [2.5111603  1.24603564] Bias: -1.155360776669689 loss: 0.3433829595443058\n",
            "Round: 2113 Weight: [2.51117245 1.2460419 ] Bias: -1.1553655935711389 loss: 0.343382957436611\n",
            "Round: 2114 Weight: [2.51118457 1.24604814] Bias: -1.1553703984954606 loss: 0.34338295533937985\n",
            "Round: 2115 Weight: [2.51119666 1.24605437] Bias: -1.155375191472585 loss: 0.3433829532525603\n",
            "Round: 2116 Weight: [2.51120872 1.24606058] Bias: -1.1553799725323666 loss: 0.34338295117610035\n",
            "Round: 2117 Weight: [2.51122075 1.24606677] Bias: -1.1553847417045853 loss: 0.34338294910994877\n",
            "Round: 2118 Weight: [2.51123275 1.24607295] Bias: -1.1553894990189455 loss: 0.3433829470540541\n",
            "Round: 2119 Weight: [2.51124472 1.24607911] Bias: -1.1553942445050767 loss: 0.3433829450083653\n",
            "Round: 2120 Weight: [2.51125666 1.24608526] Bias: -1.1553989781925338 loss: 0.3433829429728316\n",
            "Round: 2121 Weight: [2.51126857 1.24609139] Bias: -1.155403700110797 loss: 0.3433829409474025\n",
            "Round: 2122 Weight: [2.51128046 1.24609751] Bias: -1.155408410289272 loss: 0.34338293893202765\n",
            "Round: 2123 Weight: [2.51129231 1.24610361] Bias: -1.1554131087572908 loss: 0.3433829369266572\n",
            "Round: 2124 Weight: [2.51130413 1.2461097 ] Bias: -1.1554177955441105 loss: 0.3433829349312412\n",
            "Round: 2125 Weight: [2.51131592 1.24611577] Bias: -1.1554224706789153 loss: 0.34338293294573036\n",
            "Round: 2126 Weight: [2.51132769 1.24612183] Bias: -1.1554271341908153 loss: 0.34338293097007505\n",
            "Round: 2127 Weight: [2.51133942 1.24612787] Bias: -1.1554317861088472 loss: 0.34338292900422657\n",
            "Round: 2128 Weight: [2.51135113 1.2461339 ] Bias: -1.1554364264619748 loss: 0.34338292704813594\n",
            "Round: 2129 Weight: [2.51136281 1.24613991] Bias: -1.1554410552790881 loss: 0.3433829251017548\n",
            "Round: 2130 Weight: [2.51137445 1.24614591] Bias: -1.1554456725890052 loss: 0.34338292316503444\n",
            "Round: 2131 Weight: [2.51138607 1.24615189] Bias: -1.1554502784204708 loss: 0.34338292123792735\n",
            "Round: 2132 Weight: [2.51139766 1.24615785] Bias: -1.1554548728021574 loss: 0.34338291932038534\n",
            "Round: 2133 Weight: [2.51140922 1.24616381] Bias: -1.1554594557626652 loss: 0.34338291741236093\n",
            "Round: 2134 Weight: [2.51142076 1.24616974] Bias: -1.1554640273305221 loss: 0.3433829155138069\n",
            "Round: 2135 Weight: [2.51143226 1.24617567] Bias: -1.1554685875341844 loss: 0.34338291362467593\n",
            "Round: 2136 Weight: [2.51144373 1.24618158] Bias: -1.1554731364020363 loss: 0.34338291174492136\n",
            "Round: 2137 Weight: [2.51145518 1.24618747] Bias: -1.1554776739623904 loss: 0.3433829098744963\n",
            "Round: 2138 Weight: [2.5114666  1.24619335] Bias: -1.1554822002434884 loss: 0.3433829080133545\n",
            "Round: 2139 Weight: [2.51147799 1.24619921] Bias: -1.1554867152735004 loss: 0.34338290616144984\n",
            "Round: 2140 Weight: [2.51148935 1.24620506] Bias: -1.1554912190805255 loss: 0.3433829043187363\n",
            "Round: 2141 Weight: [2.51150068 1.2462109 ] Bias: -1.1554957116925921 loss: 0.3433829024851682\n",
            "Round: 2142 Weight: [2.51151199 1.24621672] Bias: -1.155500193137658 loss: 0.3433829006607\n",
            "Round: 2143 Weight: [2.51152327 1.24622252] Bias: -1.1555046634436104 loss: 0.3433828988452864\n",
            "Round: 2144 Weight: [2.51153451 1.24622831] Bias: -1.1555091226382659 loss: 0.3433828970388826\n",
            "Round: 2145 Weight: [2.51154574 1.24623409] Bias: -1.1555135707493718 loss: 0.34338289524144355\n",
            "Round: 2146 Weight: [2.51155693 1.24623985] Bias: -1.1555180078046048 loss: 0.3433828934529247\n",
            "Round: 2147 Weight: [2.51156809 1.2462456 ] Bias: -1.155522433831572 loss: 0.3433828916732818\n",
            "Round: 2148 Weight: [2.51157923 1.24625134] Bias: -1.155526848857811 loss: 0.34338288990247057\n",
            "Round: 2149 Weight: [2.51159034 1.24625706] Bias: -1.15553125291079 loss: 0.3433828881404473\n",
            "Round: 2150 Weight: [2.51160142 1.24626276] Bias: -1.155535646017908 loss: 0.3433828863871681\n",
            "Round: 2151 Weight: [2.51161248 1.24626845] Bias: -1.155540028206495 loss: 0.34338288464258954\n",
            "Round: 2152 Weight: [2.51162351 1.24627413] Bias: -1.155544399503812 loss: 0.3433828829066683\n",
            "Round: 2153 Weight: [2.51163451 1.2462798 ] Bias: -1.1555487599370513 loss: 0.34338288117936144\n",
            "Round: 2154 Weight: [2.51164548 1.24628545] Bias: -1.155553109533337 loss: 0.34338287946062596\n",
            "Round: 2155 Weight: [2.51165642 1.24629108] Bias: -1.1555574483197244 loss: 0.3433828777504195\n",
            "Round: 2156 Weight: [2.51166734 1.2462967 ] Bias: -1.1555617763232011 loss: 0.3433828760486993\n",
            "Round: 2157 Weight: [2.51167823 1.24630231] Bias: -1.1555660935706864 loss: 0.3433828743554235\n",
            "Round: 2158 Weight: [2.5116891 1.2463079] Bias: -1.1555704000890321 loss: 0.34338287267054995\n",
            "Round: 2159 Weight: [2.51169994 1.24631348] Bias: -1.1555746959050222 loss: 0.34338287099403686\n",
            "Round: 2160 Weight: [2.51171075 1.24631905] Bias: -1.155578981045373 loss: 0.34338286932584283\n",
            "Round: 2161 Weight: [2.51172153 1.2463246 ] Bias: -1.1555832555367338 loss: 0.34338286766592613\n",
            "Round: 2162 Weight: [2.51173228 1.24633014] Bias: -1.1555875194056868 loss: 0.343382866014246\n",
            "Round: 2163 Weight: [2.51174301 1.24633566] Bias: -1.155591772678747 loss: 0.3433828643707612\n",
            "Round: 2164 Weight: [2.51175372 1.24634117] Bias: -1.155596015382363 loss: 0.34338286273543117\n",
            "Round: 2165 Weight: [2.51176439 1.24634667] Bias: -1.1556002475429166 loss: 0.3433828611082153\n",
            "Round: 2166 Weight: [2.51177504 1.24635215] Bias: -1.155604469186723 loss: 0.34338285948907327\n",
            "Round: 2167 Weight: [2.51178567 1.24635762] Bias: -1.1556086803400316 loss: 0.34338285787796496\n",
            "Round: 2168 Weight: [2.51179627 1.24636308] Bias: -1.1556128810290252 loss: 0.34338285627485027\n",
            "Round: 2169 Weight: [2.51180684 1.24636852] Bias: -1.155617071279821 loss: 0.34338285467968965\n",
            "Round: 2170 Weight: [2.51181738 1.24637395] Bias: -1.1556212511184705 loss: 0.3433828530924435\n",
            "Round: 2171 Weight: [2.5118279  1.24637937] Bias: -1.155625420570959 loss: 0.34338285151307235\n",
            "Round: 2172 Weight: [2.51183839 1.24638477] Bias: -1.1556295796632075 loss: 0.34338284994153717\n",
            "Round: 2173 Weight: [2.51184886 1.24639016] Bias: -1.1556337284210707 loss: 0.3433828483777991\n",
            "Round: 2174 Weight: [2.5118593  1.24639553] Bias: -1.1556378668703386 loss: 0.34338284682181913\n",
            "Round: 2175 Weight: [2.51186971 1.24640089] Bias: -1.1556419950367365 loss: 0.343382845273559\n",
            "Round: 2176 Weight: [2.5118801  1.24640624] Bias: -1.1556461129459248 loss: 0.34338284373298006\n",
            "Round: 2177 Weight: [2.51189046 1.24641158] Bias: -1.155650220623499 loss: 0.3433828422000442\n",
            "Round: 2178 Weight: [2.5119008 1.2464169] Bias: -1.155654318094991 loss: 0.34338284067471364\n",
            "Round: 2179 Weight: [2.51191111 1.24642221] Bias: -1.1556584053858674 loss: 0.34338283915695034\n",
            "Round: 2180 Weight: [2.5119214 1.2464275] Bias: -1.1556624825215314 loss: 0.3433828376467166\n",
            "Round: 2181 Weight: [2.51193166 1.24643279] Bias: -1.1556665495273222 loss: 0.3433828361439753\n",
            "Round: 2182 Weight: [2.51194189 1.24643806] Bias: -1.155670606428515 loss: 0.34338283464868896\n",
            "Round: 2183 Weight: [2.5119521  1.24644331] Bias: -1.1556746532503215 loss: 0.34338283316082063\n",
            "Round: 2184 Weight: [2.51196228 1.24644856] Bias: -1.1556786900178904 loss: 0.3433828316803334\n",
            "Round: 2185 Weight: [2.51197244 1.24645379] Bias: -1.1556827167563064 loss: 0.3433828302071907\n",
            "Round: 2186 Weight: [2.51198258 1.246459  ] Bias: -1.1556867334905916 loss: 0.3433828287413557\n",
            "Round: 2187 Weight: [2.51199268 1.24646421] Bias: -1.1556907402457048 loss: 0.34338282728279257\n",
            "Round: 2188 Weight: [2.51200277 1.2464694 ] Bias: -1.1556947370465422 loss: 0.3433828258314647\n",
            "Round: 2189 Weight: [2.51201283 1.24647458] Bias: -1.1556987239179375 loss: 0.3433828243873363\n",
            "Round: 2190 Weight: [2.51202286 1.24647974] Bias: -1.1557027008846619 loss: 0.3433828229503718\n",
            "Round: 2191 Weight: [2.51203287 1.2464849 ] Bias: -1.1557066679714239 loss: 0.34338282152053534\n",
            "Round: 2192 Weight: [2.51204285 1.24649004] Bias: -1.1557106252028704 loss: 0.3433828200977915\n",
            "Round: 2193 Weight: [2.51205281 1.24649516] Bias: -1.1557145726035858 loss: 0.34338281868210513\n",
            "Round: 2194 Weight: [2.51206274 1.24650028] Bias: -1.1557185101980931 loss: 0.34338281727344117\n",
            "Round: 2195 Weight: [2.51207265 1.24650538] Bias: -1.1557224380108535 loss: 0.3433828158717646\n",
            "Round: 2196 Weight: [2.51208254 1.24651047] Bias: -1.1557263560662665 loss: 0.3433828144770409\n",
            "Round: 2197 Weight: [2.5120924  1.24651554] Bias: -1.1557302643886704 loss: 0.34338281308923524\n",
            "Round: 2198 Weight: [2.51210223 1.24652061] Bias: -1.1557341630023423 loss: 0.3433828117083134\n",
            "Round: 2199 Weight: [2.51211204 1.24652566] Bias: -1.1557380519314984 loss: 0.3433828103342413\n",
            "Round: 2200 Weight: [2.51212183 1.2465307 ] Bias: -1.1557419312002934 loss: 0.3433828089669847\n",
            "Round: 2201 Weight: [2.51213159 1.24653572] Bias: -1.1557458008328223 loss: 0.34338280760650974\n",
            "Round: 2202 Weight: [2.51214133 1.24654074] Bias: -1.1557496608531184 loss: 0.3433828062527829\n",
            "Round: 2203 Weight: [2.51215104 1.24654574] Bias: -1.1557535112851554 loss: 0.34338280490577044\n",
            "Round: 2204 Weight: [2.51216073 1.24655073] Bias: -1.1557573521528461 loss: 0.3433828035654391\n",
            "Round: 2205 Weight: [2.5121704 1.2465557] Bias: -1.1557611834800439 loss: 0.3433828022317556\n",
            "Round: 2206 Weight: [2.51218004 1.24656067] Bias: -1.1557650052905417 loss: 0.343382800904687\n",
            "Round: 2207 Weight: [2.51218966 1.24656562] Bias: -1.1557688176080727 loss: 0.3433827995842004\n",
            "Round: 2208 Weight: [2.51219925 1.24657056] Bias: -1.1557726204563106 loss: 0.34338279827026313\n",
            "Round: 2209 Weight: [2.51220882 1.24657549] Bias: -1.1557764138588693 loss: 0.3433827969628426\n",
            "Round: 2210 Weight: [2.51221837 1.2465804 ] Bias: -1.1557801978393039 loss: 0.3433827956619064\n",
            "Round: 2211 Weight: [2.51222789 1.24658531] Bias: -1.1557839724211094 loss: 0.3433827943674224\n",
            "Round: 2212 Weight: [2.51223739 1.2465902 ] Bias: -1.1557877376277228 loss: 0.34338279307935854\n",
            "Round: 2213 Weight: [2.51224687 1.24659507] Bias: -1.1557914934825213 loss: 0.3433827917976828\n",
            "Round: 2214 Weight: [2.51225632 1.24659994] Bias: -1.1557952400088238 loss: 0.34338279052236365\n",
            "Round: 2215 Weight: [2.51226575 1.2466048 ] Bias: -1.1557989772298907 loss: 0.3433827892533693\n",
            "Round: 2216 Weight: [2.51227515 1.24660964] Bias: -1.1558027051689237 loss: 0.3433827879906683\n",
            "Round: 2217 Weight: [2.51228453 1.24661447] Bias: -1.1558064238490664 loss: 0.3433827867342296\n",
            "Round: 2218 Weight: [2.51229389 1.24661929] Bias: -1.1558101332934039 loss: 0.343382785484022\n",
            "Round: 2219 Weight: [2.51230323 1.24662409] Bias: -1.1558138335249637 loss: 0.34338278424001445\n",
            "Round: 2220 Weight: [2.51231254 1.24662889] Bias: -1.155817524566715 loss: 0.34338278300217634\n",
            "Round: 2221 Weight: [2.51232183 1.24663367] Bias: -1.15582120644157 loss: 0.3433827817704768\n",
            "Round: 2222 Weight: [2.51233109 1.24663844] Bias: -1.1558248791723826 loss: 0.34338278054488547\n",
            "Round: 2223 Weight: [2.51234034 1.2466432 ] Bias: -1.1558285427819497 loss: 0.343382779325372\n",
            "Round: 2224 Weight: [2.51234956 1.24664795] Bias: -1.1558321972930108 loss: 0.34338277811190615\n",
            "Round: 2225 Weight: [2.51235875 1.24665268] Bias: -1.1558358427282482 loss: 0.34338277690445795\n",
            "Round: 2226 Weight: [2.51236793 1.2466574 ] Bias: -1.1558394791102875 loss: 0.3433827757029973\n",
            "Round: 2227 Weight: [2.51237708 1.24666212] Bias: -1.1558431064616972 loss: 0.34338277450749466\n",
            "Round: 2228 Weight: [2.51238621 1.24666682] Bias: -1.155846724804989 loss: 0.3433827733179205\n",
            "Round: 2229 Weight: [2.51239531 1.2466715 ] Bias: -1.1558503341626187 loss: 0.3433827721342451\n",
            "Round: 2230 Weight: [2.5124044  1.24667618] Bias: -1.1558539345569852 loss: 0.34338277095643954\n",
            "Round: 2231 Weight: [2.51241346 1.24668085] Bias: -1.155857526010431 loss: 0.3433827697844742\n",
            "Round: 2232 Weight: [2.5124225 1.2466855] Bias: -1.1558611085452426 loss: 0.34338276861832046\n",
            "Round: 2233 Weight: [2.51243151 1.24669014] Bias: -1.155864682183651 loss: 0.3433827674579492\n",
            "Round: 2234 Weight: [2.51244051 1.24669477] Bias: -1.1558682469478307 loss: 0.3433827663033318\n",
            "Round: 2235 Weight: [2.51244948 1.24669939] Bias: -1.155871802859901 loss: 0.3433827651544398\n",
            "Round: 2236 Weight: [2.51245843 1.246704  ] Bias: -1.1558753499419256 loss: 0.34338276401124457\n",
            "Round: 2237 Weight: [2.51246735 1.24670859] Bias: -1.1558788882159126 loss: 0.3433827628737179\n",
            "Round: 2238 Weight: [2.51247626 1.24671318] Bias: -1.1558824177038147 loss: 0.3433827617418315\n",
            "Round: 2239 Weight: [2.51248514 1.24671775] Bias: -1.15588593842753 loss: 0.34338276061555767\n",
            "Round: 2240 Weight: [2.512494   1.24672231] Bias: -1.1558894504089012 loss: 0.34338275949486824\n",
            "Round: 2241 Weight: [2.51250284 1.24672686] Bias: -1.1558929536697164 loss: 0.3433827583797356\n",
            "Round: 2242 Weight: [2.51251166 1.2467314 ] Bias: -1.155896448231709 loss: 0.343382757270132\n",
            "Round: 2243 Weight: [2.51252045 1.24673593] Bias: -1.1558999341165574 loss: 0.3433827561660303\n",
            "Round: 2244 Weight: [2.51252922 1.24674045] Bias: -1.1559034113458864 loss: 0.34338275506740296\n",
            "Round: 2245 Weight: [2.51253797 1.24674495] Bias: -1.1559068799412657 loss: 0.3433827539742227\n",
            "Round: 2246 Weight: [2.5125467  1.24674945] Bias: -1.1559103399242114 loss: 0.3433827528864627\n",
            "Round: 2247 Weight: [2.51255541 1.24675393] Bias: -1.1559137913161854 loss: 0.3433827518040958\n",
            "Round: 2248 Weight: [2.5125641 1.2467584] Bias: -1.1559172341385957 loss: 0.34338275072709545\n",
            "Round: 2249 Weight: [2.51257276 1.24676286] Bias: -1.1559206684127965 loss: 0.34338274965543475\n",
            "Round: 2250 Weight: [2.5125814  1.24676731] Bias: -1.1559240941600886 loss: 0.3433827485890875\n",
            "Round: 2251 Weight: [2.51259003 1.24677175] Bias: -1.1559275114017193 loss: 0.343382747528027\n",
            "Round: 2252 Weight: [2.51259863 1.24677618] Bias: -1.1559309201588825 loss: 0.34338274647222733\n",
            "Round: 2253 Weight: [2.5126072 1.2467806] Bias: -1.155934320452719 loss: 0.34338274542166186\n",
            "Round: 2254 Weight: [2.51261576 1.246785  ] Bias: -1.1559377123043164 loss: 0.343382744376305\n",
            "Round: 2255 Weight: [2.5126243 1.2467894] Bias: -1.1559410957347096 loss: 0.34338274333613095\n",
            "Round: 2256 Weight: [2.51263281 1.24679378] Bias: -1.1559444707648805 loss: 0.3433827423011137\n",
            "Round: 2257 Weight: [2.51264131 1.24679816] Bias: -1.1559478374157586 loss: 0.34338274127122775\n",
            "Round: 2258 Weight: [2.51264978 1.24680252] Bias: -1.1559511957082207 loss: 0.3433827402464476\n",
            "Round: 2259 Weight: [2.51265823 1.24680687] Bias: -1.1559545456630913 loss: 0.343382739226748\n",
            "Round: 2260 Weight: [2.51266666 1.24681121] Bias: -1.1559578873011427 loss: 0.3433827382121036\n",
            "Round: 2261 Weight: [2.51267507 1.24681554] Bias: -1.155961220643095 loss: 0.3433827372024894\n",
            "Round: 2262 Weight: [2.51268346 1.24681986] Bias: -1.1559645457096162 loss: 0.3433827361978803\n",
            "Round: 2263 Weight: [2.51269183 1.24682417] Bias: -1.1559678625213226 loss: 0.3433827351982516\n",
            "Round: 2264 Weight: [2.51270018 1.24682846] Bias: -1.1559711710987788 loss: 0.34338273420357834\n",
            "Round: 2265 Weight: [2.5127085  1.24683275] Bias: -1.1559744714624978 loss: 0.3433827332138361\n",
            "Round: 2266 Weight: [2.51271681 1.24683703] Bias: -1.1559777636329411 loss: 0.34338273222900045\n",
            "Round: 2267 Weight: [2.5127251  1.24684129] Bias: -1.1559810476305192 loss: 0.3433827312490469\n",
            "Round: 2268 Weight: [2.51273336 1.24684555] Bias: -1.1559843234755909 loss: 0.3433827302739511\n",
            "Round: 2269 Weight: [2.5127416  1.24684979] Bias: -1.155987591188464 loss: 0.3433827293036893\n",
            "Round: 2270 Weight: [2.51274983 1.24685403] Bias: -1.155990850789396 loss: 0.34338272833823713\n",
            "Round: 2271 Weight: [2.51275803 1.24685825] Bias: -1.1559941022985927 loss: 0.3433827273775709\n",
            "Round: 2272 Weight: [2.51276622 1.24686246] Bias: -1.1559973457362098 loss: 0.34338272642166684\n",
            "Round: 2273 Weight: [2.51277438 1.24686667] Bias: -1.1560005811223524 loss: 0.3433827254705013\n",
            "Round: 2274 Weight: [2.51278252 1.24687086] Bias: -1.156003808477075 loss: 0.34338272452405066\n",
            "Round: 2275 Weight: [2.51279064 1.24687504] Bias: -1.1560070278203818 loss: 0.34338272358229166\n",
            "Round: 2276 Weight: [2.51279875 1.24687921] Bias: -1.1560102391722271 loss: 0.3433827226452008\n",
            "Round: 2277 Weight: [2.51280683 1.24688337] Bias: -1.156013442552515 loss: 0.3433827217127551\n",
            "Round: 2278 Weight: [2.51281489 1.24688753] Bias: -1.1560166379810999 loss: 0.34338272078493143\n",
            "Round: 2279 Weight: [2.51282293 1.24689167] Bias: -1.1560198254777858 loss: 0.3433827198617068\n",
            "Round: 2280 Weight: [2.51283095 1.2468958 ] Bias: -1.156023005062328 loss: 0.34338271894305855\n",
            "Round: 2281 Weight: [2.51283896 1.24689992] Bias: -1.156026176754431 loss: 0.34338271802896375\n",
            "Round: 2282 Weight: [2.51284694 1.24690403] Bias: -1.1560293405737514 loss: 0.34338271711939994\n",
            "Round: 2283 Weight: [2.5128549  1.24690813] Bias: -1.1560324965398956 loss: 0.34338271621434446\n",
            "Round: 2284 Weight: [2.51286284 1.24691221] Bias: -1.156035644672421 loss: 0.3433827153137752\n",
            "Round: 2285 Weight: [2.51287077 1.24691629] Bias: -1.1560387849908358 loss: 0.34338271441766965\n",
            "Round: 2286 Weight: [2.51287867 1.24692036] Bias: -1.1560419175145997 loss: 0.34338271352600563\n",
            "Round: 2287 Weight: [2.51288655 1.24692442] Bias: -1.1560450422631234 loss: 0.34338271263876136\n",
            "Round: 2288 Weight: [2.51289442 1.24692847] Bias: -1.156048159255769 loss: 0.34338271175591467\n",
            "Round: 2289 Weight: [2.51290226 1.24693251] Bias: -1.1560512685118498 loss: 0.34338271087744376\n",
            "Round: 2290 Weight: [2.51291009 1.24693654] Bias: -1.1560543700506312 loss: 0.34338271000332704\n",
            "Round: 2291 Weight: [2.51291789 1.24694056] Bias: -1.15605746389133 loss: 0.3433827091335427\n",
            "Round: 2292 Weight: [2.51292568 1.24694457] Bias: -1.1560605500531147 loss: 0.3433827082680693\n",
            "Round: 2293 Weight: [2.51293345 1.24694857] Bias: -1.1560636285551062 loss: 0.34338270740688565\n",
            "Round: 2294 Weight: [2.5129412  1.24695255] Bias: -1.1560666994163773 loss: 0.34338270654997016\n",
            "Round: 2295 Weight: [2.51294892 1.24695653] Bias: -1.1560697626559528 loss: 0.3433827056973017\n",
            "Round: 2296 Weight: [2.51295663 1.2469605 ] Bias: -1.15607281829281 loss: 0.3433827048488594\n",
            "Round: 2297 Weight: [2.51296432 1.24696446] Bias: -1.1560758663458786 loss: 0.34338270400462223\n",
            "Round: 2298 Weight: [2.512972   1.24696841] Bias: -1.156078906834041 loss: 0.3433827031645691\n",
            "Round: 2299 Weight: [2.51297965 1.24697235] Bias: -1.156081939776132 loss: 0.34338270232867946\n",
            "Round: 2300 Weight: [2.51298728 1.24697628] Bias: -1.1560849651909395 loss: 0.34338270149693256\n",
            "Round: 2301 Weight: [2.5129949 1.2469802] Bias: -1.1560879830972042 loss: 0.34338270066930765\n",
            "Round: 2302 Weight: [2.51300249 1.24698411] Bias: -1.1560909935136199 loss: 0.3433826998457846\n",
            "Round: 2303 Weight: [2.51301007 1.24698801] Bias: -1.1560939964588335 loss: 0.3433826990263429\n",
            "Round: 2304 Weight: [2.51301763 1.2469919 ] Bias: -1.156096991951445 loss: 0.3433826982109624\n",
            "Round: 2305 Weight: [2.51302516 1.24699579] Bias: -1.1560999800100082 loss: 0.34338269739962274\n",
            "Round: 2306 Weight: [2.51303268 1.24699966] Bias: -1.1561029606530304 loss: 0.3433826965923041\n",
            "Round: 2307 Weight: [2.51304019 1.24700352] Bias: -1.156105933898972 loss: 0.3433826957889862\n",
            "Round: 2308 Weight: [2.51304767 1.24700737] Bias: -1.156108899766248 loss: 0.3433826949896496\n",
            "Round: 2309 Weight: [2.51305513 1.24701122] Bias: -1.1561118582732266 loss: 0.34338269419427414\n",
            "Round: 2310 Weight: [2.51306258 1.24701505] Bias: -1.15611480943823 loss: 0.34338269340284056\n",
            "Round: 2311 Weight: [2.51307001 1.24701887] Bias: -1.156117753279535 loss: 0.34338269261532905\n",
            "Round: 2312 Weight: [2.51307742 1.24702269] Bias: -1.1561206898153722 loss: 0.34338269183172004\n",
            "Round: 2313 Weight: [2.51308481 1.24702649] Bias: -1.1561236190639268 loss: 0.3433826910519945\n",
            "Round: 2314 Weight: [2.51309218 1.24703029] Bias: -1.1561265410433381 loss: 0.3433826902761328\n",
            "Round: 2315 Weight: [2.51309953 1.24703408] Bias: -1.1561294557717003 loss: 0.3433826895041161\n",
            "Round: 2316 Weight: [2.51310687 1.24703785] Bias: -1.1561323632670624 loss: 0.3433826887359249\n",
            "Round: 2317 Weight: [2.51311419 1.24704162] Bias: -1.1561352635474278 loss: 0.34338268797154065\n",
            "Round: 2318 Weight: [2.51312149 1.24704538] Bias: -1.156138156630755 loss: 0.34338268721094434\n",
            "Round: 2319 Weight: [2.51312877 1.24704913] Bias: -1.1561410425349574 loss: 0.34338268645411696\n",
            "Round: 2320 Weight: [2.51313603 1.24705287] Bias: -1.156143921277904 loss: 0.34338268570104\n",
            "Round: 2321 Weight: [2.51314328 1.2470566 ] Bias: -1.1561467928774187 loss: 0.34338268495169494\n",
            "Round: 2322 Weight: [2.5131505  1.24706032] Bias: -1.1561496573512808 loss: 0.343382684206063\n",
            "Round: 2323 Weight: [2.51315771 1.24706403] Bias: -1.156152514717225 loss: 0.3433826834641259\n",
            "Round: 2324 Weight: [2.51316491 1.24706773] Bias: -1.1561553649929417 loss: 0.3433826827258654\n",
            "Round: 2325 Weight: [2.51317208 1.24707143] Bias: -1.156158208196077 loss: 0.34338268199126293\n",
            "Round: 2326 Weight: [2.51317923 1.24707511] Bias: -1.156161044344233 loss: 0.34338268126030075\n",
            "Round: 2327 Weight: [2.51318637 1.24707879] Bias: -1.1561638734549673 loss: 0.34338268053296056\n",
            "Round: 2328 Weight: [2.51319349 1.24708245] Bias: -1.1561666955457939 loss: 0.3433826798092244\n",
            "Round: 2329 Weight: [2.5132006  1.24708611] Bias: -1.156169510634183 loss: 0.34338267908907444\n",
            "Round: 2330 Weight: [2.51320768 1.24708976] Bias: -1.1561723187375608 loss: 0.343382678372493\n",
            "Round: 2331 Weight: [2.51321475 1.2470934 ] Bias: -1.1561751198733101 loss: 0.343382677659462\n",
            "Round: 2332 Weight: [2.5132218  1.24709702] Bias: -1.15617791405877 loss: 0.3433826769499642\n",
            "Round: 2333 Weight: [2.51322883 1.24710065] Bias: -1.1561807013112364 loss: 0.34338267624398194\n",
            "Round: 2334 Weight: [2.51323585 1.24710426] Bias: -1.1561834816479617 loss: 0.3433826755414978\n",
            "Round: 2335 Weight: [2.51324284 1.24710786] Bias: -1.1561862550861552 loss: 0.3433826748424943\n",
            "Round: 2336 Weight: [2.51324982 1.24711145] Bias: -1.1561890216429835 loss: 0.34338267414695434\n",
            "Round: 2337 Weight: [2.51325679 1.24711504] Bias: -1.1561917813355695 loss: 0.3433826734548606\n",
            "Round: 2338 Weight: [2.51326373 1.24711862] Bias: -1.1561945341809938 loss: 0.3433826727661961\n",
            "Round: 2339 Weight: [2.51327066 1.24712218] Bias: -1.156197280196294 loss: 0.3433826720809438\n",
            "Round: 2340 Weight: [2.51327757 1.24712574] Bias: -1.1562000193984654 loss: 0.3433826713990867\n",
            "Round: 2341 Weight: [2.51328447 1.24712929] Bias: -1.1562027518044604 loss: 0.3433826707206081\n",
            "Round: 2342 Weight: [2.51329134 1.24713283] Bias: -1.156205477431189 loss: 0.34338267004549095\n",
            "Round: 2343 Weight: [2.5132982  1.24713636] Bias: -1.156208196295519 loss: 0.3433826693737189\n",
            "Round: 2344 Weight: [2.51330505 1.24713989] Bias: -1.1562109084142762 loss: 0.3433826687052752\n",
            "Round: 2345 Weight: [2.51331187 1.2471434 ] Bias: -1.1562136138042438 loss: 0.3433826680401433\n",
            "Round: 2346 Weight: [2.51331868 1.24714691] Bias: -1.1562163124821634 loss: 0.34338266737830697\n",
            "Round: 2347 Weight: [2.51332548 1.2471504 ] Bias: -1.1562190044647347 loss: 0.3433826667197496\n",
            "Round: 2348 Weight: [2.51333225 1.24715389] Bias: -1.1562216897686153 loss: 0.3433826660644551\n",
            "Round: 2349 Weight: [2.51333901 1.24715737] Bias: -1.1562243684104216 loss: 0.3433826654124072\n",
            "Round: 2350 Weight: [2.51334575 1.24716084] Bias: -1.156227040406728 loss: 0.34338266476358975\n",
            "Round: 2351 Weight: [2.51335248 1.24716431] Bias: -1.1562297057740678 loss: 0.34338266411798685\n",
            "Round: 2352 Weight: [2.51335918 1.24716776] Bias: -1.1562323645289325 loss: 0.3433826634755825\n",
            "Round: 2353 Weight: [2.51336588 1.2471712 ] Bias: -1.1562350166877726 loss: 0.34338266283636093\n",
            "Round: 2354 Weight: [2.51337255 1.24717464] Bias: -1.1562376622669976 loss: 0.3433826622003061\n",
            "Round: 2355 Weight: [2.51337921 1.24717807] Bias: -1.1562403012829756 loss: 0.3433826615674025\n",
            "Round: 2356 Weight: [2.51338585 1.24718149] Bias: -1.1562429337520341 loss: 0.3433826609376345\n",
            "Round: 2357 Weight: [2.51339248 1.2471849 ] Bias: -1.1562455596904595 loss: 0.3433826603109864\n",
            "Round: 2358 Weight: [2.51339909 1.2471883 ] Bias: -1.1562481791144976 loss: 0.3433826596874429\n",
            "Round: 2359 Weight: [2.51340568 1.2471917 ] Bias: -1.1562507920403537 loss: 0.34338265906698856\n",
            "Round: 2360 Weight: [2.51341226 1.24719508] Bias: -1.1562533984841923 loss: 0.3433826584496079\n",
            "Round: 2361 Weight: [2.51341882 1.24719846] Bias: -1.1562559984621374 loss: 0.34338265783528593\n",
            "Round: 2362 Weight: [2.51342536 1.24720183] Bias: -1.156258591990273 loss: 0.34338265722400724\n",
            "Round: 2363 Weight: [2.51343189 1.24720519] Bias: -1.1562611790846427 loss: 0.3433826566157568\n",
            "Round: 2364 Weight: [2.5134384  1.24720854] Bias: -1.15626375976125 loss: 0.3433826560105198\n",
            "Round: 2365 Weight: [2.5134449  1.24721189] Bias: -1.1562663340360582 loss: 0.34338265540828106\n",
            "Round: 2366 Weight: [2.51345137 1.24721522] Bias: -1.156268901924991 loss: 0.3433826548090257\n",
            "Round: 2367 Weight: [2.51345784 1.24721855] Bias: -1.1562714634439322 loss: 0.343382654212739\n",
            "Round: 2368 Weight: [2.51346429 1.24722187] Bias: -1.1562740186087257 loss: 0.34338265361940623\n",
            "Round: 2369 Weight: [2.51347072 1.24722518] Bias: -1.156276567435176 loss: 0.3433826530290127\n",
            "Round: 2370 Weight: [2.51347713 1.24722848] Bias: -1.156279109939048 loss: 0.3433826524415439\n",
            "Round: 2371 Weight: [2.51348353 1.24723178] Bias: -1.156281646136067 loss: 0.34338265185698535\n",
            "Round: 2372 Weight: [2.51348991 1.24723507] Bias: -1.1562841760419194 loss: 0.34338265127532264\n",
            "Round: 2373 Weight: [2.51349628 1.24723834] Bias: -1.1562866996722518 loss: 0.34338265069654117\n",
            "Round: 2374 Weight: [2.51350263 1.24724161] Bias: -1.1562892170426722 loss: 0.3433826501206268\n",
            "Round: 2375 Weight: [2.51350897 1.24724488] Bias: -1.1562917281687493 loss: 0.34338264954756537\n",
            "Round: 2376 Weight: [2.51351529 1.24724813] Bias: -1.1562942330660129 loss: 0.3433826489773426\n",
            "Round: 2377 Weight: [2.51352159 1.24725138] Bias: -1.1562967317499542 loss: 0.3433826484099446\n",
            "Round: 2378 Weight: [2.51352788 1.24725461] Bias: -1.1562992242360253 loss: 0.3433826478453572\n",
            "Round: 2379 Weight: [2.51353416 1.24725784] Bias: -1.15630171053964 loss: 0.34338264728356643\n",
            "Round: 2380 Weight: [2.51354042 1.24726107] Bias: -1.1563041906761735 loss: 0.34338264672455854\n",
            "Round: 2381 Weight: [2.51354666 1.24726428] Bias: -1.1563066646609623 loss: 0.34338264616831976\n",
            "Round: 2382 Weight: [2.51355288 1.24726749] Bias: -1.156309132509305 loss: 0.3433826456148362\n",
            "Round: 2383 Weight: [2.5135591  1.24727068] Bias: -1.1563115942364615 loss: 0.3433826450640943\n",
            "Round: 2384 Weight: [2.51356529 1.24727387] Bias: -1.1563140498576538 loss: 0.3433826445160805\n",
            "Round: 2385 Weight: [2.51357147 1.24727706] Bias: -1.1563164993880661 loss: 0.3433826439707813\n",
            "Round: 2386 Weight: [2.51357764 1.24728023] Bias: -1.1563189428428442 loss: 0.343382643428183\n",
            "Round: 2387 Weight: [2.51358379 1.2472834 ] Bias: -1.1563213802370962 loss: 0.34338264288827236\n",
            "Round: 2388 Weight: [2.51358992 1.24728656] Bias: -1.1563238115858925 loss: 0.34338264235103605\n",
            "Round: 2389 Weight: [2.51359604 1.24728971] Bias: -1.1563262369042657 loss: 0.3433826418164609\n",
            "Round: 2390 Weight: [2.51360215 1.24729285] Bias: -1.1563286562072113 loss: 0.3433826412845335\n",
            "Round: 2391 Weight: [2.51360824 1.24729598] Bias: -1.1563310695096864 loss: 0.34338264075524094\n",
            "Round: 2392 Weight: [2.51361431 1.24729911] Bias: -1.1563334768266118 loss: 0.34338264022857\n",
            "Round: 2393 Weight: [2.51362037 1.24730223] Bias: -1.1563358781728703 loss: 0.34338263970450783\n",
            "Round: 2394 Weight: [2.51362641 1.24730534] Bias: -1.1563382735633077 loss: 0.3433826391830413\n",
            "Round: 2395 Weight: [2.51363244 1.24730845] Bias: -1.1563406630127324 loss: 0.34338263866415775\n",
            "Round: 2396 Weight: [2.51363846 1.24731154] Bias: -1.1563430465359166 loss: 0.34338263814784414\n",
            "Round: 2397 Weight: [2.51364446 1.24731463] Bias: -1.1563454241475948 loss: 0.3433826376340879\n",
            "Round: 2398 Weight: [2.51365044 1.24731771] Bias: -1.156347795862465 loss: 0.3433826371228763\n",
            "Round: 2399 Weight: [2.51365641 1.24732079] Bias: -1.1563501616951886 loss: 0.3433826366141966\n",
            "Round: 2400 Weight: [2.51366236 1.24732385] Bias: -1.1563525216603898 loss: 0.34338263610803654\n",
            "Round: 2401 Weight: [2.5136683  1.24732691] Bias: -1.1563548757726572 loss: 0.3433826356043834\n",
            "Round: 2402 Weight: [2.51367423 1.24732996] Bias: -1.156357224046542 loss: 0.3433826351032247\n",
            "Round: 2403 Weight: [2.51368014 1.247333  ] Bias: -1.1563595664965598 loss: 0.34338263460454826\n",
            "Round: 2404 Weight: [2.51368604 1.24733604] Bias: -1.1563619031371895 loss: 0.34338263410834174\n",
            "Round: 2405 Weight: [2.51369192 1.24733907] Bias: -1.1563642339828737 loss: 0.34338263361459276\n",
            "Round: 2406 Weight: [2.51369778 1.24734209] Bias: -1.1563665590480194 loss: 0.34338263312328926\n",
            "Round: 2407 Weight: [2.51370364 1.2473451 ] Bias: -1.1563688783469972 loss: 0.34338263263441904\n",
            "Round: 2408 Weight: [2.51370947 1.24734811] Bias: -1.156371191894142 loss: 0.34338263214796994\n",
            "Round: 2409 Weight: [2.5137153  1.24735111] Bias: -1.156373499703753 loss: 0.3433826316639303\n",
            "Round: 2410 Weight: [2.51372111 1.2473541 ] Bias: -1.1563758017900934 loss: 0.34338263118228773\n",
            "Round: 2411 Weight: [2.5137269  1.24735708] Bias: -1.1563780981673908 loss: 0.3433826307030307\n",
            "Round: 2412 Weight: [2.51373268 1.24736006] Bias: -1.1563803888498376 loss: 0.34338263022614735\n",
            "Round: 2413 Weight: [2.51373845 1.24736302] Bias: -1.1563826738515903 loss: 0.3433826297516256\n",
            "Round: 2414 Weight: [2.5137442  1.24736598] Bias: -1.1563849531867705 loss: 0.343382629279454\n",
            "Round: 2415 Weight: [2.51374993 1.24736894] Bias: -1.1563872268694642 loss: 0.34338262880962095\n",
            "Round: 2416 Weight: [2.51375566 1.24737188] Bias: -1.1563894949137221 loss: 0.34338262834211464\n",
            "Round: 2417 Weight: [2.51376137 1.24737482] Bias: -1.1563917573335603 loss: 0.3433826278769237\n",
            "Round: 2418 Weight: [2.51376706 1.24737776] Bias: -1.1563940141429594 loss: 0.34338262741403663\n",
            "Round: 2419 Weight: [2.51377274 1.24738068] Bias: -1.1563962653558653 loss: 0.34338262695344196\n",
            "Round: 2420 Weight: [2.51377841 1.2473836 ] Bias: -1.1563985109861892 loss: 0.34338262649512835\n",
            "Round: 2421 Weight: [2.51378406 1.24738651] Bias: -1.1564007510478072 loss: 0.34338262603908437\n",
            "Round: 2422 Weight: [2.5137897  1.24738941] Bias: -1.156402985554561 loss: 0.34338262558529903\n",
            "Round: 2423 Weight: [2.51379532 1.24739231] Bias: -1.156405214520258 loss: 0.3433826251337609\n",
            "Round: 2424 Weight: [2.51380093 1.2473952 ] Bias: -1.1564074379586704 loss: 0.34338262468445896\n",
            "Round: 2425 Weight: [2.51380653 1.24739808] Bias: -1.1564096558835368 loss: 0.3433826242373821\n",
            "Round: 2426 Weight: [2.51381211 1.24740095] Bias: -1.156411868308561 loss: 0.3433826237925192\n",
            "Round: 2427 Weight: [2.51381768 1.24740382] Bias: -1.1564140752474126 loss: 0.3433826233498595\n",
            "Round: 2428 Weight: [2.51382324 1.24740668] Bias: -1.1564162767137274 loss: 0.34338262290939187\n",
            "Round: 2429 Weight: [2.51382878 1.24740953] Bias: -1.1564184727211066 loss: 0.34338262247110535\n",
            "Round: 2430 Weight: [2.5138343  1.24741238] Bias: -1.156420663283118 loss: 0.34338262203498954\n",
            "Round: 2431 Weight: [2.51383982 1.24741522] Bias: -1.1564228484132952 loss: 0.34338262160103333\n",
            "Round: 2432 Weight: [2.51384532 1.24741805] Bias: -1.1564250281251383 loss: 0.3433826211692261\n",
            "Round: 2433 Weight: [2.5138508  1.24742087] Bias: -1.1564272024321132 loss: 0.34338262073955717\n",
            "Round: 2434 Weight: [2.51385628 1.24742369] Bias: -1.1564293713476528 loss: 0.3433826203120161\n",
            "Round: 2435 Weight: [2.51386174 1.2474265 ] Bias: -1.156431534885156 loss: 0.34338261988659213\n",
            "Round: 2436 Weight: [2.51386718 1.2474293 ] Bias: -1.1564336930579882 loss: 0.3433826194632749\n",
            "Round: 2437 Weight: [2.51387261 1.2474321 ] Bias: -1.1564358458794817 loss: 0.3433826190420539\n",
            "Round: 2438 Weight: [2.51387803 1.24743489] Bias: -1.1564379933629356 loss: 0.34338261862291874\n",
            "Round: 2439 Weight: [2.51388344 1.24743767] Bias: -1.1564401355216156 loss: 0.3433826182058591\n",
            "Round: 2440 Weight: [2.51388883 1.24744045] Bias: -1.1564422723687544 loss: 0.3433826177908648\n",
            "Round: 2441 Weight: [2.51389421 1.24744322] Bias: -1.1564444039175514 loss: 0.3433826173779254\n",
            "Round: 2442 Weight: [2.51389957 1.24744598] Bias: -1.1564465301811735 loss: 0.34338261696703093\n",
            "Round: 2443 Weight: [2.51390493 1.24744874] Bias: -1.1564486511727543 loss: 0.343382616558171\n",
            "Round: 2444 Weight: [2.51391026 1.24745148] Bias: -1.156450766905395 loss: 0.3433826161513357\n",
            "Round: 2445 Weight: [2.51391559 1.24745423] Bias: -1.1564528773921636 loss: 0.3433826157465149\n",
            "Round: 2446 Weight: [2.5139209  1.24745696] Bias: -1.156454982646096 loss: 0.3433826153436987\n",
            "Round: 2447 Weight: [2.5139262  1.24745969] Bias: -1.1564570826801952 loss: 0.34338261494287725\n",
            "Round: 2448 Weight: [2.51393149 1.24746241] Bias: -1.156459177507432 loss: 0.34338261454404045\n",
            "Round: 2449 Weight: [2.51393676 1.24746513] Bias: -1.1564612671407448 loss: 0.3433826141471785\n",
            "Round: 2450 Weight: [2.51394202 1.24746783] Bias: -1.1564633515930396 loss: 0.34338261375228174\n",
            "Round: 2451 Weight: [2.51394727 1.24747054] Bias: -1.1564654308771902 loss: 0.3433826133593404\n",
            "Round: 2452 Weight: [2.5139525  1.24747323] Bias: -1.1564675050060382 loss: 0.3433826129683447\n",
            "Round: 2453 Weight: [2.51395772 1.24747592] Bias: -1.1564695739923934 loss: 0.3433826125792851\n",
            "Round: 2454 Weight: [2.51396293 1.2474786 ] Bias: -1.1564716378490334 loss: 0.3433826121921518\n",
            "Round: 2455 Weight: [2.51396812 1.24748127] Bias: -1.1564736965887041 loss: 0.3433826118069355\n",
            "Round: 2456 Weight: [2.51397331 1.24748394] Bias: -1.1564757502241194 loss: 0.34338261142362664\n",
            "Round: 2457 Weight: [2.51397847 1.2474866 ] Bias: -1.1564777987679615 loss: 0.3433826110422157\n",
            "Round: 2458 Weight: [2.51398363 1.24748926] Bias: -1.1564798422328812 loss: 0.3433826106626932\n",
            "Round: 2459 Weight: [2.51398877 1.24749191] Bias: -1.1564818806314976 loss: 0.34338261028505\n",
            "Round: 2460 Weight: [2.5139939  1.24749455] Bias: -1.156483913976398 loss: 0.34338260990927666\n",
            "Round: 2461 Weight: [2.51399902 1.24749718] Bias: -1.1564859422801388 loss: 0.34338260953536387\n",
            "Round: 2462 Weight: [2.51400413 1.24749981] Bias: -1.1564879655552447 loss: 0.3433826091633025\n",
            "Round: 2463 Weight: [2.51400922 1.24750243] Bias: -1.1564899838142093 loss: 0.34338260879308324\n",
            "Round: 2464 Weight: [2.5140143  1.24750505] Bias: -1.156491997069495 loss: 0.3433826084246971\n",
            "Round: 2465 Weight: [2.51401937 1.24750766] Bias: -1.156494005333533 loss: 0.343382608058135\n",
            "Round: 2466 Weight: [2.51402442 1.24751026] Bias: -1.156496008618724 loss: 0.34338260769338774\n",
            "Round: 2467 Weight: [2.51402947 1.24751286] Bias: -1.1564980069374369 loss: 0.3433826073304465\n",
            "Round: 2468 Weight: [2.5140345  1.24751545] Bias: -1.1565000003020105 loss: 0.3433826069693022\n",
            "Round: 2469 Weight: [2.51403951 1.24751803] Bias: -1.1565019887247525 loss: 0.34338260660994613\n",
            "Round: 2470 Weight: [2.51404452 1.24752061] Bias: -1.15650397221794 loss: 0.3433826062523692\n",
            "Round: 2471 Weight: [2.51404951 1.24752318] Bias: -1.1565059507938191 loss: 0.3433826058965627\n",
            "Round: 2472 Weight: [2.51405449 1.24752574] Bias: -1.156507924464606 loss: 0.3433826055425178\n",
            "Round: 2473 Weight: [2.51405946 1.2475283 ] Bias: -1.1565098932424858 loss: 0.3433826051902259\n",
            "Round: 2474 Weight: [2.51406441 1.24753085] Bias: -1.1565118571396136 loss: 0.3433826048396781\n",
            "Round: 2475 Weight: [2.51406936 1.2475334 ] Bias: -1.156513816168114 loss: 0.343382604490866\n",
            "Round: 2476 Weight: [2.51407429 1.24753593] Bias: -1.1565157703400817 loss: 0.3433826041437808\n",
            "Round: 2477 Weight: [2.51407921 1.24753847] Bias: -1.1565177196675807 loss: 0.34338260379841407\n",
            "Round: 2478 Weight: [2.51408411 1.24754099] Bias: -1.1565196641626452 loss: 0.34338260345475724\n",
            "Round: 2479 Weight: [2.51408901 1.24754351] Bias: -1.1565216038372792 loss: 0.3433826031128018\n",
            "Round: 2480 Weight: [2.51409389 1.24754603] Bias: -1.1565235387034571 loss: 0.34338260277253946\n",
            "Round: 2481 Weight: [2.51409876 1.24754853] Bias: -1.1565254687731232 loss: 0.34338260243396174\n",
            "Round: 2482 Weight: [2.51410362 1.24755103] Bias: -1.1565273940581922 loss: 0.3433826020970601\n",
            "Round: 2483 Weight: [2.51410847 1.24755353] Bias: -1.1565293145705486 loss: 0.3433826017618266\n",
            "Round: 2484 Weight: [2.5141133  1.24755602] Bias: -1.1565312303220479 loss: 0.3433826014282528\n",
            "Round: 2485 Weight: [2.51411812 1.2475585 ] Bias: -1.1565331413245155 loss: 0.3433826010963303\n",
            "Round: 2486 Weight: [2.51412293 1.24756098] Bias: -1.1565350475897476 loss: 0.34338260076605115\n",
            "Round: 2487 Weight: [2.51412773 1.24756345] Bias: -1.156536949129511 loss: 0.34338260043740715\n",
            "Round: 2488 Weight: [2.51413252 1.24756591] Bias: -1.156538845955543 loss: 0.34338260011039023\n",
            "Round: 2489 Weight: [2.51413729 1.24756837] Bias: -1.1565407380795518 loss: 0.34338259978499225\n",
            "Round: 2490 Weight: [2.51414205 1.24757082] Bias: -1.1565426255132163 loss: 0.34338259946120525\n",
            "Round: 2491 Weight: [2.51414681 1.24757327] Bias: -1.1565445082681862 loss: 0.34338259913902114\n",
            "Round: 2492 Weight: [2.51415154 1.24757571] Bias: -1.1565463863560823 loss: 0.3433825988184321\n",
            "Round: 2493 Weight: [2.51415627 1.24757814] Bias: -1.1565482597884962 loss: 0.34338259849943026\n",
            "Round: 2494 Weight: [2.51416099 1.24758057] Bias: -1.156550128576991 loss: 0.3433825981820076\n",
            "Round: 2495 Weight: [2.51416569 1.24758299] Bias: -1.1565519927331005 loss: 0.34338259786615644\n",
            "Round: 2496 Weight: [2.51417038 1.24758541] Bias: -1.15655385226833 loss: 0.34338259755186884\n",
            "Round: 2497 Weight: [2.51417506 1.24758782] Bias: -1.1565557071941563 loss: 0.3433825972391371\n",
            "Round: 2498 Weight: [2.51417973 1.24759022] Bias: -1.1565575575220273 loss: 0.3433825969279537\n",
            "Round: 2499 Weight: [2.51418439 1.24759262] Bias: -1.1565594032633624 loss: 0.34338259661831083\n",
            "Round: 2500 Weight: [2.51418904 1.24759501] Bias: -1.1565612444295525 loss: 0.34338259631020074\n",
            "Round: 2501 Weight: [2.51419367 1.2475974 ] Bias: -1.1565630810319603 loss: 0.343382596003616\n",
            "Round: 2502 Weight: [2.51419829 1.24759978] Bias: -1.1565649130819198 loss: 0.343382595698549\n",
            "Round: 2503 Weight: [2.51420291 1.24760215] Bias: -1.1565667405907372 loss: 0.34338259539499205\n",
            "Round: 2504 Weight: [2.51420751 1.24760452] Bias: -1.15656856356969 loss: 0.34338259509293806\n",
            "Round: 2505 Weight: [2.51421209 1.24760688] Bias: -1.1565703820300282 loss: 0.3433825947923792\n",
            "Round: 2506 Weight: [2.51421667 1.24760924] Bias: -1.1565721959829733 loss: 0.3433825944933083\n",
            "Round: 2507 Weight: [2.51422124 1.24761159] Bias: -1.1565740054397189 loss: 0.34338259419571787\n",
            "Round: 2508 Weight: [2.51422579 1.24761394] Bias: -1.1565758104114308 loss: 0.3433825938996007\n",
            "Round: 2509 Weight: [2.51423034 1.24761628] Bias: -1.156577610909247 loss: 0.3433825936049492\n",
            "Round: 2510 Weight: [2.51423487 1.24761861] Bias: -1.1565794069442774 loss: 0.34338259331175647\n",
            "Round: 2511 Weight: [2.51423939 1.24762094] Bias: -1.1565811985276047 loss: 0.34338259302001506\n",
            "Round: 2512 Weight: [2.5142439  1.24762326] Bias: -1.1565829856702836 loss: 0.34338259272971794\n",
            "Round: 2513 Weight: [2.5142484  1.24762557] Bias: -1.1565847683833415 loss: 0.34338259244085784\n",
            "Round: 2514 Weight: [2.51425288 1.24762788] Bias: -1.156586546677778 loss: 0.34338259215342753\n",
            "Round: 2515 Weight: [2.51425736 1.24763019] Bias: -1.1565883205645657 loss: 0.34338259186742015\n",
            "Round: 2516 Weight: [2.51426183 1.24763249] Bias: -1.1565900900546497 loss: 0.3433825915828284\n",
            "Round: 2517 Weight: [2.51426628 1.24763478] Bias: -1.1565918551589476 loss: 0.3433825912996457\n",
            "Round: 2518 Weight: [2.51427072 1.24763707] Bias: -1.1565936158883499 loss: 0.34338259101786456\n",
            "Round: 2519 Weight: [2.51427516 1.24763935] Bias: -1.1565953722537199 loss: 0.3433825907374783\n",
            "Round: 2520 Weight: [2.51427958 1.24764163] Bias: -1.1565971242658941 loss: 0.34338259045848\n",
            "Round: 2521 Weight: [2.51428399 1.2476439 ] Bias: -1.156598871935682 loss: 0.3433825901808628\n",
            "Round: 2522 Weight: [2.51428839 1.24764616] Bias: -1.1566006152738655 loss: 0.34338258990461984\n",
            "Round: 2523 Weight: [2.51429277 1.24764842] Bias: -1.1566023542912005 loss: 0.34338258962974416\n",
            "Round: 2524 Weight: [2.51429715 1.24765067] Bias: -1.1566040889984155 loss: 0.3433825893562292\n",
            "Round: 2525 Weight: [2.51430152 1.24765292] Bias: -1.1566058194062125 loss: 0.34338258908406816\n",
            "Round: 2526 Weight: [2.51430587 1.24765517] Bias: -1.1566075455252671 loss: 0.34338258881325423\n",
            "Round: 2527 Weight: [2.51431022 1.2476574 ] Bias: -1.1566092673662276 loss: 0.3433825885437809\n",
            "Round: 2528 Weight: [2.51431455 1.24765963] Bias: -1.1566109849397164 loss: 0.3433825882756414\n",
            "Round: 2529 Weight: [2.51431888 1.24766186] Bias: -1.156612698256329 loss: 0.3433825880088291\n",
            "Round: 2530 Weight: [2.51432319 1.24766408] Bias: -1.156614407326635 loss: 0.3433825877433375\n",
            "Round: 2531 Weight: [2.51432749 1.2476663 ] Bias: -1.1566161121611769 loss: 0.34338258747916\n",
            "Round: 2532 Weight: [2.51433178 1.2476685 ] Bias: -1.1566178127704718 loss: 0.34338258721629034\n",
            "Round: 2533 Weight: [2.51433606 1.24767071] Bias: -1.15661950916501 loss: 0.3433825869547217\n",
            "Round: 2534 Weight: [2.51434033 1.24767291] Bias: -1.156621201355256 loss: 0.34338258669444777\n",
            "Round: 2535 Weight: [2.51434459 1.2476751 ] Bias: -1.1566228893516477 loss: 0.3433825864354621\n",
            "Round: 2536 Weight: [2.51434884 1.24767729] Bias: -1.1566245731645977 loss: 0.34338258617775835\n",
            "Round: 2537 Weight: [2.51435308 1.24767947] Bias: -1.1566262528044922 loss: 0.34338258592133025\n",
            "Round: 2538 Weight: [2.51435731 1.24768165] Bias: -1.1566279282816916 loss: 0.3433825856661713\n",
            "Round: 2539 Weight: [2.51436152 1.24768382] Bias: -1.1566295996065306 loss: 0.34338258541227534\n",
            "Round: 2540 Weight: [2.51436573 1.24768598] Bias: -1.1566312667893182 loss: 0.3433825851596362\n",
            "Round: 2541 Weight: [2.51436993 1.24768814] Bias: -1.1566329298403373 loss: 0.3433825849082474\n",
            "Round: 2542 Weight: [2.51437411 1.2476903 ] Bias: -1.1566345887698457 loss: 0.3433825846581029\n",
            "Round: 2543 Weight: [2.51437829 1.24769245] Bias: -1.1566362435880755 loss: 0.34338258440919656\n",
            "Round: 2544 Weight: [2.51438246 1.24769459] Bias: -1.1566378943052331 loss: 0.34338258416152223\n",
            "Round: 2545 Weight: [2.51438661 1.24769673] Bias: -1.1566395409314998 loss: 0.34338258391507376\n",
            "Round: 2546 Weight: [2.51439076 1.24769887] Bias: -1.1566411834770312 loss: 0.3433825836698451\n",
            "Round: 2547 Weight: [2.51439489 1.247701  ] Bias: -1.1566428219519576 loss: 0.34338258342583017\n",
            "Round: 2548 Weight: [2.51439902 1.24770312] Bias: -1.1566444563663845 loss: 0.34338258318302306\n",
            "Round: 2549 Weight: [2.51440313 1.24770524] Bias: -1.1566460867303918 loss: 0.34338258294141766\n",
            "Round: 2550 Weight: [2.51440723 1.24770735] Bias: -1.1566477130540345 loss: 0.3433825827010081\n",
            "Round: 2551 Weight: [2.51441133 1.24770946] Bias: -1.1566493353473424 loss: 0.3433825824617885\n",
            "Round: 2552 Weight: [2.51441541 1.24771156] Bias: -1.1566509536203204 loss: 0.3433825822237528\n",
            "Round: 2553 Weight: [2.51441948 1.24771366] Bias: -1.1566525678829487 loss: 0.3433825819868953\n",
            "Round: 2554 Weight: [2.51442355 1.24771575] Bias: -1.1566541781451822 loss: 0.3433825817512101\n",
            "Round: 2555 Weight: [2.5144276  1.24771784] Bias: -1.1566557844169514 loss: 0.3433825815166914\n",
            "Round: 2556 Weight: [2.51443164 1.24771992] Bias: -1.1566573867081618 loss: 0.3433825812833335\n",
            "Round: 2557 Weight: [2.51443568 1.247722  ] Bias: -1.1566589850286941 loss: 0.34338258105113034\n",
            "Round: 2558 Weight: [2.5144397  1.24772407] Bias: -1.156660579388405 loss: 0.34338258082007667\n",
            "Round: 2559 Weight: [2.51444371 1.24772613] Bias: -1.1566621697971262 loss: 0.34338258059016646\n",
            "Round: 2560 Weight: [2.51444772 1.24772819] Bias: -1.1566637562646649 loss: 0.34338258036139413\n",
            "Round: 2561 Weight: [2.51445171 1.24773025] Bias: -1.156665338800804 loss: 0.3433825801337541\n",
            "Round: 2562 Weight: [2.51445569 1.2477323 ] Bias: -1.156666917415302 loss: 0.3433825799072407\n",
            "Round: 2563 Weight: [2.51445967 1.24773435] Bias: -1.1566684921178931 loss: 0.34338257968184843\n",
            "Round: 2564 Weight: [2.51446363 1.24773639] Bias: -1.1566700629182873 loss: 0.34338257945757156\n",
            "Round: 2565 Weight: [2.51446759 1.24773842] Bias: -1.1566716298261703 loss: 0.34338257923440474\n",
            "Round: 2566 Weight: [2.51447153 1.24774045] Bias: -1.1566731928512037 loss: 0.3433825790123424\n",
            "Round: 2567 Weight: [2.51447546 1.24774248] Bias: -1.1566747520030254 loss: 0.34338257879137907\n",
            "Round: 2568 Weight: [2.51447939 1.2477445 ] Bias: -1.1566763072912487 loss: 0.3433825785715094\n",
            "Round: 2569 Weight: [2.5144833  1.24774652] Bias: -1.1566778587254631 loss: 0.3433825783527278\n",
            "Round: 2570 Weight: [2.51448721 1.24774853] Bias: -1.1566794063152348 loss: 0.34338257813502904\n",
            "Round: 2571 Weight: [2.51449111 1.24775053] Bias: -1.1566809500701054 loss: 0.3433825779184077\n",
            "Round: 2572 Weight: [2.51449499 1.24775253] Bias: -1.1566824899995933 loss: 0.3433825777028583\n",
            "Round: 2573 Weight: [2.51449887 1.24775453] Bias: -1.156684026113193 loss: 0.34338257748837575\n",
            "Round: 2574 Weight: [2.51450273 1.24775652] Bias: -1.1566855584203752 loss: 0.3433825772749548\n",
            "Round: 2575 Weight: [2.51450659 1.24775851] Bias: -1.1566870869305874 loss: 0.34338257706258996\n",
            "Round: 2576 Weight: [2.51451044 1.24776049] Bias: -1.1566886116532533 loss: 0.34338257685127604\n",
            "Round: 2577 Weight: [2.51451428 1.24776246] Bias: -1.156690132597773 loss: 0.3433825766410081\n",
            "Round: 2578 Weight: [2.51451811 1.24776443] Bias: -1.1566916497735236 loss: 0.3433825764317806\n",
            "Round: 2579 Weight: [2.51452192 1.2477664 ] Bias: -1.1566931631898585 loss: 0.3433825762235887\n",
            "Round: 2580 Weight: [2.51452573 1.24776836] Bias: -1.156694672856108 loss: 0.343382576016427\n",
            "Round: 2581 Weight: [2.51452953 1.24777032] Bias: -1.156696178781579 loss: 0.3433825758102906\n",
            "Round: 2582 Weight: [2.51453333 1.24777227] Bias: -1.1566976809755556 loss: 0.34338257560517427\n",
            "Round: 2583 Weight: [2.51453711 1.24777422] Bias: -1.1566991794472983 loss: 0.34338257540107314\n",
            "Round: 2584 Weight: [2.51454088 1.24777616] Bias: -1.1567006742060448 loss: 0.343382575197982\n",
            "Round: 2585 Weight: [2.51454464 1.2477781 ] Bias: -1.15670216526101 loss: 0.343382574995896\n",
            "Round: 2586 Weight: [2.51454839 1.24778003] Bias: -1.1567036526213856 loss: 0.3433825747948101\n",
            "Round: 2587 Weight: [2.51455214 1.24778196] Bias: -1.1567051362963403 loss: 0.3433825745947192\n",
            "Round: 2588 Weight: [2.51455587 1.24778388] Bias: -1.1567066162950201 loss: 0.34338257439561864\n",
            "Round: 2589 Weight: [2.5145596 1.2477858] Bias: -1.1567080926265485 loss: 0.34338257419750323\n",
            "Round: 2590 Weight: [2.51456331 1.24778771] Bias: -1.1567095653000259 loss: 0.34338257400036837\n",
            "Round: 2591 Weight: [2.51456702 1.24778962] Bias: -1.1567110343245302 loss: 0.3433825738042091\n",
            "Round: 2592 Weight: [2.51457072 1.24779152] Bias: -1.1567124997091167 loss: 0.3433825736090205\n",
            "Round: 2593 Weight: [2.51457441 1.24779342] Bias: -1.1567139614628181 loss: 0.34338257341479794\n",
            "Round: 2594 Weight: [2.51457809 1.24779532] Bias: -1.156715419594645 loss: 0.3433825732215364\n",
            "Round: 2595 Weight: [2.51458176 1.24779721] Bias: -1.156716874113585 loss: 0.3433825730292313\n",
            "Round: 2596 Weight: [2.51458542 1.24779909] Bias: -1.1567183250286035 loss: 0.3433825728378779\n",
            "Round: 2597 Weight: [2.51458907 1.24780097] Bias: -1.1567197723486438 loss: 0.3433825726474714\n",
            "Round: 2598 Weight: [2.51459272 1.24780285] Bias: -1.1567212160826268 loss: 0.3433825724580071\n",
            "Round: 2599 Weight: [2.51459635 1.24780472] Bias: -1.1567226562394513 loss: 0.34338257226948043\n",
            "Round: 2600 Weight: [2.51459998 1.24780658] Bias: -1.1567240928279936 loss: 0.3433825720818867\n",
            "Round: 2601 Weight: [2.51460359 1.24780845] Bias: -1.1567255258571083 loss: 0.34338257189522126\n",
            "Round: 2602 Weight: [2.5146072 1.2478103] Bias: -1.1567269553356279 loss: 0.34338257170947967\n",
            "Round: 2603 Weight: [2.5146108  1.24781216] Bias: -1.1567283812723628 loss: 0.3433825715246571\n",
            "Round: 2604 Weight: [2.51461439 1.247814  ] Bias: -1.1567298036761016 loss: 0.34338257134074907\n",
            "Round: 2605 Weight: [2.51461797 1.24781585] Bias: -1.1567312225556108 loss: 0.3433825711577512\n",
            "Round: 2606 Weight: [2.51462154 1.24781769] Bias: -1.1567326379196352 loss: 0.3433825709756589\n",
            "Round: 2607 Weight: [2.5146251  1.24781952] Bias: -1.1567340497768979 loss: 0.34338257079446766\n",
            "Round: 2608 Weight: [2.51462866 1.24782135] Bias: -1.1567354581361002 loss: 0.3433825706141731\n",
            "Round: 2609 Weight: [2.5146322  1.24782318] Bias: -1.156736863005922 loss: 0.34338257043477066\n",
            "Round: 2610 Weight: [2.51463574 1.247825  ] Bias: -1.1567382643950213 loss: 0.343382570256256\n",
            "Round: 2611 Weight: [2.51463926 1.24782681] Bias: -1.1567396623120345 loss: 0.34338257007862466\n",
            "Round: 2612 Weight: [2.51464278 1.24782863] Bias: -1.1567410567655767 loss: 0.34338256990187227\n",
            "Round: 2613 Weight: [2.51464629 1.24783043] Bias: -1.1567424477642416 loss: 0.34338256972599457\n",
            "Round: 2614 Weight: [2.5146498  1.24783223] Bias: -1.1567438353166015 loss: 0.3433825695509873\n",
            "Round: 2615 Weight: [2.51465329 1.24783403] Bias: -1.1567452194312073 loss: 0.34338256937684575\n",
            "Round: 2616 Weight: [2.51465677 1.24783583] Bias: -1.1567466001165885 loss: 0.3433825692035662\n",
            "Round: 2617 Weight: [2.51466025 1.24783762] Bias: -1.1567479773812535 loss: 0.343382569031144\n",
            "Round: 2618 Weight: [2.51466371 1.2478394 ] Bias: -1.1567493512336895 loss: 0.3433825688595748\n",
            "Round: 2619 Weight: [2.51466717 1.24784118] Bias: -1.1567507216823627 loss: 0.3433825686888548\n",
            "Round: 2620 Weight: [2.51467062 1.24784296] Bias: -1.1567520887357183 loss: 0.34338256851897947\n",
            "Round: 2621 Weight: [2.51467406 1.24784473] Bias: -1.15675345240218 loss: 0.3433825683499448\n",
            "Round: 2622 Weight: [2.5146775 1.2478465] Bias: -1.1567548126901512 loss: 0.34338256818174656\n",
            "Round: 2623 Weight: [2.51468092 1.24784826] Bias: -1.156756169608014 loss: 0.34338256801438044\n",
            "Round: 2624 Weight: [2.51468434 1.24785002] Bias: -1.1567575231641296 loss: 0.3433825678478426\n",
            "Round: 2625 Weight: [2.51468774 1.24785177] Bias: -1.1567588733668384 loss: 0.3433825676821288\n",
            "Round: 2626 Weight: [2.51469114 1.24785352] Bias: -1.1567602202244602 loss: 0.343382567517235\n",
            "Round: 2627 Weight: [2.51469453 1.24785527] Bias: -1.1567615637452944 loss: 0.3433825673531571\n",
            "Round: 2628 Weight: [2.51469792 1.24785701] Bias: -1.156762903937619 loss: 0.34338256718989113\n",
            "Round: 2629 Weight: [2.51470129 1.24785875] Bias: -1.156764240809692 loss: 0.34338256702743286\n",
            "Round: 2630 Weight: [2.51470465 1.24786048] Bias: -1.1567655743697507 loss: 0.3433825668657786\n",
            "Round: 2631 Weight: [2.51470801 1.24786221] Bias: -1.1567669046260116 loss: 0.34338256670492406\n",
            "Round: 2632 Weight: [2.51471136 1.24786393] Bias: -1.1567682315866714 loss: 0.34338256654486565\n",
            "Round: 2633 Weight: [2.5147147  1.24786565] Bias: -1.1567695552599058 loss: 0.3433825663855991\n",
            "Round: 2634 Weight: [2.51471803 1.24786737] Bias: -1.1567708756538704 loss: 0.34338256622712066\n",
            "Round: 2635 Weight: [2.51472136 1.24786908] Bias: -1.1567721927767007 loss: 0.3433825660694263\n",
            "Round: 2636 Weight: [2.51472467 1.24787079] Bias: -1.1567735066365117 loss: 0.3433825659125123\n",
            "Round: 2637 Weight: [2.51472798 1.24787249] Bias: -1.1567748172413983 loss: 0.3433825657563747\n",
            "Round: 2638 Weight: [2.51473128 1.24787419] Bias: -1.156776124599435 loss: 0.34338256560100966\n",
            "Round: 2639 Weight: [2.51473457 1.24787588] Bias: -1.1567774287186767 loss: 0.3433825654464133\n",
            "Round: 2640 Weight: [2.51473785 1.24787757] Bias: -1.156778729607158 loss: 0.343382565292582\n",
            "Round: 2641 Weight: [2.51474113 1.24787926] Bias: -1.1567800272728936 loss: 0.3433825651395117\n",
            "Round: 2642 Weight: [2.51474439 1.24788094] Bias: -1.1567813217238783 loss: 0.3433825649871989\n",
            "Round: 2643 Weight: [2.51474765 1.24788262] Bias: -1.1567826129680867 loss: 0.3433825648356396\n",
            "Round: 2644 Weight: [2.5147509  1.24788429] Bias: -1.1567839010134737 loss: 0.34338256468483025\n",
            "Round: 2645 Weight: [2.51475414 1.24788596] Bias: -1.1567851858679747 loss: 0.3433825645347671\n",
            "Round: 2646 Weight: [2.51475738 1.24788762] Bias: -1.1567864675395052 loss: 0.34338256438544645\n",
            "Round: 2647 Weight: [2.51476061 1.24788929] Bias: -1.1567877460359608 loss: 0.34338256423686464\n",
            "Round: 2648 Weight: [2.51476382 1.24789094] Bias: -1.1567890213652177 loss: 0.3433825640890179\n",
            "Round: 2649 Weight: [2.51476703 1.2478926 ] Bias: -1.1567902935351324 loss: 0.34338256394190275\n",
            "Round: 2650 Weight: [2.51477024 1.24789424] Bias: -1.156791562553542 loss: 0.3433825637955155\n",
            "Round: 2651 Weight: [2.51477343 1.24789589] Bias: -1.156792828428264 loss: 0.34338256364985253\n",
            "Round: 2652 Weight: [2.51477662 1.24789753] Bias: -1.1567940911670964 loss: 0.3433825635049102\n",
            "Round: 2653 Weight: [2.5147798  1.24789917] Bias: -1.156795350777818 loss: 0.34338256336068507\n",
            "Round: 2654 Weight: [2.51478297 1.2479008 ] Bias: -1.156796607268188 loss: 0.34338256321717353\n",
            "Round: 2655 Weight: [2.51478613 1.24790243] Bias: -1.1567978606459461 loss: 0.34338256307437204\n",
            "Round: 2656 Weight: [2.51478928 1.24790405] Bias: -1.1567991109188138 loss: 0.34338256293227704\n",
            "Round: 2657 Weight: [2.51479243 1.24790567] Bias: -1.156800358094492 loss: 0.3433825627908852\n",
            "Round: 2658 Weight: [2.51479557 1.24790729] Bias: -1.1568016021806637 loss: 0.34338256265019285\n",
            "Round: 2659 Weight: [2.5147987 1.2479089] Bias: -1.156802843184992 loss: 0.34338256251019655\n",
            "Round: 2660 Weight: [2.51480183 1.24791051] Bias: -1.1568040811151208 loss: 0.34338256237089304\n",
            "Round: 2661 Weight: [2.51480494 1.24791211] Bias: -1.1568053159786758 loss: 0.3433825622322787\n",
            "Round: 2662 Weight: [2.51480805 1.24791371] Bias: -1.156806547783263 loss: 0.34338256209435014\n",
            "Round: 2663 Weight: [2.51481115 1.24791531] Bias: -1.15680777653647 loss: 0.343382561957104\n",
            "Round: 2664 Weight: [2.51481425 1.2479169 ] Bias: -1.1568090022458652 loss: 0.3433825618205369\n",
            "Round: 2665 Weight: [2.51481733 1.24791849] Bias: -1.1568102249189984 loss: 0.34338256168464537\n",
            "Round: 2666 Weight: [2.51482041 1.24792008] Bias: -1.1568114445634003 loss: 0.34338256154942626\n",
            "Round: 2667 Weight: [2.51482348 1.24792166] Bias: -1.1568126611865832 loss: 0.3433825614148762\n",
            "Round: 2668 Weight: [2.51482654 1.24792323] Bias: -1.1568138747960406 loss: 0.3433825612809918\n",
            "Round: 2669 Weight: [2.5148296  1.24792481] Bias: -1.1568150853992474 loss: 0.3433825611477698\n",
            "Round: 2670 Weight: [2.51483264 1.24792638] Bias: -1.1568162930036598 loss: 0.34338256101520687\n",
            "Round: 2671 Weight: [2.51483568 1.24792794] Bias: -1.1568174976167156 loss: 0.3433825608832998\n",
            "Round: 2672 Weight: [2.51483872 1.2479295 ] Bias: -1.156818699245834 loss: 0.34338256075204543\n",
            "Round: 2673 Weight: [2.51484174 1.24793106] Bias: -1.1568198978984159 loss: 0.3433825606214404\n",
            "Round: 2674 Weight: [2.51484476 1.24793261] Bias: -1.1568210935818435 loss: 0.3433825604914815\n",
            "Round: 2675 Weight: [2.51484777 1.24793416] Bias: -1.156822286303481 loss: 0.3433825603621656\n",
            "Round: 2676 Weight: [2.51485077 1.24793571] Bias: -1.1568234760706742 loss: 0.34338256023348945\n",
            "Round: 2677 Weight: [2.51485377 1.24793725] Bias: -1.1568246628907504 loss: 0.34338256010544993\n",
            "Round: 2678 Weight: [2.51485675 1.24793879] Bias: -1.1568258467710189 loss: 0.34338255997804384\n",
            "Round: 2679 Weight: [2.51485973 1.24794032] Bias: -1.1568270277187709 loss: 0.3433825598512681\n",
            "Round: 2680 Weight: [2.51486271 1.24794185] Bias: -1.156828205741279 loss: 0.3433825597251195\n",
            "Round: 2681 Weight: [2.51486567 1.24794338] Bias: -1.1568293808457986 loss: 0.3433825595995952\n",
            "Round: 2682 Weight: [2.51486863 1.2479449 ] Bias: -1.1568305530395662 loss: 0.3433825594746917\n",
            "Round: 2683 Weight: [2.51487158 1.24794642] Bias: -1.1568317223298006 loss: 0.34338255935040624\n",
            "Round: 2684 Weight: [2.51487453 1.24794794] Bias: -1.1568328887237027 loss: 0.3433825592267356\n",
            "Round: 2685 Weight: [2.51487746 1.24794945] Bias: -1.1568340522284557 loss: 0.3433825591036769\n",
            "Round: 2686 Weight: [2.51488039 1.24795096] Bias: -1.1568352128512247 loss: 0.3433825589812269\n",
            "Round: 2687 Weight: [2.51488331 1.24795246] Bias: -1.156836370599157 loss: 0.34338255885938274\n",
            "Round: 2688 Weight: [2.51488623 1.24795396] Bias: -1.1568375254793817 loss: 0.3433825587381414\n",
            "Round: 2689 Weight: [2.51488913 1.24795546] Bias: -1.1568386774990111 loss: 0.3433825586174997\n",
            "Round: 2690 Weight: [2.51489203 1.24795695] Bias: -1.1568398266651394 loss: 0.34338255849745497\n",
            "Round: 2691 Weight: [2.51489493 1.24795844] Bias: -1.156840972984843 loss: 0.3433825583780042\n",
            "Round: 2692 Weight: [2.51489781 1.24795993] Bias: -1.1568421164651808 loss: 0.3433825582591444\n",
            "Round: 2693 Weight: [2.51490069 1.24796141] Bias: -1.156843257113194 loss: 0.34338255814087243\n",
            "Round: 2694 Weight: [2.51490356 1.24796289] Bias: -1.1568443949359066 loss: 0.34338255802318574\n",
            "Round: 2695 Weight: [2.51490643 1.24796436] Bias: -1.156845529940325 loss: 0.34338255790608124\n",
            "Round: 2696 Weight: [2.51490928 1.24796583] Bias: -1.1568466621334383 loss: 0.343382557789556\n",
            "Round: 2697 Weight: [2.51491213 1.2479673 ] Bias: -1.1568477915222182 loss: 0.34338255767360726\n",
            "Round: 2698 Weight: [2.51491498 1.24796876] Bias: -1.1568489181136188 loss: 0.3433825575582321\n",
            "Round: 2699 Weight: [2.51491781 1.24797022] Bias: -1.156850041914577 loss: 0.3433825574434277\n",
            "Round: 2700 Weight: [2.51492064 1.24797168] Bias: -1.1568511629320128 loss: 0.34338255732919143\n",
            "Round: 2701 Weight: [2.51492346 1.24797313] Bias: -1.1568522811728286 loss: 0.3433825572155201\n",
            "Round: 2702 Weight: [2.51492628 1.24797458] Bias: -1.1568533966439098 loss: 0.34338255710241117\n",
            "Round: 2703 Weight: [2.51492909 1.24797603] Bias: -1.156854509352125 loss: 0.3433825569898618\n",
            "Round: 2704 Weight: [2.51493189 1.24797747] Bias: -1.156855619304325 loss: 0.34338255687786917\n",
            "Round: 2705 Weight: [2.51493468 1.24797891] Bias: -1.1568567265073442 loss: 0.3433825567664306\n",
            "Round: 2706 Weight: [2.51493747 1.24798034] Bias: -1.1568578309679998 loss: 0.3433825566555434\n",
            "Round: 2707 Weight: [2.51494025 1.24798178] Bias: -1.156858932693092 loss: 0.34338255654520483\n",
            "Round: 2708 Weight: [2.51494302 1.2479832 ] Bias: -1.1568600316894042 loss: 0.34338255643541177\n",
            "Round: 2709 Weight: [2.51494579 1.24798463] Bias: -1.1568611279637029 loss: 0.34338255632616216\n",
            "Round: 2710 Weight: [2.51494855 1.24798605] Bias: -1.1568622215227378 loss: 0.34338255621745295\n",
            "Round: 2711 Weight: [2.5149513  1.24798747] Bias: -1.1568633123732417 loss: 0.3433825561092815\n",
            "Round: 2712 Weight: [2.51495405 1.24798888] Bias: -1.1568644005219308 loss: 0.343382556001645\n",
            "Round: 2713 Weight: [2.51495679 1.24799029] Bias: -1.1568654859755048 loss: 0.34338255589454114\n",
            "Round: 2714 Weight: [2.51495952 1.2479917 ] Bias: -1.1568665687406463 loss: 0.34338255578796717\n",
            "Round: 2715 Weight: [2.51496225 1.2479931 ] Bias: -1.1568676488240215 loss: 0.3433825556819203\n",
            "Round: 2716 Weight: [2.51496496 1.2479945 ] Bias: -1.15686872623228 loss: 0.3433825555763981\n",
            "Round: 2717 Weight: [2.51496768 1.2479959 ] Bias: -1.1568698009720553 loss: 0.3433825554713978\n",
            "Round: 2718 Weight: [2.51497038 1.24799729] Bias: -1.1568708730499637 loss: 0.3433825553669169\n",
            "Round: 2719 Weight: [2.51497308 1.24799868] Bias: -1.1568719424726057 loss: 0.34338255526295297\n",
            "Round: 2720 Weight: [2.51497577 1.24800007] Bias: -1.1568730092465649 loss: 0.34338255515950333\n",
            "Round: 2721 Weight: [2.51497846 1.24800145] Bias: -1.1568740733784086 loss: 0.34338255505656545\n",
            "Round: 2722 Weight: [2.51498114 1.24800283] Bias: -1.1568751348746882 loss: 0.3433825549541367\n",
            "Round: 2723 Weight: [2.51498381 1.2480042 ] Bias: -1.1568761937419383 loss: 0.34338255485221475\n",
            "Round: 2724 Weight: [2.51498647 1.24800558] Bias: -1.1568772499866777 loss: 0.343382554750797\n",
            "Round: 2725 Weight: [2.51498913 1.24800694] Bias: -1.1568783036154087 loss: 0.34338255464988077\n",
            "Round: 2726 Weight: [2.51499179 1.24800831] Bias: -1.1568793546346174 loss: 0.3433825545494638\n",
            "Round: 2727 Weight: [2.51499443 1.24800967] Bias: -1.1568804030507742 loss: 0.34338255444954363\n",
            "Round: 2728 Weight: [2.51499707 1.24801103] Bias: -1.1568814488703332 loss: 0.3433825543501178\n",
            "Round: 2729 Weight: [2.5149997  1.24801239] Bias: -1.156882492099732 loss: 0.3433825542511837\n",
            "Round: 2730 Weight: [2.51500233 1.24801374] Bias: -1.156883532745393 loss: 0.34338255415273905\n",
            "Round: 2731 Weight: [2.51500495 1.24801509] Bias: -1.156884570813722 loss: 0.34338255405478124\n",
            "Round: 2732 Weight: [2.51500756 1.24801643] Bias: -1.1568856063111095 loss: 0.3433825539573082\n",
            "Round: 2733 Weight: [2.51501017 1.24801777] Bias: -1.1568866392439294 loss: 0.34338255386031724\n",
            "Round: 2734 Weight: [2.51501277 1.24801911] Bias: -1.1568876696185404 loss: 0.34338255376380605\n",
            "Round: 2735 Weight: [2.51501536 1.24802045] Bias: -1.1568886974412849 loss: 0.3433825536677723\n",
            "Round: 2736 Weight: [2.51501795 1.24802178] Bias: -1.1568897227184898 loss: 0.3433825535722136\n",
            "Round: 2737 Weight: [2.51502053 1.24802311] Bias: -1.1568907454564663 loss: 0.34338255347712754\n",
            "Round: 2738 Weight: [2.51502311 1.24802444] Bias: -1.1568917656615099 loss: 0.34338255338251195\n",
            "Round: 2739 Weight: [2.51502567 1.24802576] Bias: -1.1568927833399003 loss: 0.34338255328836415\n",
            "Round: 2740 Weight: [2.51502824 1.24802708] Bias: -1.1568937984979017 loss: 0.3433825531946823\n",
            "Round: 2741 Weight: [2.51503079 1.24802839] Bias: -1.156894811141763 loss: 0.34338255310146376\n",
            "Round: 2742 Weight: [2.51503334 1.2480297 ] Bias: -1.156895821277717 loss: 0.3433825530087063\n",
            "Round: 2743 Weight: [2.51503588 1.24803101] Bias: -1.1568968289119814 loss: 0.34338255291640785\n",
            "Round: 2744 Weight: [2.51503842 1.24803232] Bias: -1.1568978340507587 loss: 0.3433825528245657\n",
            "Round: 2745 Weight: [2.51504095 1.24803362] Bias: -1.1568988367002355 loss: 0.34338255273317797\n",
            "Round: 2746 Weight: [2.51504347 1.24803492] Bias: -1.1568998368665833 loss: 0.34338255264224227\n",
            "Round: 2747 Weight: [2.51504599 1.24803622] Bias: -1.156900834555958 loss: 0.3433825525517564\n",
            "Round: 2748 Weight: [2.5150485  1.24803751] Bias: -1.1569018297745004 loss: 0.34338255246171817\n",
            "Round: 2749 Weight: [2.51505101 1.2480388 ] Bias: -1.1569028225283362 loss: 0.3433825523721253\n",
            "Round: 2750 Weight: [2.51505351 1.24804009] Bias: -1.1569038128235758 loss: 0.34338255228297554\n",
            "Round: 2751 Weight: [2.515056   1.24804137] Bias: -1.156904800666314 loss: 0.3433825521942668\n",
            "Round: 2752 Weight: [2.51505849 1.24804265] Bias: -1.1569057860626313 loss: 0.3433825521059968\n",
            "Round: 2753 Weight: [2.51506097 1.24804393] Bias: -1.1569067690185921 loss: 0.3433825520181635\n",
            "Round: 2754 Weight: [2.51506344 1.2480452 ] Bias: -1.1569077495402464 loss: 0.3433825519307646\n",
            "Round: 2755 Weight: [2.51506591 1.24804647] Bias: -1.1569087276336292 loss: 0.34338255184379807\n",
            "Round: 2756 Weight: [2.51506837 1.24804774] Bias: -1.15690970330476 loss: 0.3433825517572617\n",
            "Round: 2757 Weight: [2.51507083 1.24804901] Bias: -1.1569106765596437 loss: 0.34338255167115334\n",
            "Round: 2758 Weight: [2.51507328 1.24805027] Bias: -1.1569116474042704 loss: 0.343382551585471\n",
            "Round: 2759 Weight: [2.51507572 1.24805153] Bias: -1.1569126158446152 loss: 0.34338255150021235\n",
            "Round: 2760 Weight: [2.51507816 1.24805278] Bias: -1.156913581886638 loss: 0.34338255141537544\n",
            "Round: 2761 Weight: [2.51508059 1.24805403] Bias: -1.1569145455362846 loss: 0.3433825513309582\n",
            "Round: 2762 Weight: [2.51508302 1.24805528] Bias: -1.1569155067994854 loss: 0.3433825512469586\n",
            "Round: 2763 Weight: [2.51508544 1.24805653] Bias: -1.1569164656821562 loss: 0.34338255116337424\n",
            "Round: 2764 Weight: [2.51508785 1.24805777] Bias: -1.1569174221901986 loss: 0.3433825510802035\n",
            "Round: 2765 Weight: [2.51509026 1.24805901] Bias: -1.1569183763294988 loss: 0.34338255099744414\n",
            "Round: 2766 Weight: [2.51509266 1.24806025] Bias: -1.156919328105929 loss: 0.3433825509150941\n",
            "Round: 2767 Weight: [2.51509506 1.24806148] Bias: -1.1569202775253462 loss: 0.34338255083315133\n",
            "Round: 2768 Weight: [2.51509745 1.24806271] Bias: -1.1569212245935934 loss: 0.34338255075161406\n",
            "Round: 2769 Weight: [2.51509983 1.24806394] Bias: -1.1569221693164988 loss: 0.3433825506704799\n",
            "Round: 2770 Weight: [2.51510221 1.24806516] Bias: -1.1569231116998766 loss: 0.3433825505897472\n",
            "Round: 2771 Weight: [2.51510458 1.24806638] Bias: -1.1569240517495258 loss: 0.3433825505094137\n",
            "Round: 2772 Weight: [2.51510695 1.2480676 ] Bias: -1.1569249894712315 loss: 0.34338255042947763\n",
            "Round: 2773 Weight: [2.51510931 1.24806882] Bias: -1.1569259248707642 loss: 0.3433825503499369\n",
            "Round: 2774 Weight: [2.51511167 1.24807003] Bias: -1.1569268579538803 loss: 0.34338255027078957\n",
            "Round: 2775 Weight: [2.51511401 1.24807124] Bias: -1.1569277887263216 loss: 0.3433825501920338\n",
            "Round: 2776 Weight: [2.51511636 1.24807245] Bias: -1.1569287171938158 loss: 0.34338255011366753\n",
            "Round: 2777 Weight: [2.5151187  1.24807365] Bias: -1.1569296433620766 loss: 0.3433825500356889\n",
            "Round: 2778 Weight: [2.51512103 1.24807485] Bias: -1.156930567236803 loss: 0.3433825499580959\n",
            "Round: 2779 Weight: [2.51512335 1.24807605] Bias: -1.1569314888236806 loss: 0.34338254988088673\n",
            "Round: 2780 Weight: [2.51512567 1.24807724] Bias: -1.15693240812838 loss: 0.34338254980405947\n",
            "Round: 2781 Weight: [2.51512799 1.24807843] Bias: -1.1569333251565583 loss: 0.3433825497276122\n",
            "Round: 2782 Weight: [2.5151303  1.24807962] Bias: -1.1569342399138585 loss: 0.34338254965154297\n",
            "Round: 2783 Weight: [2.5151326  1.24808081] Bias: -1.1569351524059093 loss: 0.34338254957584996\n",
            "Round: 2784 Weight: [2.5151349  1.24808199] Bias: -1.1569360626383256 loss: 0.3433825495005315\n",
            "Round: 2785 Weight: [2.51513719 1.24808317] Bias: -1.1569369706167083 loss: 0.34338254942558555\n",
            "Round: 2786 Weight: [2.51513947 1.24808435] Bias: -1.1569378763466445 loss: 0.3433825493510101\n",
            "Round: 2787 Weight: [2.51514175 1.24808552] Bias: -1.1569387798337074 loss: 0.3433825492768037\n",
            "Round: 2788 Weight: [2.51514403 1.24808669] Bias: -1.1569396810834565 loss: 0.34338254920296424\n",
            "Round: 2789 Weight: [2.5151463  1.24808786] Bias: -1.156940580101437 loss: 0.34338254912949007\n",
            "Round: 2790 Weight: [2.51514856 1.24808902] Bias: -1.1569414768931807 loss: 0.3433825490563792\n",
            "Round: 2791 Weight: [2.51515082 1.24809019] Bias: -1.1569423714642058 loss: 0.34338254898363\n",
            "Round: 2792 Weight: [2.51515307 1.24809135] Bias: -1.1569432638200163 loss: 0.3433825489112406\n",
            "Round: 2793 Weight: [2.51515531 1.2480925 ] Bias: -1.1569441539661032 loss: 0.3433825488392093\n",
            "Round: 2794 Weight: [2.51515756 1.24809366] Bias: -1.1569450419079432 loss: 0.3433825487675342\n",
            "Round: 2795 Weight: [2.51515979 1.24809481] Bias: -1.156945927651 loss: 0.3433825486962136\n",
            "Round: 2796 Weight: [2.51516202 1.24809596] Bias: -1.156946811200723 loss: 0.3433825486252458\n",
            "Round: 2797 Weight: [2.51516425 1.2480971 ] Bias: -1.156947692562549 loss: 0.34338254855462896\n",
            "Round: 2798 Weight: [2.51516646 1.24809824] Bias: -1.1569485717419008 loss: 0.3433825484843614\n",
            "Round: 2799 Weight: [2.51516868 1.24809938] Bias: -1.1569494487441874 loss: 0.3433825484144414\n",
            "Round: 2800 Weight: [2.51517088 1.24810052] Bias: -1.1569503235748049 loss: 0.34338254834486726\n",
            "Round: 2801 Weight: [2.51517309 1.24810165] Bias: -1.1569511962391357 loss: 0.3433825482756372\n",
            "Round: 2802 Weight: [2.51517528 1.24810278] Bias: -1.156952066742549 loss: 0.34338254820674946\n",
            "Round: 2803 Weight: [2.51517748 1.24810391] Bias: -1.1569529350904006 loss: 0.3433825481382025\n",
            "Round: 2804 Weight: [2.51517966 1.24810504] Bias: -1.1569538012880332 loss: 0.3433825480699945\n",
            "Round: 2805 Weight: [2.51518184 1.24810616] Bias: -1.1569546653407756 loss: 0.34338254800212403\n",
            "Round: 2806 Weight: [2.51518402 1.24810728] Bias: -1.1569555272539442 loss: 0.343382547934589\n",
            "Round: 2807 Weight: [2.51518619 1.2481084 ] Bias: -1.1569563870328419 loss: 0.3433825478673881\n",
            "Round: 2808 Weight: [2.51518835 1.24810951] Bias: -1.156957244682758 loss: 0.3433825478005196\n",
            "Round: 2809 Weight: [2.51519051 1.24811062] Bias: -1.1569581002089693 loss: 0.34338254773398175\n",
            "Round: 2810 Weight: [2.51519266 1.24811173] Bias: -1.156958953616739 loss: 0.34338254766777304\n",
            "Round: 2811 Weight: [2.51519481 1.24811284] Bias: -1.1569598049113177 loss: 0.3433825476018918\n",
            "Round: 2812 Weight: [2.51519696 1.24811394] Bias: -1.1569606540979425 loss: 0.34338254753633635\n",
            "Round: 2813 Weight: [2.51519909 1.24811504] Bias: -1.1569615011818377 loss: 0.3433825474711052\n",
            "Round: 2814 Weight: [2.51520123 1.24811614] Bias: -1.1569623461682148 loss: 0.3433825474061966\n",
            "Round: 2815 Weight: [2.51520335 1.24811724] Bias: -1.156963189062272 loss: 0.343382547341609\n",
            "Round: 2816 Weight: [2.51520547 1.24811833] Bias: -1.156964029869195 loss: 0.34338254727734085\n",
            "Round: 2817 Weight: [2.51520759 1.24811942] Bias: -1.1569648685941563 loss: 0.3433825472133906\n",
            "Round: 2818 Weight: [2.5152097 1.2481205] Bias: -1.1569657052423157 loss: 0.3433825471497567\n",
            "Round: 2819 Weight: [2.51521181 1.24812159] Bias: -1.1569665398188202 loss: 0.34338254708643734\n",
            "Round: 2820 Weight: [2.51521391 1.24812267] Bias: -1.156967372328804 loss: 0.34338254702343124\n",
            "Round: 2821 Weight: [2.51521601 1.24812375] Bias: -1.1569682027773887 loss: 0.3433825469607368\n",
            "Round: 2822 Weight: [2.5152181  1.24812483] Bias: -1.1569690311696825 loss: 0.3433825468983523\n",
            "Round: 2823 Weight: [2.51522018 1.2481259 ] Bias: -1.1569698575107819 loss: 0.34338254683627645\n",
            "Round: 2824 Weight: [2.51522226 1.24812697] Bias: -1.1569706818057701 loss: 0.34338254677450764\n",
            "Round: 2825 Weight: [2.51522434 1.24812804] Bias: -1.1569715040597182 loss: 0.34338254671304413\n",
            "Round: 2826 Weight: [2.51522641 1.2481291 ] Bias: -1.156972324277684 loss: 0.3433825466518848\n",
            "Round: 2827 Weight: [2.51522847 1.24813017] Bias: -1.1569731424647132 loss: 0.34338254659102785\n",
            "Round: 2828 Weight: [2.51523053 1.24813123] Bias: -1.156973958625839 loss: 0.3433825465304718\n",
            "Round: 2829 Weight: [2.51523259 1.24813229] Bias: -1.156974772766082 loss: 0.3433825464702154\n",
            "Round: 2830 Weight: [2.51523464 1.24813334] Bias: -1.1569755848904504 loss: 0.34338254641025695\n",
            "Round: 2831 Weight: [2.51523668 1.24813439] Bias: -1.1569763950039398 loss: 0.34338254635059506\n",
            "Round: 2832 Weight: [2.51523872 1.24813544] Bias: -1.1569772031115335 loss: 0.34338254629122805\n",
            "Round: 2833 Weight: [2.51524075 1.24813649] Bias: -1.1569780092182027 loss: 0.34338254623215475\n",
            "Round: 2834 Weight: [2.51524278 1.24813754] Bias: -1.1569788133289058 loss: 0.34338254617337377\n",
            "Round: 2835 Weight: [2.51524481 1.24813858] Bias: -1.1569796154485892 loss: 0.3433825461148833\n",
            "Round: 2836 Weight: [2.51524683 1.24813962] Bias: -1.1569804155821866 loss: 0.3433825460566821\n",
            "Round: 2837 Weight: [2.51524884 1.24814066] Bias: -1.15698121373462 loss: 0.3433825459987689\n",
            "Round: 2838 Weight: [2.51525085 1.24814169] Bias: -1.156982009910799 loss: 0.343382545941142\n",
            "Round: 2839 Weight: [2.51525285 1.24814272] Bias: -1.156982804115621 loss: 0.3433825458838\n",
            "Round: 2840 Weight: [2.51525485 1.24814375] Bias: -1.156983596353971 loss: 0.34338254582674177\n",
            "Round: 2841 Weight: [2.51525685 1.24814478] Bias: -1.1569843866307221 loss: 0.3433825457699657\n",
            "Round: 2842 Weight: [2.51525884 1.2481458 ] Bias: -1.1569851749507356 loss: 0.3433825457134704\n",
            "Round: 2843 Weight: [2.51526082 1.24814682] Bias: -1.15698596131886 loss: 0.34338254565725446\n",
            "Round: 2844 Weight: [2.5152628  1.24814784] Bias: -1.1569867457399325 loss: 0.3433825456013165\n",
            "Round: 2845 Weight: [2.51526478 1.24814886] Bias: -1.1569875282187778 loss: 0.3433825455456553\n",
            "Round: 2846 Weight: [2.51526675 1.24814987] Bias: -1.1569883087602089 loss: 0.34338254549026925\n",
            "Round: 2847 Weight: [2.51526871 1.24815089] Bias: -1.1569890873690267 loss: 0.3433825454351571\n",
            "Round: 2848 Weight: [2.51527067 1.24815189] Bias: -1.1569898640500202 loss: 0.3433825453803176\n",
            "Round: 2849 Weight: [2.51527263 1.2481529 ] Bias: -1.1569906388079667 loss: 0.34338254532574924\n",
            "Round: 2850 Weight: [2.51527458 1.24815391] Bias: -1.1569914116476314 loss: 0.3433825452714508\n",
            "Round: 2851 Weight: [2.51527652 1.24815491] Bias: -1.156992182573768 loss: 0.34338254521742084\n",
            "Round: 2852 Weight: [2.51527846 1.24815591] Bias: -1.1569929515911177 loss: 0.34338254516365807\n",
            "Round: 2853 Weight: [2.5152804 1.2481569] Bias: -1.1569937187044106 loss: 0.34338254511016125\n",
            "Round: 2854 Weight: [2.51528233 1.2481579 ] Bias: -1.156994483918365 loss: 0.34338254505692906\n",
            "Round: 2855 Weight: [2.51528426 1.24815889] Bias: -1.1569952472376872 loss: 0.34338254500396\n",
            "Round: 2856 Weight: [2.51528618 1.24815988] Bias: -1.156996008667072 loss: 0.34338254495125287\n",
            "Round: 2857 Weight: [2.5152881  1.24816087] Bias: -1.1569967682112028 loss: 0.3433825448988065\n",
            "Round: 2858 Weight: [2.51529001 1.24816185] Bias: -1.1569975258747507 loss: 0.34338254484661934\n",
            "Round: 2859 Weight: [2.51529192 1.24816283] Bias: -1.1569982816623758 loss: 0.3433825447946905\n",
            "Round: 2860 Weight: [2.51529382 1.24816381] Bias: -1.1569990355787263 loss: 0.34338254474301827\n",
            "Round: 2861 Weight: [2.51529572 1.24816479] Bias: -1.1569997876284392 loss: 0.34338254469160157\n",
            "Round: 2862 Weight: [2.51529761 1.24816576] Bias: -1.1570005378161397 loss: 0.3433825446404394\n",
            "Round: 2863 Weight: [2.5152995  1.24816674] Bias: -1.1570012861464416 loss: 0.34338254458952994\n",
            "Round: 2864 Weight: [2.51530138 1.24816771] Bias: -1.1570020326239472 loss: 0.3433825445388724\n",
            "Round: 2865 Weight: [2.51530326 1.24816867] Bias: -1.1570027772532476 loss: 0.3433825444884654\n",
            "Round: 2866 Weight: [2.51530514 1.24816964] Bias: -1.1570035200389222 loss: 0.3433825444383075\n",
            "Round: 2867 Weight: [2.51530701 1.2481706 ] Bias: -1.1570042609855393 loss: 0.34338254438839777\n",
            "Round: 2868 Weight: [2.51530887 1.24817156] Bias: -1.1570050000976557 loss: 0.343382544338735\n",
            "Round: 2869 Weight: [2.51531073 1.24817252] Bias: -1.1570057373798168 loss: 0.3433825442893176\n",
            "Round: 2870 Weight: [2.51531259 1.24817347] Bias: -1.1570064728365572 loss: 0.3433825442401447\n",
            "Round: 2871 Weight: [2.51531444 1.24817443] Bias: -1.1570072064723995 loss: 0.34338254419121494\n",
            "Round: 2872 Weight: [2.51531629 1.24817538] Bias: -1.1570079382918559 loss: 0.3433825441425272\n",
            "Round: 2873 Weight: [2.51531813 1.24817633] Bias: -1.1570086682994267 loss: 0.34338254409408014\n",
            "Round: 2874 Weight: [2.51531997 1.24817727] Bias: -1.1570093964996013 loss: 0.34338254404587276\n",
            "Round: 2875 Weight: [2.5153218  1.24817822] Bias: -1.1570101228968581 loss: 0.34338254399790374\n",
            "Round: 2876 Weight: [2.51532363 1.24817916] Bias: -1.1570108474956642 loss: 0.34338254395017187\n",
            "Round: 2877 Weight: [2.51532545 1.2481801 ] Bias: -1.1570115703004757 loss: 0.3433825439026761\n",
            "Round: 2878 Weight: [2.51532727 1.24818103] Bias: -1.1570122913157377 loss: 0.34338254385541517\n",
            "Round: 2879 Weight: [2.51532909 1.24818197] Bias: -1.157013010545884 loss: 0.34338254380838795\n",
            "Round: 2880 Weight: [2.5153309 1.2481829] Bias: -1.1570137279953379 loss: 0.3433825437615934\n",
            "Round: 2881 Weight: [2.5153327  1.24818383] Bias: -1.157014443668511 loss: 0.34338254371503013\n",
            "Round: 2882 Weight: [2.5153345  1.24818476] Bias: -1.1570151575698047 loss: 0.34338254366869714\n",
            "Round: 2883 Weight: [2.5153363  1.24818568] Bias: -1.157015869703609 loss: 0.3433825436225934\n",
            "Round: 2884 Weight: [2.51533809 1.24818661] Bias: -1.157016580074303 loss: 0.34338254357671755\n",
            "Round: 2885 Weight: [2.51533988 1.24818753] Bias: -1.1570172886862555 loss: 0.3433825435310685\n",
            "Round: 2886 Weight: [2.51534167 1.24818845] Bias: -1.1570179955438238 loss: 0.34338254348564534\n",
            "Round: 2887 Weight: [2.51534345 1.24818936] Bias: -1.1570187006513546 loss: 0.3433825434404468\n",
            "Round: 2888 Weight: [2.51534522 1.24819028] Bias: -1.1570194040131838 loss: 0.3433825433954717\n",
            "Round: 2889 Weight: [2.51534699 1.24819119] Bias: -1.1570201056336367 loss: 0.34338254335071894\n",
            "Round: 2890 Weight: [2.51534876 1.2481921 ] Bias: -1.1570208055170277 loss: 0.3433825433061875\n",
            "Round: 2891 Weight: [2.51535052 1.248193  ] Bias: -1.1570215036676605 loss: 0.34338254326187645\n",
            "Round: 2892 Weight: [2.51535228 1.24819391] Bias: -1.1570222000898283 loss: 0.3433825432177843\n",
            "Round: 2893 Weight: [2.51535403 1.24819481] Bias: -1.1570228947878134 loss: 0.3433825431739103\n",
            "Round: 2894 Weight: [2.51535578 1.24819571] Bias: -1.1570235877658877 loss: 0.34338254313025335\n",
            "Round: 2895 Weight: [2.51535752 1.24819661] Bias: -1.1570242790283123 loss: 0.3433825430868121\n",
            "Round: 2896 Weight: [2.51535926 1.24819751] Bias: -1.157024968579338 loss: 0.3433825430435858\n",
            "Round: 2897 Weight: [2.515361  1.2481984] Bias: -1.1570256564232047 loss: 0.34338254300057325\n",
            "Round: 2898 Weight: [2.51536273 1.24819929] Bias: -1.157026342564142 loss: 0.34338254295777326\n",
            "Round: 2899 Weight: [2.51536446 1.24820018] Bias: -1.157027027006369 loss: 0.34338254291518505\n",
            "Round: 2900 Weight: [2.51536618 1.24820107] Bias: -1.1570277097540942 loss: 0.34338254287280745\n",
            "Round: 2901 Weight: [2.5153679  1.24820195] Bias: -1.1570283908115158 loss: 0.34338254283063935\n",
            "Round: 2902 Weight: [2.51536962 1.24820284] Bias: -1.1570290701828216 loss: 0.3433825427886798\n",
            "Round: 2903 Weight: [2.51537133 1.24820372] Bias: -1.157029747872189 loss: 0.34338254274692775\n",
            "Round: 2904 Weight: [2.51537303 1.2482046 ] Bias: -1.1570304238837847 loss: 0.3433825427053822\n",
            "Round: 2905 Weight: [2.51537473 1.24820547] Bias: -1.1570310982217655 loss: 0.34338254266404206\n",
            "Round: 2906 Weight: [2.51537643 1.24820635] Bias: -1.1570317708902778 loss: 0.34338254262290624\n",
            "Round: 2907 Weight: [2.51537813 1.24820722] Bias: -1.1570324418934577 loss: 0.3433825425819739\n",
            "Round: 2908 Weight: [2.51537981 1.24820809] Bias: -1.1570331112354308 loss: 0.343382542541244\n",
            "Round: 2909 Weight: [2.5153815  1.24820895] Bias: -1.1570337789203127 loss: 0.34338254250071554\n",
            "Round: 2910 Weight: [2.51538318 1.24820982] Bias: -1.1570344449522088 loss: 0.34338254246038746\n",
            "Round: 2911 Weight: [2.51538486 1.24821068] Bias: -1.1570351093352143 loss: 0.34338254242025884\n",
            "Round: 2912 Weight: [2.51538653 1.24821154] Bias: -1.157035772073414 loss: 0.34338254238032856\n",
            "Round: 2913 Weight: [2.5153882 1.2482124] Bias: -1.1570364331708827 loss: 0.3433825423405958\n",
            "Round: 2914 Weight: [2.51538986 1.24821326] Bias: -1.1570370926316855 loss: 0.34338254230105947\n",
            "Round: 2915 Weight: [2.51539152 1.24821411] Bias: -1.1570377504598768 loss: 0.3433825422617187\n",
            "Round: 2916 Weight: [2.51539318 1.24821497] Bias: -1.1570384066595014 loss: 0.34338254222257236\n",
            "Round: 2917 Weight: [2.51539483 1.24821582] Bias: -1.1570390612345938 loss: 0.3433825421836197\n",
            "Round: 2918 Weight: [2.51539648 1.24821667] Bias: -1.1570397141891784 loss: 0.34338254214485964\n",
            "Round: 2919 Weight: [2.51539812 1.24821751] Bias: -1.1570403655272699 loss: 0.34338254210629116\n",
            "Round: 2920 Weight: [2.51539976 1.24821836] Bias: -1.157041015252873 loss: 0.3433825420679135\n",
            "Round: 2921 Weight: [2.5154014 1.2482192] Bias: -1.1570416633699823 loss: 0.34338254202972557\n",
            "Round: 2922 Weight: [2.51540303 1.24822004] Bias: -1.1570423098825824 loss: 0.3433825419917264\n",
            "Round: 2923 Weight: [2.51540466 1.24822088] Bias: -1.1570429547946486 loss: 0.34338254195391527\n",
            "Round: 2924 Weight: [2.51540628 1.24822171] Bias: -1.1570435981101457 loss: 0.343382541916291\n",
            "Round: 2925 Weight: [2.5154079  1.24822255] Bias: -1.1570442398330287 loss: 0.34338254187885286\n",
            "Round: 2926 Weight: [2.51540952 1.24822338] Bias: -1.1570448799672433 loss: 0.3433825418415998\n",
            "Round: 2927 Weight: [2.51541113 1.24822421] Bias: -1.157045518516725 loss: 0.34338254180453104\n",
            "Round: 2928 Weight: [2.51541273 1.24822504] Bias: -1.1570461554853995 loss: 0.34338254176764543\n",
            "Round: 2929 Weight: [2.51541434 1.24822586] Bias: -1.157046790877183 loss: 0.34338254173094224\n",
            "Round: 2930 Weight: [2.51541594 1.24822668] Bias: -1.157047424695982 loss: 0.3433825416944206\n",
            "Round: 2931 Weight: [2.51541753 1.24822751] Bias: -1.1570480569456931 loss: 0.3433825416580796\n",
            "Round: 2932 Weight: [2.51541912 1.24822833] Bias: -1.1570486876302033 loss: 0.3433825416219183\n",
            "Round: 2933 Weight: [2.51542071 1.24822914] Bias: -1.15704931675339 loss: 0.3433825415859356\n",
            "Round: 2934 Weight: [2.5154223  1.24822996] Bias: -1.157049944319121 loss: 0.343382541550131\n",
            "Round: 2935 Weight: [2.51542388 1.24823077] Bias: -1.1570505703312541 loss: 0.34338254151450337\n",
            "Round: 2936 Weight: [2.51542545 1.24823158] Bias: -1.1570511947936386 loss: 0.343382541479052\n",
            "Round: 2937 Weight: [2.51542702 1.24823239] Bias: -1.157051817710113 loss: 0.3433825414437759\n",
            "Round: 2938 Weight: [2.51542859 1.2482332 ] Bias: -1.1570524390845072 loss: 0.3433825414086742\n",
            "Round: 2939 Weight: [2.51543016 1.24823401] Bias: -1.157053058920641 loss: 0.3433825413737461\n",
            "Round: 2940 Weight: [2.51543172 1.24823481] Bias: -1.1570536772223248 loss: 0.34338254133899065\n",
            "Round: 2941 Weight: [2.51543327 1.24823561] Bias: -1.1570542939933601 loss: 0.3433825413044071\n",
            "Round: 2942 Weight: [2.51543483 1.24823641] Bias: -1.1570549092375384 loss: 0.34338254126999457\n",
            "Round: 2943 Weight: [2.51543638 1.24823721] Bias: -1.157055522958642 loss: 0.3433825412357521\n",
            "Round: 2944 Weight: [2.51543792 1.248238  ] Bias: -1.1570561351604436 loss: 0.3433825412016791\n",
            "Round: 2945 Weight: [2.51543946 1.2482388 ] Bias: -1.157056745846707 loss: 0.3433825411677745\n",
            "Round: 2946 Weight: [2.515441   1.24823959] Bias: -1.1570573550211862 loss: 0.34338254113403754\n",
            "Round: 2947 Weight: [2.51544253 1.24824038] Bias: -1.1570579626876263 loss: 0.34338254110046745\n",
            "Round: 2948 Weight: [2.51544406 1.24824116] Bias: -1.1570585688497628 loss: 0.3433825410670633\n",
            "Round: 2949 Weight: [2.51544559 1.24824195] Bias: -1.1570591735113218 loss: 0.3433825410338243\n",
            "Round: 2950 Weight: [2.51544711 1.24824273] Bias: -1.1570597766760207 loss: 0.3433825410007497\n",
            "Round: 2951 Weight: [2.51544863 1.24824352] Bias: -1.1570603783475673 loss: 0.34338254096783866\n",
            "Round: 2952 Weight: [2.51545014 1.2482443 ] Bias: -1.1570609785296602 loss: 0.3433825409350903\n",
            "Round: 2953 Weight: [2.51545165 1.24824507] Bias: -1.157061577225989 loss: 0.3433825409025039\n",
            "Round: 2954 Weight: [2.51545316 1.24824585] Bias: -1.1570621744402338 loss: 0.3433825408700786\n",
            "Round: 2955 Weight: [2.51545467 1.24824662] Bias: -1.1570627701760663 loss: 0.3433825408378137\n",
            "Round: 2956 Weight: [2.51545617 1.2482474 ] Bias: -1.1570633644371484 loss: 0.34338254080570824\n",
            "Round: 2957 Weight: [2.51545766 1.24824817] Bias: -1.157063957227133 loss: 0.3433825407737617\n",
            "Round: 2958 Weight: [2.51545915 1.24824893] Bias: -1.1570645485496642 loss: 0.34338254074197294\n",
            "Round: 2959 Weight: [2.51546064 1.2482497 ] Bias: -1.157065138408377 loss: 0.34338254071034147\n",
            "Round: 2960 Weight: [2.51546213 1.24825047] Bias: -1.1570657268068971 loss: 0.3433825406788663\n",
            "Round: 2961 Weight: [2.51546361 1.24825123] Bias: -1.1570663137488417 loss: 0.34338254064754686\n",
            "Round: 2962 Weight: [2.51546509 1.24825199] Bias: -1.1570668992378186 loss: 0.34338254061638224\n",
            "Round: 2963 Weight: [2.51546656 1.24825275] Bias: -1.1570674832774268 loss: 0.3433825405853717\n",
            "Round: 2964 Weight: [2.51546803 1.2482535 ] Bias: -1.1570680658712564 loss: 0.3433825405545145\n",
            "Round: 2965 Weight: [2.5154695  1.24825426] Bias: -1.1570686470228886 loss: 0.3433825405238099\n",
            "Round: 2966 Weight: [2.51547096 1.24825501] Bias: -1.1570692267358957 loss: 0.3433825404932571\n",
            "Round: 2967 Weight: [2.51547242 1.24825576] Bias: -1.1570698050138413 loss: 0.3433825404628555\n",
            "Round: 2968 Weight: [2.51547388 1.24825651] Bias: -1.1570703818602797 loss: 0.3433825404326041\n",
            "Round: 2969 Weight: [2.51547533 1.24825726] Bias: -1.1570709572787568 loss: 0.34338254040250227\n",
            "Round: 2970 Weight: [2.51547678 1.24825801] Bias: -1.1570715312728097 loss: 0.3433825403725492\n",
            "Round: 2971 Weight: [2.51547822 1.24825875] Bias: -1.1570721038459666 loss: 0.34338254034274435\n",
            "Round: 2972 Weight: [2.51547966 1.24825949] Bias: -1.1570726750017468 loss: 0.3433825403130869\n",
            "Round: 2973 Weight: [2.5154811  1.24826023] Bias: -1.1570732447436614 loss: 0.343382540283576\n",
            "Round: 2974 Weight: [2.51548253 1.24826097] Bias: -1.157073813075212 loss: 0.3433825402542111\n",
            "Round: 2975 Weight: [2.51548397 1.24826171] Bias: -1.1570743799998924 loss: 0.34338254022499126\n",
            "Round: 2976 Weight: [2.51548539 1.24826244] Bias: -1.157074945521187 loss: 0.343382540195916\n",
            "Round: 2977 Weight: [2.51548682 1.24826318] Bias: -1.157075509642572 loss: 0.34338254016698444\n",
            "Round: 2978 Weight: [2.51548824 1.24826391] Bias: -1.1570760723675146 loss: 0.3433825401381961\n",
            "Round: 2979 Weight: [2.51548965 1.24826464] Bias: -1.157076633699474 loss: 0.34338254010954994\n",
            "Round: 2980 Weight: [2.51549107 1.24826537] Bias: -1.1570771936419002 loss: 0.3433825400810454\n",
            "Round: 2981 Weight: [2.51549248 1.24826609] Bias: -1.157077752198235 loss: 0.3433825400526819\n",
            "Round: 2982 Weight: [2.51549388 1.24826681] Bias: -1.1570783093719115 loss: 0.34338254002445856\n",
            "Round: 2983 Weight: [2.51549528 1.24826754] Bias: -1.1570788651663544 loss: 0.3433825399963748\n",
            "Round: 2984 Weight: [2.51549668 1.24826826] Bias: -1.1570794195849798 loss: 0.3433825399684299\n",
            "Round: 2985 Weight: [2.51549808 1.24826898] Bias: -1.1570799726311956 loss: 0.3433825399406233\n",
            "Round: 2986 Weight: [2.51549947 1.24826969] Bias: -1.1570805243084006 loss: 0.343382539912954\n",
            "Round: 2987 Weight: [2.51550086 1.24827041] Bias: -1.157081074619986 loss: 0.34338253988542156\n",
            "Round: 2988 Weight: [2.51550225 1.24827112] Bias: -1.157081623569334 loss: 0.3433825398580253\n",
            "Round: 2989 Weight: [2.51550363 1.24827183] Bias: -1.1570821711598187 loss: 0.3433825398307644\n",
            "Round: 2990 Weight: [2.51550501 1.24827254] Bias: -1.1570827173948057 loss: 0.34338253980363825\n",
            "Round: 2991 Weight: [2.51550638 1.24827325] Bias: -1.1570832622776523 loss: 0.34338253977664646\n",
            "Round: 2992 Weight: [2.51550775 1.24827396] Bias: -1.1570838058117077 loss: 0.343382539749788\n",
            "Round: 2993 Weight: [2.51550912 1.24827466] Bias: -1.1570843480003123 loss: 0.34338253972306226\n",
            "Round: 2994 Weight: [2.51551049 1.24827536] Bias: -1.1570848888467986 loss: 0.3433825396964687\n",
            "Round: 2995 Weight: [2.51551185 1.24827606] Bias: -1.1570854283544907 loss: 0.3433825396700067\n",
            "Round: 2996 Weight: [2.51551321 1.24827676] Bias: -1.1570859665267046 loss: 0.3433825396436756\n",
            "Round: 2997 Weight: [2.51551456 1.24827746] Bias: -1.1570865033667477 loss: 0.34338253961747445\n",
            "Round: 2998 Weight: [2.51551591 1.24827816] Bias: -1.1570870388779197 loss: 0.3433825395914029\n",
            "Round: 2999 Weight: [2.51551726 1.24827885] Bias: -1.1570875730635117 loss: 0.34338253956546033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKc9SvLVCKUg",
        "outputId": "0d6e6417-25d9-4cc8-ca3d-a71b8cd59e68"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.79535913, -1.21175916],\n",
              "       [-0.89622783, -1.09296895],\n",
              "       [-0.05043435,  0.15432828],\n",
              "       [-0.61429667,  0.59979158],\n",
              "       [ 0.79535913,  0.30281605],\n",
              "       [ 0.32547386,  0.3325136 ],\n",
              "       [-0.05043435,  2.29255211],\n",
              "       [-0.42634257,  2.38164477],\n",
              "       [ 1.35922145, -1.41964203],\n",
              "       [-0.05043435,  0.09493318],\n",
              "       [ 0.13751976, -0.29113501],\n",
              "       [-1.74202132,  0.03553807],\n",
              "       [-1.08418194,  1.46102062],\n",
              "       [-0.61429667,  0.15432828],\n",
              "       [-0.70827373,  0.59979158],\n",
              "       [-0.23838846,  0.57009403],\n",
              "       [-1.46009016, -1.50873469],\n",
              "       [ 0.32547386, -0.70690076],\n",
              "       [ 2.11103788, -0.79599342],\n",
              "       [ 1.07729029,  0.15432828],\n",
              "       [-0.23838846, -0.32083257],\n",
              "       [-1.55406721, -0.02385703],\n",
              "       [ 0.70138208,  1.84708881],\n",
              "       [-0.23838846,  0.12463073],\n",
              "       [ 1.64115261, -0.88508607],\n",
              "       [-1.08418194, -1.5681298 ],\n",
              "       [-0.33236551,  0.09493318],\n",
              "       [-0.89622783, -0.40992522],\n",
              "       [-0.52031962,  1.52041573],\n",
              "       [-0.61429667, -1.50873469],\n",
              "       [-1.74202132, -1.30085182],\n",
              "       [-0.80225078,  2.35194722],\n",
              "       [-0.23838846,  0.06523563],\n",
              "       [-1.08418194,  0.3325136 ],\n",
              "       [ 1.2652444 ,  2.29255211],\n",
              "       [ 0.13751976,  1.57981083],\n",
              "       [ 0.98331324,  2.14406434],\n",
              "       [ 0.23149681,  0.18402584],\n",
              "       [-1.27213605,  0.45130382],\n",
              "       [ 1.2652444 ,  1.93618147],\n",
              "       [ 1.45319851,  0.09493318],\n",
              "       [ 0.13751976,  0.30281605],\n",
              "       [ 0.98331324,  1.84708881],\n",
              "       [-1.08418194, -0.49901788],\n",
              "       [ 0.41945092, -0.43962278],\n",
              "       [ 0.98331324, -1.06327139],\n",
              "       [-1.55406721,  0.57009403],\n",
              "       [-0.23838846, -0.55841299],\n",
              "       [-0.05043435,  2.233157  ],\n",
              "       [-0.23838846, -0.35053012],\n",
              "       [-1.64804426,  0.39190871],\n",
              "       [-1.64804426, -0.58811054],\n",
              "       [ 1.07729029, -1.21175916],\n",
              "       [-0.80225078,  0.3325136 ],\n",
              "       [ 0.88933618,  1.31253286],\n",
              "       [ 0.32547386, -0.49901788],\n",
              "       [-0.33236551,  1.2828353 ],\n",
              "       [ 0.79535913, -1.09296895],\n",
              "       [ 1.64115261,  1.66890349],\n",
              "       [-0.14441141, -0.55841299],\n",
              "       [-0.23838846, -0.91478363],\n",
              "       [-0.80225078, -0.23173991],\n",
              "       [ 0.79535913, -1.36024692],\n",
              "       [-0.42634257, -1.21175916],\n",
              "       [-0.23838846,  0.83737201],\n",
              "       [-1.08418194,  0.3325136 ],\n",
              "       [ 0.23149681, -0.64750565],\n",
              "       [-0.14441141,  0.89676711],\n",
              "       [ 0.32547386,  0.30281605],\n",
              "       [-1.27213605, -1.09296895],\n",
              "       [ 2.01706083, -0.79599342],\n",
              "       [ 0.23149681, -0.29113501],\n",
              "       [-0.89622783,  0.54039647],\n",
              "       [-0.70827373, -0.58811054],\n",
              "       [-1.08418194, -1.15236405],\n",
              "       [-0.05043435,  0.2731185 ],\n",
              "       [ 0.0435427 ,  0.3325136 ],\n",
              "       [ 0.23149681,  0.09493318],\n",
              "       [ 0.41945092,  0.3325136 ],\n",
              "       [-1.27213605, -1.47903714],\n",
              "       [ 0.23149681,  0.06523563],\n",
              "       [-1.83599837,  0.51069892],\n",
              "       [ 0.79535913,  1.43132307],\n",
              "       [-1.74202132, -1.47903714],\n",
              "       [-1.27213605, -1.36024692],\n",
              "       [ 0.98331324, -1.18206161],\n",
              "       [ 1.64115261,  1.81739126],\n",
              "       [-0.80225078,  0.18402584],\n",
              "       [-1.08418194,  0.51069892],\n",
              "       [-1.08418194, -1.00387629],\n",
              "       [-0.05043435, -0.46932033],\n",
              "       [-0.05043435,  0.06523563],\n",
              "       [ 0.32547386, -0.26143746],\n",
              "       [-0.70827373, -0.20204235],\n",
              "       [ 0.88933618, -0.76629586],\n",
              "       [-0.23838846, -0.73659831],\n",
              "       [ 0.0435427 ,  0.06523563],\n",
              "       [-0.05043435, -0.40992522],\n",
              "       [-0.23838846, -0.11294969],\n",
              "       [-1.178159  ,  0.54039647],\n",
              "       [ 0.0435427 , -0.23173991],\n",
              "       [-0.89622783, -0.29113501],\n",
              "       [ 0.13751976,  0.24342094],\n",
              "       [-1.3661131 , -1.44933958],\n",
              "       [ 0.0435427 ,  1.31253286],\n",
              "       [ 1.17126734, -0.73659831],\n",
              "       [ 1.54717556, -1.27115427],\n",
              "       [-0.23838846, -0.55841299],\n",
              "       [ 0.70138208, -0.70690076],\n",
              "       [ 0.51342797,  1.2828353 ],\n",
              "       [-0.99020489, -0.32083257],\n",
              "       [-0.14441141,  1.66890349],\n",
              "       [ 1.35922145,  2.05497168],\n",
              "       [-1.27213605, -0.40992522],\n",
              "       [-0.14441141,  1.69860105],\n",
              "       [ 0.0435427 , -0.55841299],\n",
              "       [-1.27213605, -0.32083257],\n",
              "       [ 1.07729029,  0.59979158],\n",
              "       [ 0.98331324, -1.00387629],\n",
              "       [-0.61429667, -1.03357384],\n",
              "       [-0.23838846,  0.09493318],\n",
              "       [ 0.88933618,  1.07495243],\n",
              "       [ 1.17126734, -1.44933958],\n",
              "       [-1.08418194, -1.59782735],\n",
              "       [-0.14441141, -0.26143746],\n",
              "       [-1.27213605, -0.40992522],\n",
              "       [-0.70827373,  0.30281605],\n",
              "       [ 1.54717556,  1.16404509],\n",
              "       [ 0.88933618, -0.55841299],\n",
              "       [ 0.0435427 , -0.11294969],\n",
              "       [-0.70827373,  1.40162552],\n",
              "       [-0.52031962,  1.43132307],\n",
              "       [ 0.98331324, -1.15236405],\n",
              "       [ 0.41945092, -0.46932033],\n",
              "       [-0.23838846, -0.64750565],\n",
              "       [ 1.07729029, -1.21175916],\n",
              "       [ 0.23149681, -0.35053012],\n",
              "       [-1.178159  ,  0.3325136 ],\n",
              "       [-0.05043435, -0.20204235],\n",
              "       [-1.83599837, -0.49901788],\n",
              "       [-0.23838846,  0.18402584],\n",
              "       [-0.99020489, -1.1226665 ],\n",
              "       [ 0.98331324,  0.15432828],\n",
              "       [ 0.88933618, -0.64750565],\n",
              "       [-0.70827373,  1.13434754],\n",
              "       [ 0.32547386, -0.49901788],\n",
              "       [ 0.41945092,  1.04525488],\n",
              "       [ 1.73512967,  1.90648392],\n",
              "       [ 0.32547386,  0.54039647],\n",
              "       [ 2.11103788, -1.03357384],\n",
              "       [-0.70827373,  0.54039647],\n",
              "       [ 2.01706083,  0.21372339],\n",
              "       [-1.3661131 ,  0.39190871],\n",
              "       [ 0.13751976, -0.79599342],\n",
              "       [-1.55406721, -1.5681298 ],\n",
              "       [ 1.92308377, -1.36024692],\n",
              "       [ 1.82910672, -0.26143746],\n",
              "       [-0.23838846, -1.44933958],\n",
              "       [-0.14441141, -0.1723448 ],\n",
              "       [ 0.13751976,  1.10464998],\n",
              "       [-0.52031962, -1.50873469],\n",
              "       [ 1.17126734,  0.57009403],\n",
              "       [-0.61429667,  0.21372339],\n",
              "       [-0.23838846, -0.46932033],\n",
              "       [ 0.13751976,  0.18402584],\n",
              "       [ 0.98331324,  2.05497168],\n",
              "       [ 0.88933618, -1.03357384],\n",
              "       [-0.52031962, -1.50873469],\n",
              "       [-1.08418194,  0.36221116],\n",
              "       [-0.05043435,  0.24342094],\n",
              "       [ 0.23149681,  0.2731185 ],\n",
              "       [-0.23838846,  0.18402584],\n",
              "       [-0.99020489, -0.43962278],\n",
              "       [ 2.11103788,  1.16404509],\n",
              "       [-1.27213605, -1.24145671],\n",
              "       [-1.74202132, -1.41964203],\n",
              "       [-1.83599837, -0.02385703],\n",
              "       [-0.80225078, -0.64750565],\n",
              "       [ 0.98331324,  0.80767445],\n",
              "       [ 1.07729029, -0.88508607],\n",
              "       [-0.14441141,  1.46102062],\n",
              "       [ 0.70138208, -1.09296895],\n",
              "       [ 1.07729029,  0.51069892],\n",
              "       [ 1.92308377,  0.7779769 ],\n",
              "       [-0.99020489,  0.59979158],\n",
              "       [-1.46009016, -0.40992522],\n",
              "       [ 1.92308377,  0.95616222],\n",
              "       [-1.64804426,  0.15432828],\n",
              "       [ 1.07729029, -0.11294969],\n",
              "       [-0.42634257,  0.00584052],\n",
              "       [-0.23838846, -1.36024692],\n",
              "       [-0.33236551, -0.76629586],\n",
              "       [-0.99020489,  0.62948913],\n",
              "       [-0.89622783,  0.48100137],\n",
              "       [-0.99020489, -1.53843224],\n",
              "       [-0.23838846, -0.26143746],\n",
              "       [-0.23838846, -0.88508607],\n",
              "       [-1.3661131 , -0.6178081 ],\n",
              "       [ 0.32547386,  0.09493318],\n",
              "       [-0.80225078, -1.21175916],\n",
              "       [ 0.13751976,  0.12463073],\n",
              "       [ 0.79535913,  0.80767445],\n",
              "       [-0.80225078,  0.42160626],\n",
              "       [-0.99020489,  0.45130382],\n",
              "       [ 1.54717556,  0.03553807],\n",
              "       [-1.08418194, -1.53843224],\n",
              "       [ 1.45319851,  0.39190871],\n",
              "       [ 0.79535913,  0.39190871],\n",
              "       [-0.70827373, -1.53843224],\n",
              "       [ 0.41945092,  0.3325136 ],\n",
              "       [ 1.07729029, -0.97417873],\n",
              "       [ 2.01706083,  0.57009403],\n",
              "       [ 2.11103788, -0.79599342],\n",
              "       [-0.61429667, -0.02385703],\n",
              "       [ 0.32547386,  0.06523563],\n",
              "       [-0.05043435,  0.71858179],\n",
              "       [-0.33236551, -0.76629586],\n",
              "       [-1.46009016, -0.1723448 ],\n",
              "       [ 0.0435427 , -0.23173991],\n",
              "       [ 0.32547386,  0.09493318],\n",
              "       [ 1.35922145,  2.41134232],\n",
              "       [ 1.17126734, -0.97417873],\n",
              "       [ 0.70138208,  0.30281605],\n",
              "       [-1.83599837, -0.73659831],\n",
              "       [ 0.13751976, -0.79599342],\n",
              "       [ 0.0435427 , -0.29113501],\n",
              "       [ 0.88933618, -1.30085182],\n",
              "       [ 1.82910672, -1.27115427],\n",
              "       [-0.14441141, -1.06327139],\n",
              "       [ 1.82910672, -1.06327139],\n",
              "       [-1.27213605,  0.59979158],\n",
              "       [-1.3661131 , -0.1723448 ],\n",
              "       [ 2.01706083,  0.42160626],\n",
              "       [ 0.41945092, -0.43962278],\n",
              "       [-0.42634257, -0.52871544],\n",
              "       [ 0.23149681, -0.26143746],\n",
              "       [-1.55406721,  0.09493318],\n",
              "       [ 0.51342797,  1.90648392],\n",
              "       [-0.61429667, -0.08325214],\n",
              "       [ 0.0435427 , -0.52871544],\n",
              "       [-0.89622783,  0.45130382],\n",
              "       [-1.08418194,  0.09493318],\n",
              "       [-1.3661131 , -1.21175916],\n",
              "       [-1.64804426,  0.39190871],\n",
              "       [-0.99020489,  2.02527413],\n",
              "       [ 1.07729029,  0.57009403],\n",
              "       [-0.23838846,  1.16404509],\n",
              "       [ 0.60740502,  2.08466924],\n",
              "       [ 0.41945092,  1.16404509],\n",
              "       [ 2.01706083, -1.18206161],\n",
              "       [ 1.35922145, -0.91478363],\n",
              "       [ 0.88933618,  1.13434754],\n",
              "       [ 0.0435427 ,  0.06523563],\n",
              "       [-0.52031962,  0.51069892],\n",
              "       [ 2.01706083,  1.81739126],\n",
              "       [-0.80225078, -0.76629586],\n",
              "       [-1.178159  ,  0.62948913],\n",
              "       [ 1.07729029,  2.14406434],\n",
              "       [-0.14441141,  2.233157  ],\n",
              "       [-0.14441141,  0.18402584],\n",
              "       [ 0.88933618, -1.15236405],\n",
              "       [ 0.23149681,  0.18402584],\n",
              "       [ 1.2652444 , -1.36024692],\n",
              "       [-0.61429667, -1.59782735],\n",
              "       [ 0.41945092,  0.18402584],\n",
              "       [ 0.23149681, -0.35053012],\n",
              "       [-0.70827373,  1.96587902],\n",
              "       [-0.05043435,  0.30281605],\n",
              "       [-0.52031962,  2.41134232],\n",
              "       [-0.14441141, -0.43962278],\n",
              "       [ 0.98331324,  1.49071817],\n",
              "       [-1.08418194, -1.59782735],\n",
              "       [-0.05043435,  0.3325136 ],\n",
              "       [ 0.0435427 , -0.55841299],\n",
              "       [ 1.45319851,  1.04525488],\n",
              "       [ 0.41945092, -0.11294969],\n",
              "       [ 0.88933618, -0.52871544],\n",
              "       [-0.61429667,  1.46102062],\n",
              "       [-0.42634257, -1.1226665 ],\n",
              "       [-0.80225078, -0.76629586],\n",
              "       [ 0.98331324,  0.62948913],\n",
              "       [-1.64804426, -1.36024692],\n",
              "       [-0.23838846,  0.65918669],\n",
              "       [ 1.92308377, -0.64750565],\n",
              "       [-1.08418194, -1.09296895],\n",
              "       [ 0.13751976,  0.06523563],\n",
              "       [ 0.13751976,  0.80767445],\n",
              "       [ 2.11103788,  0.98585977],\n",
              "       [ 0.32547386, -1.15236405],\n",
              "       [ 0.70138208, -1.38994448],\n",
              "       [ 0.98331324, -1.06327139],\n",
              "       [-1.64804426,  0.51069892],\n",
              "       [-1.3661131 , -0.08325214],\n",
              "       [ 0.98331324, -0.82569097],\n",
              "       [-0.42634257, -0.26143746],\n",
              "       [-1.64804426, -0.97417873],\n",
              "       [ 0.41945092, -0.14264725],\n",
              "       [ 2.01706083,  2.20345945],\n",
              "       [-0.42634257, -0.82569097],\n",
              "       [-0.52031962,  1.96587902]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=predict(X_test)"
      ],
      "metadata": {
        "id": "lWQK2SG9DGKe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XzdxphhEWCO",
        "outputId": "f5185174-745e-44f4-c3d7-10580fa897e8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print actual and predicted values in a table\n",
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(y_test)):\n",
        "    print(y_test[i],\"\\t\\t\",int(y_pred[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epeGBz2GE8bt",
        "outputId": "fff8d368-f9c4-4e77-9e2b-014b19663994"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual Value\tpredicted values\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==y_pred[i]):\n",
        "    x+=1\n",
        "print((x/len(y_test))*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgvGdLAzFegm",
        "outputId": "4a44f226-22cc-4e86-99aa-bbdc17679f22"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "from sklearn.metrics import  accuracy_score\n",
        "#Fit\n",
        "LR.fit(X_train,y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "sRBcUufAHDoF",
        "outputId": "6b367fdd-03f6-4015-d5cc-dfa99196bbd8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the test label with LR. Predict always takes X as input\n",
        "y_test_pred = LR.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)*100\n",
        "print(\"Accuracy: \", accuracy,\"%\")\n",
        "precision = precision_score(y_test, y_test_pred, average=None)\n",
        "recall = recall_score(y_test, y_test_pred, average=None)\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))"
      ],
      "metadata": {
        "id": "JgWqwoSdJA4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4ea0ad-5b3e-4001-b59a-de53ed5ec37f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  85.0 %\n",
            "precision: [0.85714286 0.83333333]\n",
            "recall: [0.92307692 0.71428571]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "l1=np.array(l1)"
      ],
      "metadata": {
        "id": "C_RT6zZJS2Ss"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYkskF6sUA57",
        "outputId": "83ed8661-87f9-41c9-f860-e92267c7d803"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRnb60fuUECc",
        "outputId": "0950f20c-a93d-4f22-f0a7-7ed5eaf7dddd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72613887, 0.71082102, 0.69632543, ..., 0.34338254, 0.34338254,\n",
              "       0.34338254])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(range(0,3000))"
      ],
      "metadata": {
        "id": "yPmqD-HNUFrQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT4KzwkdUQIa",
        "outputId": "dd0592fe-99b9-4804-e9e5-8b25dbb83415"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 2997, 2998, 2999])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x,l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2wwMXw5eUQxk",
        "outputId": "15ee1f78-b19a-43d4-87ae-05f6ff6fb1ae"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa0ee658490>]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hello1=np.array([[28,76000]])\n"
      ],
      "metadata": {
        "id": "cm200gpCUzbn"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello1=np.array(hello1)"
      ],
      "metadata": {
        "id": "c8WUz8xgVPeY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2MxB_PZVZoX",
        "outputId": "1d46f74f-15ab-46e9-91ba-6fc6381b6c47"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   28, 76000]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask=sc.fit(hello1)"
      ],
      "metadata": {
        "id": "35PJoc6jVuK9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask=x_ask.transform(hello1)"
      ],
      "metadata": {
        "id": "d1gsug0OWCAt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lamNFlHRWWqi",
        "outputId": "2e2d7843-d3b2-4733-9e3d-c983318ccf41"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR.predict(x_ask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtHd1gIXWZmc",
        "outputId": "47885b43-4a74-4c0f-de7f-012a1876cadc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CymNW0gYXi4w"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}